{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a79ebcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sheila/anaconda3/envs/environment_py3_7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sheila/anaconda3/envs/environment_py3_7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sheila/anaconda3/envs/environment_py3_7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sheila/anaconda3/envs/environment_py3_7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sheila/anaconda3/envs/environment_py3_7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sheila/anaconda3/envs/environment_py3_7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import scipy.io as io\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from ns3gym import ns3env\n",
    "\n",
    "import sys\n",
    "sys.argv=['']\n",
    "del sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "956c340f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got new port for ns3gm interface:  9552\n",
      "Observation space:  Box(0, 100, (5,), uint64) uint64\n",
      "Action space:  Box(0, 100, (5,), uint64) uint64\n",
      "WARNING:tensorflow:From /home/sheila/anaconda3/envs/environment_py3_7/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Episode: 0\n",
      "linear-wireless-mesh|123\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Rnd\n",
      "actionVec: [85, 82, 8, 47, 100]\n",
      "next_state: [90, 1, 0, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[90  1  0  1  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Rnd\n",
      "actionVec: [31, 18, 32, 37, 100]\n",
      "next_state: [100, 4, 4, 4, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   4   4   4   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 2\n",
      "Rnd\n",
      "actionVec: [85, 14, 2, 55, 100]\n",
      "next_state: [100, 1, 0, 12, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   1   0  12   0]]\n",
      "rewardsum:  1.0\n",
      "Time Slot: 3\n",
      "Rnd\n",
      "actionVec: [91, 8, 30, 53, 100]\n",
      "next_state: [100, 0, 0, 9, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0   0   9   0]]\n",
      "rewardsum:  8.0\n",
      "Time Slot: 4\n",
      "Rnd\n",
      "actionVec: [86, 81, 55, 30, 100]\n",
      "next_state: [100, 2, 0, 0, 0]\n",
      "Reward: 10.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   2   0   0   0]]\n",
      "rewardsum:  18.0\n",
      "Time Slot: 5\n",
      "Rnd\n",
      "actionVec: [57, 7, 60, 77, 100]\n",
      "next_state: [98, 0, 2, 3, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98  0  2  3  0]]\n",
      "rewardsum:  19.0\n",
      "Time Slot: 6\n",
      "Rnd\n",
      "actionVec: [93, 40, 94, 92, 100]\n",
      "next_state: [100, 0, 3, 4, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0   3   4   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 7\n",
      "Rnd\n",
      "actionVec: [41, 90, 16, 38, 100]\n",
      "next_state: [100, 3, 0, 5, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   3   0   5   0]]\n",
      "rewardsum:  26.0\n",
      "Time Slot: 8\n",
      "Rnd\n",
      "actionVec: [13, 67, 73, 91, 100]\n",
      "next_state: [100, 14, 0, 5, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   0   5   0]]\n",
      "rewardsum:  27.0\n",
      "Time Slot: 9\n",
      "Rnd\n",
      "actionVec: [34, 34, 89, 34, 100]\n",
      "next_state: [100, 14, 3, 3, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   3   3   0]]\n",
      "rewardsum:  31.0\n",
      "Time Slot: 10\n",
      "Rnd\n",
      "actionVec: [33, 1, 52, 11, 100]\n",
      "next_state: [64, 0, 16, 3, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[64  0 16  3  0]]\n",
      "rewardsum:  32.0\n",
      "Time Slot: 11\n",
      "Rnd\n",
      "actionVec: [34, 92, 26, 77, 100]\n",
      "next_state: [100, 2, 10, 6, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   2  10   6   0]]\n",
      "rewardsum:  36.0\n",
      "Time Slot: 12\n",
      "Rnd\n",
      "actionVec: [68, 84, 60, 62, 100]\n",
      "next_state: [100, 5, 10, 5, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   5  10   5   0]]\n",
      "rewardsum:  40.0\n",
      "Time Slot: 13\n",
      "Rnd\n",
      "actionVec: [42, 31, 15, 10, 100]\n",
      "next_state: [89, 4, 4, 4, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[89  4  4  4  0]]\n",
      "rewardsum:  48.0\n",
      "Time Slot: 14\n",
      "Rnd\n",
      "actionVec: [18, 7, 50, 4, 100]\n",
      "next_state: [99, 2, 6, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99  2  6  0  0]]\n",
      "rewardsum:  55.0\n",
      "Time Slot: 15\n",
      "Rnd\n",
      "actionVec: [26, 83, 38, 51, 100]\n",
      "next_state: [100, 5, 3, 3, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   5   3   3   0]]\n",
      "rewardsum:  58.0\n",
      "Time Slot: 16\n",
      "Rnd\n",
      "actionVec: [47, 95, 64, 75, 100]\n",
      "next_state: [100, 8, 1, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   8   1   0   0]]\n",
      "rewardsum:  64.0\n",
      "Time Slot: 17\n",
      "Rnd\n",
      "actionVec: [91, 77, 68, 2, 100]\n",
      "next_state: [100, 7, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   7   0   0   0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 18\n",
      "Rnd\n",
      "actionVec: [49, 10, 57, 93, 100]\n",
      "next_state: [100, 1, 9, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   1   9   1   0]]\n",
      "rewardsum:  69.0\n",
      "Time Slot: 19\n",
      "Rnd\n",
      "actionVec: [23, 77, 55, 37, 100]\n",
      "next_state: [100, 0, 12, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0  12   2   0]]\n",
      "rewardsum:  71.0\n",
      "Time Slot: 20\n",
      "Rnd\n",
      "actionVec: [52, 92, 70, 30, 100]\n",
      "next_state: [99, 2, 12, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99  2 12  1  0]]\n",
      "rewardsum:  75.0\n",
      "Time Slot: 21\n",
      "Rnd\n",
      "actionVec: [30, 79, 76, 23, 100]\n",
      "next_state: [100, 5, 8, 1, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   5   8   1   0]]\n",
      "rewardsum:  81.0\n",
      "Time Slot: 22\n",
      "Rnd\n",
      "actionVec: [27, 47, 3, 20, 100]\n",
      "next_state: [99, 7, 3, 4, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99  7  3  4  0]]\n",
      "rewardsum:  84.0\n",
      "Time Slot: 23\n",
      "Rnd\n",
      "actionVec: [55, 3, 17, 78, 100]\n",
      "next_state: [100, 0, 8, 5, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0   8   5   0]]\n",
      "rewardsum:  86.0\n",
      "Time Slot: 24\n",
      "Rnd\n",
      "actionVec: [80, 95, 20, 75, 100]\n",
      "next_state: [100, 2, 0, 11, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   2   0  11   0]]\n",
      "rewardsum:  89.0\n",
      "Time Slot: 25\n",
      "Rnd\n",
      "actionVec: [83, 74, 88, 99, 100]\n",
      "next_state: [100, 2, 1, 10, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   2   1  10   0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 26\n",
      "Rnd\n",
      "actionVec: [91, 73, 87, 51, 100]\n",
      "next_state: [100, 3, 0, 6, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   3   0   6   0]]\n",
      "rewardsum:  101.0\n",
      "Time Slot: 27\n",
      "Rnd\n",
      "actionVec: [69, 8, 25, 77, 100]\n",
      "next_state: [100, 0, 0, 9, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0   0   9   0]]\n",
      "rewardsum:  103.0\n",
      "Time Slot: 28\n",
      "Rnd\n",
      "actionVec: [73, 95, 94, 48, 100]\n",
      "next_state: [100, 1, 2, 7, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   1   2   7   0]]\n",
      "rewardsum:  107.0\n",
      "Time Slot: 29\n",
      "Rnd\n",
      "actionVec: [76, 28, 64, 18, 100]\n",
      "next_state: [100, 0, 1, 2, 0]\n",
      "Reward: 9.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0   1   2   0]]\n",
      "rewardsum:  116.0\n",
      "Time Slot: 30\n",
      "Rnd\n",
      "actionVec: [67, 64, 62, 8, 100]\n",
      "next_state: [86, 1, 1, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[86  1  1  1  0]]\n",
      "rewardsum:  121.0\n",
      "Time Slot: 31\n",
      "Rnd\n",
      "actionVec: [56, 30, 15, 78, 100]\n",
      "next_state: [100, 0, 0, 2, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0   0   2   0]]\n",
      "rewardsum:  125.0\n",
      "Time Slot: 32\n",
      "Rnd\n",
      "actionVec: [50, 76, 20, 69, 100]\n",
      "next_state: [100, 0, 1, 3, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0   1   3   0]]\n",
      "rewardsum:  127.0\n",
      "Time Slot: 33\n",
      "Rnd\n",
      "actionVec: [22, 94, 91, 25, 100]\n",
      "next_state: [100, 6, 1, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   6   1   0   0]]\n",
      "rewardsum:  132.0\n",
      "Time Slot: 34\n",
      "Rnd\n",
      "actionVec: [23, 88, 90, 99, 100]\n",
      "next_state: [100, 13, 0, 3, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13   0   3   0]]\n",
      "rewardsum:  133.0\n",
      "Time Slot: 35\n",
      "Rnd\n",
      "actionVec: [41, 15, 20, 40, 100]\n",
      "next_state: [100, 11, 2, 4, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11   2   4   0]]\n",
      "rewardsum:  134.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 22, 77, 100]\n",
      "next_state: [82, 12, 0, 6, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[82 12  0  6  0]]\n",
      "rewardsum:  138.0\n",
      "Time Slot: 37\n",
      "Rnd\n",
      "actionVec: [29, 89, 90, 53, 100]\n",
      "next_state: [100, 17, 1, 7, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   1   7   0]]\n",
      "rewardsum:  140.0\n",
      "Time Slot: 38\n",
      "Rnd\n",
      "actionVec: [91, 59, 79, 22, 100]\n",
      "next_state: [100, 15, 3, 0, 0]\n",
      "Reward: 9.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15   3   0   0]]\n",
      "rewardsum:  149.0\n",
      "Time Slot: 39\n",
      "Rnd\n",
      "actionVec: [90, 45, 10, 8, 100]\n",
      "next_state: [97, 12, 1, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 12  1  0  0]]\n",
      "rewardsum:  154.0\n",
      "Time Slot: 40\n",
      "Rnd\n",
      "actionVec: [19, 99, 98, 66, 100]\n",
      "next_state: [100, 17, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   1   0   0]]\n",
      "rewardsum:  157.0\n",
      "Time Slot: 41\n",
      "Rnd\n",
      "actionVec: [52, 57, 97, 60, 100]\n",
      "next_state: [100, 19, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   4   0   0]]\n",
      "rewardsum:  159.0\n",
      "Time Slot: 42\n",
      "Rnd\n",
      "actionVec: [12, 30, 0, 10, 100]\n",
      "next_state: [100, 25, 7, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   7   0   0]]\n",
      "rewardsum:  160.0\n",
      "Time Slot: 43\n",
      "Rnd\n",
      "actionVec: [29, 30, 67, 87, 100]\n",
      "next_state: [100, 21, 14, 2, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  14   2   0]]\n",
      "rewardsum:  160.0\n",
      "Time Slot: 44\n",
      "Rnd\n",
      "actionVec: [32, 18, 36, 36, 100]\n",
      "next_state: [100, 16, 19, 3, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16  19   3   0]]\n",
      "rewardsum:  162.0\n",
      "Time Slot: 45\n",
      "Rnd\n",
      "actionVec: [5, 37, 63, 16, 100]\n",
      "next_state: [100, 23, 20, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  20   0   0]]\n",
      "rewardsum:  166.0\n",
      "Time Slot: 46\n",
      "Rnd\n",
      "actionVec: [96, 0, 14, 67, 100]\n",
      "next_state: [99, 19, 20, 3, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 19 20  3  0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 47\n",
      "Rnd\n",
      "actionVec: [28, 81, 52, 64, 100]\n",
      "next_state: [99, 19, 19, 4, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[99 19 19  4  0]]\n",
      "rewardsum:  171.0\n",
      "Time Slot: 48\n",
      "Rnd\n",
      "actionVec: [87, 21, 66, 17, 100]\n",
      "next_state: [100, 14, 26, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14  26   0   0]]\n",
      "rewardsum:  177.0\n",
      "Time Slot: 49\n",
      "Rnd\n",
      "actionVec: [4, 16, 85, 27, 100]\n",
      "next_state: [100, 25, 21, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  21   0   0]]\n",
      "rewardsum:  178.0\n",
      "Time Slot: 50\n",
      "Rnd\n",
      "actionVec: [4, 90, 57, 59, 100]\n",
      "next_state: [100, 34, 20, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  20   1   0]]\n",
      "rewardsum:  178.0\n",
      "Time Slot: 51\n",
      "Rnd\n",
      "actionVec: [93, 8, 86, 64, 100]\n",
      "next_state: [64, 25, 23, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[64 25 23  1  0]]\n",
      "rewardsum:  181.0\n",
      "Time Slot: 52\n",
      "Rnd\n",
      "actionVec: [17, 4, 78, 28, 100]\n",
      "next_state: [100, 11, 34, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11  34   1   0]]\n",
      "rewardsum:  181.0\n",
      "Time Slot: 53\n",
      "Rnd\n",
      "actionVec: [90, 4, 62, 82, 100]\n",
      "next_state: [97, 0, 40, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97  0 40  1  0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 54\n",
      "Rnd\n",
      "actionVec: [66, 45, 12, 87, 100]\n",
      "next_state: [94, 1, 29, 11, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[94  1 29 11  0]]\n",
      "rewardsum:  184.0\n",
      "Time Slot: 55\n",
      "Rnd\n",
      "actionVec: [20, 78, 97, 60, 100]\n",
      "next_state: [100, 7, 29, 11, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   7  29  11   0]]\n",
      "rewardsum:  187.0\n",
      "Time Slot: 56\n",
      "Rnd\n",
      "actionVec: [57, 50, 91, 49, 100]\n",
      "next_state: [100, 8, 30, 9, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   8  30   9   0]]\n",
      "rewardsum:  190.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 99, 78, 77, 100]\n",
      "next_state: [100, 14, 21, 13, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14  21  13   0]]\n",
      "rewardsum:  192.0\n",
      "Time Slot: 58\n",
      "Rnd\n",
      "actionVec: [58, 36, 55, 81, 100]\n",
      "next_state: [100, 11, 15, 12, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11  15  12   0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 59\n",
      "Rnd\n",
      "actionVec: [39, 38, 37, 19, 100]\n",
      "next_state: [100, 10, 16, 10, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10  16  10   0]]\n",
      "rewardsum:  200.0\n",
      "Time Slot: 60\n",
      "Rnd\n",
      "actionVec: [84, 80, 34, 6, 100]\n",
      "next_state: [92, 11, 15, 1, 0]\n",
      "Reward: 11.0\n",
      "----------------- \n",
      "\n",
      "state:  [[92 11 15  1  0]]\n",
      "rewardsum:  211.0\n",
      "Time Slot: 61\n",
      "Rnd\n",
      "actionVec: [23, 45, 27, 54, 100]\n",
      "next_state: [100, 12, 12, 6, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12  12   6   0]]\n",
      "rewardsum:  213.0\n",
      "Time Slot: 62\n",
      "Rnd\n",
      "actionVec: [55, 45, 18, 61, 100]\n",
      "next_state: [79, 12, 7, 11, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[79 12  7 11  0]]\n",
      "rewardsum:  215.0\n",
      "Time Slot: 63\n",
      "Rnd\n",
      "actionVec: [10, 7, 9, 65, 100]\n",
      "next_state: [100, 9, 3, 18, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   9   3  18   0]]\n",
      "rewardsum:  215.0\n",
      "Time Slot: 64\n",
      "Rnd\n",
      "actionVec: [51, 89, 7, 8, 100]\n",
      "next_state: [100, 10, 0, 15, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10   0  15   0]]\n",
      "rewardsum:  223.0\n",
      "Time Slot: 65\n",
      "Rnd\n",
      "actionVec: [34, 26, 20, 23, 100]\n",
      "next_state: [100, 9, 1, 14, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   9   1  14   0]]\n",
      "rewardsum:  228.0\n",
      "Time Slot: 66\n",
      "Rnd\n",
      "actionVec: [69, 47, 36, 57, 100]\n",
      "next_state: [100, 9, 0, 14, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   9   0  14   0]]\n",
      "rewardsum:  232.0\n",
      "Time Slot: 67\n",
      "Rnd\n",
      "actionVec: [21, 17, 36, 17, 100]\n",
      "next_state: [100, 5, 2, 10, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   5   2  10   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 68\n",
      "Rnd\n",
      "actionVec: [1, 57, 97, 0, 100]\n",
      "next_state: [100, 7, 5, 9, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   7   5   9   0]]\n",
      "rewardsum:  242.0\n",
      "Time Slot: 69\n",
      "Rnd\n",
      "actionVec: [62, 89, 19, 58, 100]\n",
      "next_state: [100, 7, 0, 11, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   7   0  11   0]]\n",
      "rewardsum:  247.0\n",
      "Time Slot: 70\n",
      "Rnd\n",
      "actionVec: [47, 56, 11, 18, 100]\n",
      "next_state: [100, 7, 0, 11, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   7   0  11   0]]\n",
      "rewardsum:  251.0\n",
      "Time Slot: 71\n",
      "Rnd\n",
      "actionVec: [52, 46, 17, 8, 100]\n",
      "next_state: [99, 6, 1, 0, 0]\n",
      "Reward: 12.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99  6  1  0  0]]\n",
      "rewardsum:  263.0\n",
      "Time Slot: 72\n",
      "Rnd\n",
      "actionVec: [48, 58, 30, 96, 100]\n",
      "next_state: [97, 5, 0, 3, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97  5  0  3  0]]\n",
      "rewardsum:  265.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 36, 77, 100]\n",
      "next_state: [100, 5, 1, 6, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   5   1   6   0]]\n",
      "rewardsum:  267.0\n",
      "Time Slot: 74\n",
      "Rnd\n",
      "actionVec: [98, 48, 65, 6, 100]\n",
      "next_state: [92, 6, 0, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[92  6  0  0  0]]\n",
      "rewardsum:  275.0\n",
      "Time Slot: 75\n",
      "Rnd\n",
      "actionVec: [7, 20, 64, 95, 100]\n",
      "next_state: [100, 8, 5, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   8   5   1   0]]\n",
      "rewardsum:  276.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 77, 100]\n",
      "next_state: [100, 14, 7, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   7   2   0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 77\n",
      "Rnd\n",
      "actionVec: [57, 4, 84, 5, 100]\n",
      "next_state: [69, 8, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[69  8 13  0  0]]\n",
      "rewardsum:  280.0\n",
      "Time Slot: 78\n",
      "Rnd\n",
      "actionVec: [92, 52, 95, 4, 100]\n",
      "next_state: [96, 7, 13, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96  7 13  0  0]]\n",
      "rewardsum:  285.0\n",
      "Time Slot: 79\n",
      "Rnd\n",
      "actionVec: [52, 74, 52, 13, 100]\n",
      "next_state: [100, 7, 11, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   7  11   0   0]]\n",
      "rewardsum:  290.0\n",
      "Time Slot: 80\n",
      "Rnd\n",
      "actionVec: [0, 83, 35, 11, 100]\n",
      "next_state: [100, 9, 7, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   9   7   0   0]]\n",
      "rewardsum:  295.0\n",
      "Time Slot: 81\n",
      "Rnd\n",
      "actionVec: [80, 80, 4, 70, 100]\n",
      "next_state: [93, 6, 0, 10, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[93  6  0 10  0]]\n",
      "rewardsum:  296.0\n",
      "Time Slot: 82\n",
      "Rnd\n",
      "actionVec: [23, 22, 42, 4, 100]\n",
      "next_state: [100, 10, 0, 0, 0]\n",
      "Reward: 11.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10   0   0   0]]\n",
      "rewardsum:  307.0\n",
      "Time Slot: 83\n",
      "Rnd\n",
      "actionVec: [30, 83, 5, 57, 100]\n",
      "next_state: [100, 18, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   0   0   0]]\n",
      "rewardsum:  309.0\n",
      "Time Slot: 84\n",
      "Rnd\n",
      "actionVec: [70, 55, 10, 21, 100]\n",
      "next_state: [100, 17, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   0   0   0]]\n",
      "rewardsum:  313.0\n",
      "Time Slot: 85\n",
      "Rnd\n",
      "actionVec: [26, 76, 42, 32, 100]\n",
      "next_state: [100, 21, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21   1   0   0]]\n",
      "rewardsum:  316.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   1   0   0]]\n",
      "rewardsum:  319.0\n",
      "Time Slot: 87\n",
      "Rnd\n",
      "actionVec: [34, 69, 18, 19, 100]\n",
      "next_state: [100, 25, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   1   0   0]]\n",
      "rewardsum:  323.0\n",
      "Time Slot: 88\n",
      "Rnd\n",
      "actionVec: [30, 28, 1, 48, 100]\n",
      "next_state: [100, 23, 0, 4, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   0   4   0]]\n",
      "rewardsum:  325.0\n",
      "Time Slot: 89\n",
      "Rnd\n",
      "actionVec: [58, 4, 11, 82, 100]\n",
      "next_state: [95, 16, 3, 7, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 16  3  7  0]]\n",
      "rewardsum:  327.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 91, 8, 100]\n",
      "next_state: [98, 17, 4, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 17  4  0  0]]\n",
      "rewardsum:  335.0\n",
      "Time Slot: 91\n",
      "Rnd\n",
      "actionVec: [81, 49, 65, 48, 100]\n",
      "next_state: [100, 14, 1, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   1   0   0]]\n",
      "rewardsum:  341.0\n",
      "Time Slot: 92\n",
      "Rnd\n",
      "actionVec: [40, 78, 86, 63, 100]\n",
      "next_state: [99, 14, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 14  1  0  0]]\n",
      "rewardsum:  345.0\n",
      "Time Slot: 93\n",
      "Rnd\n",
      "actionVec: [40, 32, 63, 3, 100]\n",
      "next_state: [98, 17, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 17  2  0  0]]\n",
      "rewardsum:  348.0\n",
      "Time Slot: 94\n",
      "Rnd\n",
      "actionVec: [4, 55, 66, 85, 100]\n",
      "next_state: [100, 29, 3, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   3   0   0]]\n",
      "rewardsum:  348.0\n",
      "Time Slot: 95\n",
      "Rnd\n",
      "actionVec: [87, 6, 39, 82, 100]\n",
      "next_state: [92, 14, 17, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[92 14 17  1  0]]\n",
      "rewardsum:  348.0\n",
      "Time Slot: 96\n",
      "Rnd\n",
      "actionVec: [35, 23, 12, 3, 100]\n",
      "next_state: [89, 12, 14, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[89 12 14  0  0]]\n",
      "rewardsum:  355.0\n",
      "Time Slot: 97\n",
      "Rnd\n",
      "actionVec: [10, 88, 9, 21, 100]\n",
      "next_state: [100, 18, 8, 6, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   8   6   0]]\n",
      "rewardsum:  356.0\n",
      "Time Slot: 98\n",
      "Rnd\n",
      "actionVec: [2, 85, 31, 95, 100]\n",
      "next_state: [100, 30, 7, 6, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   7   6   0]]\n",
      "rewardsum:  357.0\n",
      "Time Slot: 99\n",
      "Rnd\n",
      "actionVec: [49, 2, 40, 99, 100]\n",
      "next_state: [96, 21, 14, 8, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 21 14  8  0]]\n",
      "rewardsum:  358.0\n",
      "Episode: 1\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  7887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Rnd\n",
      "actionVec: [85, 26, 51, 65, 100]\n",
      "next_state: [90, 0, 2, 0, 1]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[90  0  2  0  1]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Rnd\n",
      "actionVec: [96, 19, 28, 57, 100]\n",
      "next_state: [100, 0, 1, 1, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0   1   1   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 4, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   4   1   0   0]]\n",
      "rewardsum:  9.0\n",
      "Time Slot: 3\n",
      "Rnd\n",
      "actionVec: [76, 89, 4, 30, 100]\n",
      "next_state: [100, 5, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   5   0   0   0]]\n",
      "rewardsum:  14.0\n",
      "Time Slot: 4\n",
      "Rnd\n",
      "actionVec: [50, 75, 96, 70, 100]\n",
      "next_state: [100, 9, 2, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   9   2   0   0]]\n",
      "rewardsum:  15.0\n",
      "Time Slot: 5\n",
      "Rnd\n",
      "actionVec: [6, 98, 21, 21, 100]\n",
      "next_state: [99, 17, 0, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 17  0  1  0]]\n",
      "rewardsum:  18.0\n",
      "Time Slot: 6\n",
      "Rnd\n",
      "actionVec: [14, 27, 88, 82, 100]\n",
      "next_state: [100, 25, 3, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   3   0   0]]\n",
      "rewardsum:  19.0\n",
      "Time Slot: 7\n",
      "Rnd\n",
      "actionVec: [49, 78, 54, 47, 100]\n",
      "next_state: [100, 28, 1, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   1   2   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 8\n",
      "Rnd\n",
      "actionVec: [70, 88, 31, 11, 100]\n",
      "next_state: [100, 31, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   0   0   0]]\n",
      "rewardsum:  27.0\n",
      "Time Slot: 9\n",
      "Rnd\n",
      "actionVec: [20, 1, 11, 13, 100]\n",
      "next_state: [100, 19, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   9   0   0]]\n",
      "rewardsum:  29.0\n",
      "Time Slot: 10\n",
      "Rnd\n",
      "actionVec: [55, 74, 35, 17, 100]\n",
      "next_state: [70, 18, 6, 2, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[70 18  6  2  0]]\n",
      "rewardsum:  34.0\n",
      "Time Slot: 11\n",
      "Rnd\n",
      "actionVec: [46, 54, 8, 46, 100]\n",
      "next_state: [98, 16, 0, 6, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 16  0  6  0]]\n",
      "rewardsum:  37.0\n",
      "Time Slot: 12\n",
      "Rnd\n",
      "actionVec: [50, 64, 95, 13, 100]\n",
      "next_state: [100, 14, 1, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   1   0   0]]\n",
      "rewardsum:  45.0\n",
      "Time Slot: 13\n",
      "Rnd\n",
      "actionVec: [28, 39, 24, 21, 100]\n",
      "next_state: [100, 15, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15   0   0   0]]\n",
      "rewardsum:  48.0\n",
      "Time Slot: 14\n",
      "Rnd\n",
      "actionVec: [6, 84, 17, 54, 100]\n",
      "next_state: [100, 22, 1, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   1   1   0]]\n",
      "rewardsum:  50.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   1   0   0]]\n",
      "rewardsum:  54.0\n",
      "Time Slot: 16\n",
      "Rnd\n",
      "actionVec: [53, 96, 12, 68, 100]\n",
      "next_state: [100, 28, 0, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   0   1   0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 17\n",
      "Rnd\n",
      "actionVec: [31, 85, 8, 96, 100]\n",
      "next_state: [100, 29, 0, 3, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   0   3   0]]\n",
      "rewardsum:  59.0\n",
      "Time Slot: 18\n",
      "Rnd\n",
      "actionVec: [79, 82, 75, 34, 100]\n",
      "next_state: [100, 32, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   0   0   0]]\n",
      "rewardsum:  64.0\n",
      "Time Slot: 19\n",
      "Rnd\n",
      "actionVec: [57, 35, 61, 89, 100]\n",
      "next_state: [100, 26, 3, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   3   2   0]]\n",
      "rewardsum:  66.0\n",
      "Time Slot: 20\n",
      "Rnd\n",
      "actionVec: [8, 76, 14, 90, 100]\n",
      "next_state: [100, 28, 1, 4, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   1   4   0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 21\n",
      "Rnd\n",
      "actionVec: [87, 27, 44, 9, 100]\n",
      "next_state: [95, 24, 2, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 24  2  0  0]]\n",
      "rewardsum:  74.0\n",
      "Time Slot: 22\n",
      "Rnd\n",
      "actionVec: [28, 60, 21, 2, 100]\n",
      "next_state: [99, 23, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 23  0  0  0]]\n",
      "rewardsum:  79.0\n",
      "Time Slot: 23\n",
      "Rnd\n",
      "actionVec: [81, 65, 50, 77, 100]\n",
      "next_state: [100, 20, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   1   0   0]]\n",
      "rewardsum:  83.0\n",
      "Time Slot: 24\n",
      "Rnd\n",
      "actionVec: [78, 65, 16, 11, 100]\n",
      "next_state: [99, 20, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 20  0  0  0]]\n",
      "rewardsum:  87.0\n",
      "Time Slot: 25\n",
      "Rnd\n",
      "actionVec: [2, 16, 90, 15, 100]\n",
      "next_state: [100, 28, 0, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   0   0   0]]\n",
      "rewardsum:  88.0\n",
      "Time Slot: 26\n",
      "Rnd\n",
      "actionVec: [87, 5, 50, 47, 100]\n",
      "next_state: [100, 15, 12, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15  12   1   0]]\n",
      "rewardsum:  88.0\n",
      "Time Slot: 27\n",
      "Rnd\n",
      "actionVec: [94, 6, 20, 64, 100]\n",
      "next_state: [91, 2, 23, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[91  2 23  2  0]]\n",
      "rewardsum:  89.0\n",
      "Time Slot: 28\n",
      "Rnd\n",
      "actionVec: [13, 14, 61, 3, 100]\n",
      "next_state: [100, 0, 30, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0  30   0   0]]\n",
      "rewardsum:  92.0\n",
      "Time Slot: 29\n",
      "Rnd\n",
      "actionVec: [82, 40, 63, 12, 100]\n",
      "next_state: [98, 0, 30, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98  0 30  0  0]]\n",
      "rewardsum:  95.0\n",
      "Time Slot: 30\n",
      "Rnd\n",
      "actionVec: [57, 29, 60, 73, 100]\n",
      "next_state: [98, 0, 31, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98  0 31  2  0]]\n",
      "rewardsum:  97.0\n",
      "Time Slot: 31\n",
      "Rnd\n",
      "actionVec: [67, 92, 85, 51, 100]\n",
      "next_state: [100, 2, 29, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   2  29   0   0]]\n",
      "rewardsum:  103.0\n",
      "Time Slot: 32\n",
      "Rnd\n",
      "actionVec: [27, 86, 11, 73, 100]\n",
      "next_state: [100, 1, 22, 7, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   1  22   7   0]]\n",
      "rewardsum:  105.0\n",
      "Time Slot: 33\n",
      "Rnd\n",
      "actionVec: [2, 71, 92, 10, 100]\n",
      "next_state: [100, 11, 14, 5, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11  14   5   0]]\n",
      "rewardsum:  110.0\n",
      "Time Slot: 34\n",
      "Rnd\n",
      "actionVec: [5, 46, 29, 92, 100]\n",
      "next_state: [100, 22, 12, 5, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22  12   5   0]]\n",
      "rewardsum:  110.0\n",
      "Time Slot: 35\n",
      "Rnd\n",
      "actionVec: [4, 34, 41, 81, 100]\n",
      "next_state: [100, 34, 9, 6, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   9   6   0]]\n",
      "rewardsum:  110.0\n",
      "Time Slot: 36\n",
      "Rnd\n",
      "actionVec: [65, 17, 51, 82, 100]\n",
      "next_state: [86, 27, 13, 8, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[86 27 13  8  0]]\n",
      "rewardsum:  112.0\n",
      "Time Slot: 37\n",
      "Rnd\n",
      "actionVec: [45, 65, 42, 4, 100]\n",
      "next_state: [100, 27, 15, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  15   0   0]]\n",
      "rewardsum:  120.0\n",
      "Time Slot: 38\n",
      "Rnd\n",
      "actionVec: [12, 56, 82, 98, 100]\n",
      "next_state: [100, 35, 16, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  16   1   0]]\n",
      "rewardsum:  122.0\n",
      "Time Slot: 39\n",
      "Rnd\n",
      "actionVec: [99, 86, 71, 38, 100]\n",
      "next_state: [100, 34, 14, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  14   1   0]]\n",
      "rewardsum:  126.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 25, 16, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 25 16  0  0]]\n",
      "rewardsum:  130.0\n",
      "Time Slot: 41\n",
      "Rnd\n",
      "actionVec: [93, 3, 61, 17, 100]\n",
      "next_state: [70, 14, 23, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[70 14 23  0  0]]\n",
      "rewardsum:  133.0\n",
      "Time Slot: 42\n",
      "Rnd\n",
      "actionVec: [74, 82, 97, 66, 100]\n",
      "next_state: [100, 14, 21, 3, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14  21   3   0]]\n",
      "rewardsum:  135.0\n",
      "Time Slot: 43\n",
      "Rnd\n",
      "actionVec: [77, 67, 95, 29, 100]\n",
      "next_state: [99, 14, 20, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 14 20  0  0]]\n",
      "rewardsum:  141.0\n",
      "Time Slot: 44\n",
      "Rnd\n",
      "actionVec: [13, 75, 71, 46, 100]\n",
      "next_state: [100, 19, 21, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19  21   1   0]]\n",
      "rewardsum:  143.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 19, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  19   0   0]]\n",
      "rewardsum:  147.0\n",
      "Time Slot: 46\n",
      "Rnd\n",
      "actionVec: [18, 40, 71, 84, 100]\n",
      "next_state: [100, 28, 16, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  16   0   0]]\n",
      "rewardsum:  149.0\n",
      "Time Slot: 47\n",
      "Rnd\n",
      "actionVec: [74, 53, 41, 79, 100]\n",
      "next_state: [100, 26, 15, 4, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  15   4   0]]\n",
      "rewardsum:  150.0\n",
      "Time Slot: 48\n",
      "Rnd\n",
      "actionVec: [28, 1, 95, 37, 100]\n",
      "next_state: [82, 11, 28, 5, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[82 11 28  5  0]]\n",
      "rewardsum:  151.0\n",
      "Time Slot: 49\n",
      "Rnd\n",
      "actionVec: [38, 5, 46, 23, 100]\n",
      "next_state: [97, 0, 37, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97  0 37  2  0]]\n",
      "rewardsum:  154.0\n",
      "Time Slot: 50\n",
      "Rnd\n",
      "actionVec: [88, 58, 48, 2, 100]\n",
      "next_state: [86, 0, 34, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[86  0 34  0  0]]\n",
      "rewardsum:  160.0\n",
      "Time Slot: 51\n",
      "Rnd\n",
      "actionVec: [46, 93, 16, 71, 100]\n",
      "next_state: [100, 2, 28, 6, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   2  28   6   0]]\n",
      "rewardsum:  163.0\n",
      "Time Slot: 52\n",
      "Rnd\n",
      "actionVec: [67, 71, 67, 36, 100]\n",
      "next_state: [100, 5, 27, 4, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100   5  27   4   0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 53\n",
      "Rnd\n",
      "actionVec: [57, 93, 1, 4, 100]\n",
      "next_state: [100, 5, 12, 18, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   5  12  18   0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 54\n",
      "Rnd\n",
      "actionVec: [90, 98, 15, 75, 100]\n",
      "next_state: [100, 6, 4, 25, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   6   4  25   0]]\n",
      "rewardsum:  170.0\n",
      "Time Slot: 55\n",
      "Rnd\n",
      "actionVec: [65, 30, 25, 59, 100]\n",
      "next_state: [100, 5, 4, 28, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   5   4  28   0]]\n",
      "rewardsum:  173.0\n",
      "Time Slot: 56\n",
      "Rnd\n",
      "actionVec: [56, 67, 49, 45, 100]\n",
      "next_state: [100, 3, 2, 30, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   3   2  30   0]]\n",
      "rewardsum:  177.0\n",
      "Time Slot: 57\n",
      "Rnd\n",
      "actionVec: [40, 26, 99, 87, 100]\n",
      "next_state: [100, 1, 5, 30, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   1   5  30   0]]\n",
      "rewardsum:  180.0\n",
      "Time Slot: 58\n",
      "Rnd\n",
      "actionVec: [67, 11, 97, 24, 100]\n",
      "next_state: [100, 1, 7, 25, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   1   7  25   0]]\n",
      "rewardsum:  186.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 91, 8, 100]\n",
      "next_state: [77, 0, 5, 13, 0]\n",
      "Reward: 14.0\n",
      "----------------- \n",
      "\n",
      "state:  [[77  0  5 13  0]]\n",
      "rewardsum:  200.0\n",
      "Time Slot: 60\n",
      "Rnd\n",
      "actionVec: [7, 3, 62, 78, 100]\n",
      "next_state: [100, 0, 11, 14, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0  11  14   0]]\n",
      "rewardsum:  201.0\n",
      "Time Slot: 61\n",
      "Rnd\n",
      "actionVec: [8, 82, 44, 51, 100]\n",
      "next_state: [100, 10, 9, 10, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10   9  10   0]]\n",
      "rewardsum:  204.0\n",
      "Time Slot: 62\n",
      "Rnd\n",
      "actionVec: [21, 11, 17, 97, 100]\n",
      "next_state: [100, 11, 8, 12, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11   8  12   0]]\n",
      "rewardsum:  205.0\n",
      "Time Slot: 63\n",
      "Rnd\n",
      "actionVec: [57, 55, 80, 76, 100]\n",
      "next_state: [100, 12, 10, 11, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12  10  11   0]]\n",
      "rewardsum:  209.0\n",
      "Time Slot: 64\n",
      "Rnd\n",
      "actionVec: [11, 34, 86, 76, 100]\n",
      "next_state: [100, 17, 12, 12, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17  12  12   0]]\n",
      "rewardsum:  210.0\n",
      "Time Slot: 65\n",
      "Rnd\n",
      "actionVec: [48, 56, 9, 33, 100]\n",
      "next_state: [100, 17, 11, 11, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17  11  11   0]]\n",
      "rewardsum:  215.0\n",
      "Time Slot: 66\n",
      "Rnd\n",
      "actionVec: [10, 49, 76, 24, 100]\n",
      "next_state: [100, 19, 14, 9, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19  14   9   0]]\n",
      "rewardsum:  219.0\n",
      "Time Slot: 67\n",
      "Rnd\n",
      "actionVec: [36, 15, 74, 82, 100]\n",
      "next_state: [100, 17, 18, 9, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17  18   9   0]]\n",
      "rewardsum:  221.0\n",
      "Time Slot: 68\n",
      "Rnd\n",
      "actionVec: [39, 64, 67, 56, 100]\n",
      "next_state: [100, 17, 18, 11, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17  18  11   0]]\n",
      "rewardsum:  224.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 20, 17, 2, 0]\n",
      "Reward: 9.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 20 17  2  0]]\n",
      "rewardsum:  233.0\n",
      "Time Slot: 70\n",
      "Rnd\n",
      "actionVec: [25, 54, 35, 97, 100]\n",
      "next_state: [100, 24, 16, 7, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  16   7   0]]\n",
      "rewardsum:  234.0\n",
      "Time Slot: 71\n",
      "Rnd\n",
      "actionVec: [41, 11, 20, 47, 100]\n",
      "next_state: [100, 21, 15, 9, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  15   9   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 20, 16, 0, 0]\n",
      "Reward: 9.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 20 16  0  0]]\n",
      "rewardsum:  247.0\n",
      "Time Slot: 73\n",
      "Rnd\n",
      "actionVec: [93, 84, 92, 86, 100]\n",
      "next_state: [100, 18, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18  16   0   0]]\n",
      "rewardsum:  250.0\n",
      "Time Slot: 74\n",
      "Rnd\n",
      "actionVec: [93, 62, 55, 43, 100]\n",
      "next_state: [100, 14, 18, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14  18   1   0]]\n",
      "rewardsum:  254.0\n",
      "Time Slot: 75\n",
      "Rnd\n",
      "actionVec: [2, 48, 85, 20, 100]\n",
      "next_state: [100, 25, 17, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  17   0   0]]\n",
      "rewardsum:  255.0\n",
      "Time Slot: 76\n",
      "Rnd\n",
      "actionVec: [98, 38, 32, 11, 100]\n",
      "next_state: [98, 23, 18, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 23 18  0  0]]\n",
      "rewardsum:  259.0\n",
      "Time Slot: 77\n",
      "Rnd\n",
      "actionVec: [41, 42, 20, 93, 100]\n",
      "next_state: [100, 22, 13, 7, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22  13   7   0]]\n",
      "rewardsum:  261.0\n",
      "Time Slot: 78\n",
      "Rnd\n",
      "actionVec: [75, 65, 56, 5, 100]\n",
      "next_state: [94, 20, 13, 0, 0]\n",
      "Reward: 9.0\n",
      "----------------- \n",
      "\n",
      "state:  [[94 20 13  0  0]]\n",
      "rewardsum:  270.0\n",
      "Time Slot: 79\n",
      "Rnd\n",
      "actionVec: [92, 63, 96, 49, 100]\n",
      "next_state: [97, 19, 12, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 19 12  1  0]]\n",
      "rewardsum:  274.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 14, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 14 13  0  0]]\n",
      "rewardsum:  278.0\n",
      "Time Slot: 81\n",
      "Rnd\n",
      "actionVec: [20, 71, 41, 69, 100]\n",
      "next_state: [100, 17, 10, 2, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17  10   2   0]]\n",
      "rewardsum:  282.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 19, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19  12   0   0]]\n",
      "rewardsum:  286.0\n",
      "Time Slot: 83\n",
      "Rnd\n",
      "actionVec: [46, 98, 42, 24, 100]\n",
      "next_state: [100, 21, 8, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21   8   0   0]]\n",
      "rewardsum:  291.0\n",
      "Time Slot: 84\n",
      "Rnd\n",
      "actionVec: [56, 66, 26, 45, 100]\n",
      "next_state: [100, 24, 2, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   2   1   0]]\n",
      "rewardsum:  296.0\n",
      "Time Slot: 85\n",
      "Rnd\n",
      "actionVec: [11, 14, 13, 43, 100]\n",
      "next_state: [100, 20, 3, 5, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   3   5   0]]\n",
      "rewardsum:  298.0\n",
      "Time Slot: 86\n",
      "Rnd\n",
      "actionVec: [17, 50, 62, 71, 100]\n",
      "next_state: [99, 22, 2, 6, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 22  2  6  0]]\n",
      "rewardsum:  300.0\n",
      "Time Slot: 87\n",
      "Rnd\n",
      "actionVec: [94, 45, 40, 15, 100]\n",
      "next_state: [85, 17, 3, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[85 17  3  0  0]]\n",
      "rewardsum:  308.0\n",
      "Time Slot: 88\n",
      "Rnd\n",
      "actionVec: [11, 57, 74, 63, 100]\n",
      "next_state: [100, 20, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   3   0   0]]\n",
      "rewardsum:  311.0\n",
      "Time Slot: 89\n",
      "Rnd\n",
      "actionVec: [49, 53, 26, 48, 100]\n",
      "next_state: [100, 22, 0, 4, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   0   4   0]]\n",
      "rewardsum:  313.0\n",
      "Time Slot: 90\n",
      "Rnd\n",
      "actionVec: [41, 45, 40, 75, 100]\n",
      "next_state: [74, 20, 1, 3, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[74 20  1  3  0]]\n",
      "rewardsum:  317.0\n",
      "Time Slot: 91\n",
      "Rnd\n",
      "actionVec: [91, 13, 61, 98, 100]\n",
      "next_state: [100, 13, 6, 6, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13   6   6   0]]\n",
      "rewardsum:  319.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 17, 5, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   5   0   0]]\n",
      "rewardsum:  326.0\n",
      "Time Slot: 93\n",
      "Rnd\n",
      "actionVec: [27, 89, 98, 7, 100]\n",
      "next_state: [100, 22, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   4   0   0]]\n",
      "rewardsum:  330.0\n",
      "Time Slot: 94\n",
      "Rnd\n",
      "actionVec: [88, 46, 95, 81, 100]\n",
      "next_state: [100, 17, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17  10   0   0]]\n",
      "rewardsum:  332.0\n",
      "Time Slot: 95\n",
      "Rnd\n",
      "actionVec: [8, 55, 26, 89, 100]\n",
      "next_state: [100, 26, 9, 3, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   9   3   0]]\n",
      "rewardsum:  332.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  10   0   0]]\n",
      "rewardsum:  336.0\n",
      "Time Slot: 97\n",
      "Rnd\n",
      "actionVec: [94, 63, 98, 91, 100]\n",
      "next_state: [100, 28, 14, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  14   1   0]]\n",
      "rewardsum:  338.0\n",
      "Time Slot: 98\n",
      "Rnd\n",
      "actionVec: [91, 11, 66, 85, 100]\n",
      "next_state: [97, 18, 22, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 18 22  2  0]]\n",
      "rewardsum:  340.0\n",
      "Time Slot: 99\n",
      "Rnd\n",
      "actionVec: [46, 9, 4, 12, 100]\n",
      "next_state: [100, 11, 21, 10, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11  21  10   0]]\n",
      "rewardsum:  340.0\n",
      "Episode: 2\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  6043\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Rnd\n",
      "actionVec: [99, 33, 73, 58, 100]\n",
      "next_state: [94, 1, 1, 3, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[94  1  1  3  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Rnd\n",
      "actionVec: [22, 21, 46, 32, 100]\n",
      "next_state: [100, 0, 2, 3, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0   2   3   0]]\n",
      "rewardsum:  4.0\n",
      "Time Slot: 2\n",
      "Rnd\n",
      "actionVec: [2, 29, 47, 23, 100]\n",
      "next_state: [100, 12, 2, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12   2   1   0]]\n",
      "rewardsum:  7.0\n",
      "Time Slot: 3\n",
      "Rnd\n",
      "actionVec: [82, 41, 46, 39, 100]\n",
      "next_state: [100, 10, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10   3   0   0]]\n",
      "rewardsum:  11.0\n",
      "Time Slot: 4\n",
      "Rnd\n",
      "actionVec: [42, 50, 43, 8, 100]\n",
      "next_state: [100, 11, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11   4   0   0]]\n",
      "rewardsum:  14.0\n",
      "Time Slot: 5\n",
      "Rnd\n",
      "actionVec: [5, 80, 82, 17, 100]\n",
      "next_state: [100, 22, 5, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  22   5   1   0]]\n",
      "rewardsum:  15.0\n",
      "Time Slot: 6\n",
      "Rnd\n",
      "actionVec: [25, 56, 88, 3, 100]\n",
      "next_state: [100, 29, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   4   0   0]]\n",
      "rewardsum:  18.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 33, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 33  2  0  0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 8\n",
      "Rnd\n",
      "actionVec: [84, 25, 48, 98, 100]\n",
      "next_state: [100, 30, 3, 6, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   3   6   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 9\n",
      "Rnd\n",
      "actionVec: [46, 87, 16, 69, 100]\n",
      "next_state: [100, 32, 1, 6, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   1   6   0]]\n",
      "rewardsum:  27.0\n",
      "Time Slot: 10\n",
      "Rnd\n",
      "actionVec: [88, 1, 27, 63, 100]\n",
      "next_state: [41, 19, 10, 7, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[41 19 10  7  0]]\n",
      "rewardsum:  28.0\n",
      "Time Slot: 11\n",
      "Rnd\n",
      "actionVec: [60, 46, 72, 3, 100]\n",
      "next_state: [99, 18, 14, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 18 14  0  0]]\n",
      "rewardsum:  36.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 19, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19  15   0   0]]\n",
      "rewardsum:  38.0\n",
      "Time Slot: 13\n",
      "Rnd\n",
      "actionVec: [41, 97, 41, 62, 100]\n",
      "next_state: [100, 20, 12, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20  12   2   0]]\n",
      "rewardsum:  40.0\n",
      "Time Slot: 14\n",
      "Rnd\n",
      "actionVec: [59, 62, 78, 55, 100]\n",
      "next_state: [100, 21, 11, 2, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  11   2   0]]\n",
      "rewardsum:  45.0\n",
      "Time Slot: 15\n",
      "Rnd\n",
      "actionVec: [51, 10, 2, 96, 100]\n",
      "next_state: [92, 18, 6, 9, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[92 18  6  9  0]]\n",
      "rewardsum:  46.0\n",
      "Time Slot: 16\n",
      "Rnd\n",
      "actionVec: [53, 98, 82, 47, 100]\n",
      "next_state: [100, 22, 5, 11, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   5  11   0]]\n",
      "rewardsum:  49.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 19, 4, 0, 0]\n",
      "Reward: 12.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   4   0   0]]\n",
      "rewardsum:  61.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   4   0   0]]\n",
      "rewardsum:  64.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   2   0   0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 20\n",
      "Rnd\n",
      "actionVec: [78, 44, 47, 90, 100]\n",
      "next_state: [100, 22, 3, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   3   1   0]]\n",
      "rewardsum:  71.0\n",
      "Time Slot: 21\n",
      "Rnd\n",
      "actionVec: [29, 45, 3, 32, 100]\n",
      "next_state: [100, 23, 0, 7, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   0   7   0]]\n",
      "rewardsum:  72.0\n",
      "Time Slot: 22\n",
      "Rnd\n",
      "actionVec: [23, 99, 23, 83, 100]\n",
      "next_state: [100, 28, 1, 6, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   1   6   0]]\n",
      "rewardsum:  75.0\n",
      "Time Slot: 23\n",
      "Rnd\n",
      "actionVec: [65, 96, 59, 94, 100]\n",
      "next_state: [99, 27, 0, 4, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 27  0  4  0]]\n",
      "rewardsum:  80.0\n",
      "Time Slot: 24\n",
      "Rnd\n",
      "actionVec: [73, 79, 52, 90, 100]\n",
      "next_state: [100, 25, 0, 3, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   0   3   0]]\n",
      "rewardsum:  84.0\n",
      "Time Slot: 25\n",
      "Rnd\n",
      "actionVec: [52, 11, 52, 5, 100]\n",
      "next_state: [100, 16, 6, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   6   1   0]]\n",
      "rewardsum:  89.0\n",
      "Time Slot: 26\n",
      "Rnd\n",
      "actionVec: [84, 83, 94, 79, 100]\n",
      "next_state: [99, 17, 4, 2, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 17  4  2  0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 27\n",
      "Rnd\n",
      "actionVec: [84, 64, 5, 29, 100]\n",
      "next_state: [95, 17, 0, 7, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 17  0  7  0]]\n",
      "rewardsum:  95.0\n",
      "Time Slot: 28\n",
      "Rnd\n",
      "actionVec: [0, 21, 68, 72, 100]\n",
      "next_state: [100, 11, 7, 6, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11   7   6   0]]\n",
      "rewardsum:  98.0\n",
      "Time Slot: 29\n",
      "Rnd\n",
      "actionVec: [66, 78, 2, 61, 100]\n",
      "next_state: [100, 11, 0, 12, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11   0  12   0]]\n",
      "rewardsum:  101.0\n",
      "Time Slot: 30\n",
      "Rnd\n",
      "actionVec: [24, 78, 62, 41, 100]\n",
      "next_state: [100, 17, 2, 8, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   2   8   0]]\n",
      "rewardsum:  105.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [39, 18, 1, 1, 0]\n",
      "Reward: 10.0\n",
      "----------------- \n",
      "\n",
      "state:  [[39 18  1  1  0]]\n",
      "rewardsum:  115.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   2   0   0]]\n",
      "rewardsum:  119.0\n",
      "Time Slot: 33\n",
      "Rnd\n",
      "actionVec: [57, 66, 17, 56, 100]\n",
      "next_state: [99, 22, 0, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 22  0  1  0]]\n",
      "rewardsum:  123.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   0   0   0]]\n",
      "rewardsum:  127.0\n",
      "Time Slot: 35\n",
      "Rnd\n",
      "actionVec: [57, 20, 89, 8, 100]\n",
      "next_state: [97, 20, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 20  4  0  0]]\n",
      "rewardsum:  130.0\n",
      "Time Slot: 36\n",
      "Rnd\n",
      "actionVec: [54, 85, 69, 90, 100]\n",
      "next_state: [100, 23, 3, 3, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   3   3   0]]\n",
      "rewardsum:  131.0\n",
      "Time Slot: 37\n",
      "Rnd\n",
      "actionVec: [65, 32, 68, 60, 100]\n",
      "next_state: [97, 19, 6, 2, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 19  6  2  0]]\n",
      "rewardsum:  135.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 8, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   8   1   0]]\n",
      "rewardsum:  140.0\n",
      "Time Slot: 39\n",
      "Rnd\n",
      "actionVec: [12, 21, 74, 0, 100]\n",
      "next_state: [100, 23, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  10   0   0]]\n",
      "rewardsum:  142.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  10   0   0]]\n",
      "rewardsum:  144.0\n",
      "Time Slot: 41\n",
      "Rnd\n",
      "actionVec: [30, 66, 55, 6, 100]\n",
      "next_state: [100, 29, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  10   0   0]]\n",
      "rewardsum:  148.0\n",
      "Time Slot: 42\n",
      "Rnd\n",
      "actionVec: [84, 45, 59, 64, 100]\n",
      "next_state: [100, 27, 9, 3, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   9   3   0]]\n",
      "rewardsum:  151.0\n",
      "Time Slot: 43\n",
      "Rnd\n",
      "actionVec: [42, 67, 40, 86, 100]\n",
      "next_state: [100, 29, 7, 4, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   7   4   0]]\n",
      "rewardsum:  154.0\n",
      "Time Slot: 44\n",
      "Rnd\n",
      "actionVec: [51, 75, 26, 48, 100]\n",
      "next_state: [100, 26, 2, 10, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   2  10   0]]\n",
      "rewardsum:  155.0\n",
      "Time Slot: 45\n",
      "Rnd\n",
      "actionVec: [57, 6, 44, 96, 100]\n",
      "next_state: [96, 17, 9, 13, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 17  9 13  0]]\n",
      "rewardsum:  156.0\n",
      "Time Slot: 46\n",
      "Rnd\n",
      "actionVec: [47, 40, 77, 48, 100]\n",
      "next_state: [100, 15, 9, 12, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15   9  12   0]]\n",
      "rewardsum:  161.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 15, 10, 0, 0]\n",
      "Reward: 11.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 15 10  0  0]]\n",
      "rewardsum:  172.0\n",
      "Time Slot: 48\n",
      "Rnd\n",
      "actionVec: [12, 50, 32, 91, 100]\n",
      "next_state: [100, 20, 7, 5, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   7   5   0]]\n",
      "rewardsum:  173.0\n",
      "Time Slot: 49\n",
      "Rnd\n",
      "actionVec: [58, 57, 90, 10, 100]\n",
      "next_state: [100, 18, 8, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   8   0   0]]\n",
      "rewardsum:  180.0\n",
      "Time Slot: 50\n",
      "Rnd\n",
      "actionVec: [83, 0, 65, 57, 100]\n",
      "next_state: [100, 17, 10, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17  10   1   0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 8, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21   8   0   0]]\n",
      "rewardsum:  187.0\n",
      "Time Slot: 52\n",
      "Rnd\n",
      "actionVec: [43, 33, 69, 67, 100]\n",
      "next_state: [100, 20, 13, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20  13   1   0]]\n",
      "rewardsum:  188.0\n",
      "Time Slot: 53\n",
      "Rnd\n",
      "actionVec: [16, 29, 70, 85, 100]\n",
      "next_state: [100, 24, 18, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  18   0   0]]\n",
      "rewardsum:  189.0\n",
      "Time Slot: 54\n",
      "Rnd\n",
      "actionVec: [5, 67, 99, 49, 100]\n",
      "next_state: [100, 35, 18, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  18   1   0]]\n",
      "rewardsum:  190.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 19, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  19   0   0]]\n",
      "rewardsum:  193.0\n",
      "Time Slot: 56\n",
      "Rnd\n",
      "actionVec: [32, 26, 72, 71, 100]\n",
      "next_state: [100, 35, 23, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  23   0   0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 57\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 23, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  23   0   0]]\n",
      "rewardsum:  198.0\n",
      "Time Slot: 58\n",
      "Rnd\n",
      "actionVec: [45, 62, 70, 76, 100]\n",
      "next_state: [100, 32, 21, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  21   0   0]]\n",
      "rewardsum:  203.0\n",
      "Time Slot: 59\n",
      "Rnd\n",
      "actionVec: [7, 57, 56, 23, 100]\n",
      "next_state: [100, 31, 17, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  17   1   0]]\n",
      "rewardsum:  205.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 16, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  16   0   0]]\n",
      "rewardsum:  209.0\n",
      "Time Slot: 61\n",
      "Rnd\n",
      "actionVec: [28, 52, 16, 52, 100]\n",
      "next_state: [97, 27, 12, 6, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 27 12  6  0]]\n",
      "rewardsum:  211.0\n",
      "Time Slot: 62\n",
      "Rnd\n",
      "actionVec: [0, 61, 65, 50, 100]\n",
      "next_state: [100, 31, 11, 5, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  11   5   0]]\n",
      "rewardsum:  215.0\n",
      "Time Slot: 63\n",
      "Rnd\n",
      "actionVec: [57, 69, 92, 16, 100]\n",
      "next_state: [100, 31, 8, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   8   0   0]]\n",
      "rewardsum:  223.0\n",
      "Time Slot: 64\n",
      "Rnd\n",
      "actionVec: [52, 93, 5, 15, 100]\n",
      "next_state: [86, 20, 0, 5, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[86 20  0  5  0]]\n",
      "rewardsum:  227.0\n",
      "Time Slot: 65\n",
      "Rnd\n",
      "actionVec: [91, 94, 32, 48, 100]\n",
      "next_state: [100, 20, 0, 1, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   0   1   0]]\n",
      "rewardsum:  234.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 0, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   0   1   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21   0   0   0]]\n",
      "rewardsum:  241.0\n",
      "Time Slot: 68\n",
      "Rnd\n",
      "actionVec: [47, 57, 95, 88, 100]\n",
      "next_state: [100, 22, 3, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   3   1   0]]\n",
      "rewardsum:  243.0\n",
      "Time Slot: 69\n",
      "Rnd\n",
      "actionVec: [53, 88, 16, 77, 100]\n",
      "next_state: [100, 25, 0, 4, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   0   4   0]]\n",
      "rewardsum:  245.0\n",
      "Time Slot: 70\n",
      "Rnd\n",
      "actionVec: [61, 47, 95, 29, 100]\n",
      "next_state: [100, 25, 2, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   2   0   0]]\n",
      "rewardsum:  251.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   2   0   0]]\n",
      "rewardsum:  254.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   2   0   0]]\n",
      "rewardsum:  258.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 0, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   0   1   0]]\n",
      "rewardsum:  261.0\n",
      "Time Slot: 74\n",
      "Rnd\n",
      "actionVec: [38, 5, 39, 71, 100]\n",
      "next_state: [97, 18, 8, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 18  8  2  0]]\n",
      "rewardsum:  262.0\n",
      "Time Slot: 75\n",
      "Rnd\n",
      "actionVec: [97, 42, 43, 91, 100]\n",
      "next_state: [97, 15, 9, 4, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 15  9  4  0]]\n",
      "rewardsum:  264.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 17, 8, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   8   0   0]]\n",
      "rewardsum:  272.0\n",
      "Time Slot: 77\n",
      "Rnd\n",
      "actionVec: [24, 30, 39, 36, 100]\n",
      "next_state: [97, 11, 11, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 11 11  1  0]]\n",
      "rewardsum:  275.0\n",
      "Time Slot: 78\n",
      "Rnd\n",
      "actionVec: [54, 12, 2, 22, 100]\n",
      "next_state: [92, 8, 6, 8, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[92  8  6  8  0]]\n",
      "rewardsum:  275.0\n",
      "Time Slot: 79\n",
      "Rnd\n",
      "actionVec: [35, 43, 79, 78, 100]\n",
      "next_state: [100, 6, 8, 12, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   6   8  12   0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 80\n",
      "Rnd\n",
      "actionVec: [32, 14, 77, 12, 100]\n",
      "next_state: [100, 6, 14, 6, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   6  14   6   0]]\n",
      "rewardsum:  282.0\n",
      "Time Slot: 81\n",
      "Rnd\n",
      "actionVec: [67, 66, 12, 88, 100]\n",
      "next_state: [100, 7, 2, 16, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   7   2  16   0]]\n",
      "rewardsum:  283.0\n",
      "Time Slot: 82\n",
      "Rnd\n",
      "actionVec: [35, 92, 24, 49, 100]\n",
      "next_state: [99, 9, 0, 18, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99  9  0 18  0]]\n",
      "rewardsum:  287.0\n",
      "Time Slot: 83\n",
      "Rnd\n",
      "actionVec: [95, 70, 26, 42, 100]\n",
      "next_state: [100, 10, 0, 11, 0]\n",
      "Reward: 9.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10   0  11   0]]\n",
      "rewardsum:  296.0\n",
      "Time Slot: 84\n",
      "Rnd\n",
      "actionVec: [75, 0, 33, 43, 100]\n",
      "next_state: [100, 13, 1, 8, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13   1   8   0]]\n",
      "rewardsum:  301.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 14, 1, 0, 0]\n",
      "Reward: 10.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   1   0   0]]\n",
      "rewardsum:  311.0\n",
      "Time Slot: 86\n",
      "Rnd\n",
      "actionVec: [66, 87, 27, 39, 100]\n",
      "next_state: [100, 16, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   0   0   0]]\n",
      "rewardsum:  315.0\n",
      "Time Slot: 87\n",
      "Rnd\n",
      "actionVec: [94, 63, 99, 8, 100]\n",
      "next_state: [100, 13, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13   4   0   0]]\n",
      "rewardsum:  317.0\n",
      "Time Slot: 88\n",
      "Rnd\n",
      "actionVec: [80, 38, 98, 3, 100]\n",
      "next_state: [100, 8, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   8  11   0   0]]\n",
      "rewardsum:  319.0\n",
      "Time Slot: 89\n",
      "Rnd\n",
      "actionVec: [21, 6, 69, 80, 100]\n",
      "next_state: [100, 0, 19, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0  19   2   0]]\n",
      "rewardsum:  320.0\n",
      "Time Slot: 90\n",
      "Rnd\n",
      "actionVec: [52, 23, 18, 24, 100]\n",
      "next_state: [90, 0, 17, 3, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[90  0 17  3  0]]\n",
      "rewardsum:  324.0\n",
      "Time Slot: 91\n",
      "Rnd\n",
      "actionVec: [11, 25, 87, 40, 100]\n",
      "next_state: [100, 4, 19, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   4  19   2   0]]\n",
      "rewardsum:  326.0\n",
      "Time Slot: 92\n",
      "Rnd\n",
      "actionVec: [5, 86, 54, 5, 100]\n",
      "next_state: [100, 14, 19, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14  19   0   0]]\n",
      "rewardsum:  330.0\n",
      "Time Slot: 93\n",
      "Rnd\n",
      "actionVec: [10, 39, 90, 58, 100]\n",
      "next_state: [100, 24, 18, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  18   1   0]]\n",
      "rewardsum:  331.0\n",
      "Time Slot: 94\n",
      "Rnd\n",
      "actionVec: [42, 96, 30, 40, 100]\n",
      "next_state: [100, 27, 10, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  10   1   0]]\n",
      "rewardsum:  336.0\n",
      "Time Slot: 95\n",
      "Rnd\n",
      "actionVec: [49, 84, 13, 84, 100]\n",
      "next_state: [100, 28, 5, 6, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   5   6   0]]\n",
      "rewardsum:  338.0\n",
      "Time Slot: 96\n",
      "Rnd\n",
      "actionVec: [26, 15, 24, 2, 100]\n",
      "next_state: [100, 26, 7, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   7   0   0]]\n",
      "rewardsum:  346.0\n",
      "Time Slot: 97\n",
      "Rnd\n",
      "actionVec: [66, 70, 2, 95, 100]\n",
      "next_state: [52, 21, 0, 9, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[52 21  0  9  0]]\n",
      "rewardsum:  347.0\n",
      "Time Slot: 98\n",
      "Rnd\n",
      "actionVec: [18, 26, 1, 18, 100]\n",
      "next_state: [100, 17, 0, 13, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   0  13   0]]\n",
      "rewardsum:  348.0\n",
      "Time Slot: 99\n",
      "Rnd\n",
      "actionVec: [31, 96, 27, 6, 100]\n",
      "next_state: [100, 16, 0, 1, 0]\n",
      "Reward: 12.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   0   1   0]]\n",
      "rewardsum:  360.0\n",
      "Episode: 3\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  6020\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [86, 8, 1, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[86  8  1  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 12, 5, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12   5   0   0]]\n",
      "rewardsum:  1.0\n",
      "Time Slot: 2\n",
      "Rnd\n",
      "actionVec: [76, 15, 24, 65, 100]\n",
      "next_state: [100, 6, 7, 5, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   6   7   5   0]]\n",
      "rewardsum:  2.0\n",
      "Time Slot: 3\n",
      "Rnd\n",
      "actionVec: [60, 97, 96, 74, 100]\n",
      "next_state: [100, 6, 7, 4, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   6   7   4   0]]\n",
      "rewardsum:  7.0\n",
      "Time Slot: 4\n",
      "Rnd\n",
      "actionVec: [60, 76, 35, 10, 100]\n",
      "next_state: [100, 7, 8, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   7   8   0   0]]\n",
      "rewardsum:  13.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [78, 11, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[78 11  5  0  0]]\n",
      "rewardsum:  17.0\n",
      "Time Slot: 6\n",
      "Rnd\n",
      "actionVec: [41, 80, 30, 47, 100]\n",
      "next_state: [100, 12, 1, 2, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12   1   2   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 7\n",
      "Rnd\n",
      "actionVec: [69, 59, 3, 29, 100]\n",
      "next_state: [100, 11, 0, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11   0   0   0]]\n",
      "rewardsum:  28.0\n",
      "Time Slot: 8\n",
      "Rnd\n",
      "actionVec: [66, 66, 74, 44, 100]\n",
      "next_state: [100, 9, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   9   1   0   0]]\n",
      "rewardsum:  32.0\n",
      "Time Slot: 9\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 12, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12   2   0   0]]\n",
      "rewardsum:  35.0\n",
      "Time Slot: 10\n",
      "Rnd\n",
      "actionVec: [3, 40, 40, 2, 100]\n",
      "next_state: [100, 19, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   2   0   0]]\n",
      "rewardsum:  37.0\n",
      "Time Slot: 11\n",
      "Rnd\n",
      "actionVec: [15, 31, 56, 38, 100]\n",
      "next_state: [100, 24, 4, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   4   1   0]]\n",
      "rewardsum:  38.0\n",
      "Time Slot: 12\n",
      "Rnd\n",
      "actionVec: [66, 66, 56, 98, 100]\n",
      "next_state: [100, 26, 3, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   3   2   0]]\n",
      "rewardsum:  41.0\n",
      "Time Slot: 13\n",
      "Rnd\n",
      "actionVec: [62, 86, 91, 30, 100]\n",
      "next_state: [100, 28, 3, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   3   2   0]]\n",
      "rewardsum:  44.0\n",
      "Time Slot: 14\n",
      "Rnd\n",
      "actionVec: [39, 39, 66, 11, 100]\n",
      "next_state: [100, 28, 2, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   2   0   0]]\n",
      "rewardsum:  51.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   1   0   0]]\n",
      "rewardsum:  53.0\n",
      "Time Slot: 16\n",
      "Rnd\n",
      "actionVec: [80, 21, 86, 57, 100]\n",
      "next_state: [98, 26, 4, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 26  4  1  0]]\n",
      "rewardsum:  55.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   6   0   0]]\n",
      "rewardsum:  59.0\n",
      "Time Slot: 18\n",
      "Rnd\n",
      "actionVec: [18, 10, 22, 35, 100]\n",
      "next_state: [100, 21, 7, 5, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21   7   5   0]]\n",
      "rewardsum:  60.0\n",
      "Time Slot: 19\n",
      "Rnd\n",
      "actionVec: [25, 68, 95, 40, 100]\n",
      "next_state: [100, 24, 8, 5, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   8   5   0]]\n",
      "rewardsum:  63.0\n",
      "Time Slot: 20\n",
      "Rnd\n",
      "actionVec: [89, 65, 68, 46, 100]\n",
      "next_state: [100, 19, 14, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19  14   1   0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 21\n",
      "Rnd\n",
      "actionVec: [90, 30, 89, 30, 100]\n",
      "next_state: [91, 15, 19, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[91 15 19  0  0]]\n",
      "rewardsum:  71.0\n",
      "Time Slot: 22\n",
      "Rnd\n",
      "actionVec: [5, 91, 14, 89, 100]\n",
      "next_state: [100, 24, 17, 3, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  17   3   0]]\n",
      "rewardsum:  72.0\n",
      "Time Slot: 23\n",
      "Rnd\n",
      "actionVec: [20, 15, 11, 44, 100]\n",
      "next_state: [100, 21, 17, 3, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  17   3   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 24\n",
      "Rnd\n",
      "actionVec: [53, 10, 70, 76, 100]\n",
      "next_state: [100, 18, 24, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18  24   2   0]]\n",
      "rewardsum:  78.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 23, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  23   0   0]]\n",
      "rewardsum:  81.0\n",
      "Time Slot: 26\n",
      "Rnd\n",
      "actionVec: [83, 42, 44, 85, 100]\n",
      "next_state: [100, 19, 23, 4, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19  23   4   0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 27\n",
      "Rnd\n",
      "actionVec: [90, 72, 48, 39, 100]\n",
      "next_state: [98, 19, 21, 6, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 19 21  6  0]]\n",
      "rewardsum:  86.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 19, 0, 0]\n",
      "Reward: 9.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  19   0   0]]\n",
      "rewardsum:  95.0\n",
      "Time Slot: 29\n",
      "Rnd\n",
      "actionVec: [68, 23, 68, 58, 100]\n",
      "next_state: [100, 14, 24, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14  24   1   0]]\n",
      "rewardsum:  96.0\n",
      "Time Slot: 30\n",
      "Rnd\n",
      "actionVec: [78, 81, 44, 10, 100]\n",
      "next_state: [71, 14, 22, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[71 14 22  1  0]]\n",
      "rewardsum:  100.0\n",
      "Time Slot: 31\n",
      "Rnd\n",
      "actionVec: [37, 80, 13, 98, 100]\n",
      "next_state: [100, 14, 11, 13, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14  11  13   0]]\n",
      "rewardsum:  101.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [95, 13, 11, 0, 0]\n",
      "Reward: 13.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 13 11  0  0]]\n",
      "rewardsum:  114.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 19, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19  11   0   0]]\n",
      "rewardsum:  117.0\n",
      "Time Slot: 34\n",
      "Rnd\n",
      "actionVec: [7, 32, 79, 30, 100]\n",
      "next_state: [100, 27, 11, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  11   0   0]]\n",
      "rewardsum:  118.0\n",
      "Time Slot: 35\n",
      "Rnd\n",
      "actionVec: [2, 21, 27, 68, 100]\n",
      "next_state: [100, 37, 8, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   8   0   0]]\n",
      "rewardsum:  119.0\n",
      "Time Slot: 36\n",
      "Rnd\n",
      "actionVec: [16, 8, 9, 67, 100]\n",
      "next_state: [100, 35, 7, 6, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   7   6   0]]\n",
      "rewardsum:  119.0\n",
      "Time Slot: 37\n",
      "Rnd\n",
      "actionVec: [24, 69, 57, 63, 100]\n",
      "next_state: [100, 39, 6, 8, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   6   8   0]]\n",
      "rewardsum:  121.0\n",
      "Time Slot: 38\n",
      "Rnd\n",
      "actionVec: [73, 34, 37, 43, 100]\n",
      "next_state: [98, 38, 6, 8, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 38  6  8  0]]\n",
      "rewardsum:  124.0\n",
      "Time Slot: 39\n",
      "Rnd\n",
      "actionVec: [5, 87, 65, 43, 100]\n",
      "next_state: [100, 38, 7, 9, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   7   9   0]]\n",
      "rewardsum:  126.0\n",
      "Time Slot: 40\n",
      "Rnd\n",
      "actionVec: [2, 78, 70, 5, 100]\n",
      "next_state: [100, 38, 7, 7, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   7   7   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 41\n",
      "Rnd\n",
      "actionVec: [25, 17, 74, 55, 100]\n",
      "next_state: [100, 34, 14, 5, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  14   5   0]]\n",
      "rewardsum:  131.0\n",
      "Time Slot: 42\n",
      "Rnd\n",
      "actionVec: [15, 41, 52, 34, 100]\n",
      "next_state: [100, 39, 17, 3, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  17   3   0]]\n",
      "rewardsum:  134.0\n",
      "Time Slot: 43\n",
      "Rnd\n",
      "actionVec: [66, 99, 32, 94, 100]\n",
      "next_state: [100, 38, 12, 8, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  12   8   0]]\n",
      "rewardsum:  137.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 9, 3, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  9  3  0]]\n",
      "rewardsum:  144.0\n",
      "Time Slot: 45\n",
      "Rnd\n",
      "actionVec: [20, 45, 24, 36, 100]\n",
      "next_state: [100, 22, 11, 2, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22  11   2   0]]\n",
      "rewardsum:  149.0\n",
      "Time Slot: 46\n",
      "Rnd\n",
      "actionVec: [87, 89, 46, 99, 100]\n",
      "next_state: [94, 23, 7, 5, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[94 23  7  5  0]]\n",
      "rewardsum:  152.0\n",
      "Time Slot: 47\n",
      "Rnd\n",
      "actionVec: [4, 81, 54, 60, 100]\n",
      "next_state: [100, 25, 6, 4, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   6   4   0]]\n",
      "rewardsum:  155.0\n",
      "Time Slot: 48\n",
      "Rnd\n",
      "actionVec: [55, 2, 8, 14, 100]\n",
      "next_state: [97, 24, 2, 4, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 24  2  4  0]]\n",
      "rewardsum:  161.0\n",
      "Time Slot: 49\n",
      "Rnd\n",
      "actionVec: [71, 37, 99, 91, 100]\n",
      "next_state: [97, 21, 4, 3, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 21  4  3  0]]\n",
      "rewardsum:  165.0\n",
      "Time Slot: 50\n",
      "Rnd\n",
      "actionVec: [15, 26, 51, 3, 100]\n",
      "next_state: [99, 21, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 21  8  0  0]]\n",
      "rewardsum:  169.0\n",
      "Time Slot: 51\n",
      "Rnd\n",
      "actionVec: [59, 89, 17, 61, 100]\n",
      "next_state: [100, 22, 0, 8, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   0   8   0]]\n",
      "rewardsum:  171.0\n",
      "Time Slot: 52\n",
      "Rnd\n",
      "actionVec: [89, 57, 86, 56, 100]\n",
      "next_state: [100, 19, 4, 7, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   4   7   0]]\n",
      "rewardsum:  174.0\n",
      "Time Slot: 53\n",
      "Rnd\n",
      "actionVec: [39, 30, 65, 33, 100]\n",
      "next_state: [100, 16, 7, 4, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   7   4   0]]\n",
      "rewardsum:  179.0\n",
      "Time Slot: 54\n",
      "Rnd\n",
      "actionVec: [67, 92, 13, 93, 100]\n",
      "next_state: [100, 17, 0, 11, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   0  11   0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 55\n",
      "Rnd\n",
      "actionVec: [28, 27, 53, 37, 100]\n",
      "next_state: [100, 16, 2, 9, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   2   9   0]]\n",
      "rewardsum:  186.0\n",
      "Time Slot: 56\n",
      "Rnd\n",
      "actionVec: [28, 50, 40, 0, 100]\n",
      "next_state: [67, 19, 1, 7, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[67 19  1  7  0]]\n",
      "rewardsum:  192.0\n",
      "Time Slot: 57\n",
      "Rnd\n",
      "actionVec: [30, 1, 15, 18, 100]\n",
      "next_state: [94, 5, 14, 7, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[94  5 14  7  0]]\n",
      "rewardsum:  193.0\n",
      "Time Slot: 58\n",
      "Rnd\n",
      "actionVec: [83, 0, 12, 29, 100]\n",
      "next_state: [96, 0, 11, 13, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96  0 11 13  0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 59\n",
      "Rnd\n",
      "actionVec: [61, 43, 73, 15, 100]\n",
      "next_state: [100, 0, 10, 5, 0]\n",
      "Reward: 11.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0  10   5   0]]\n",
      "rewardsum:  206.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 1, 9, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   1   9   0   0]]\n",
      "rewardsum:  214.0\n",
      "Time Slot: 61\n",
      "Rnd\n",
      "actionVec: [73, 97, 96, 90, 100]\n",
      "next_state: [100, 2, 9, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   2   9   1   0]]\n",
      "rewardsum:  217.0\n",
      "Time Slot: 62\n",
      "Rnd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [57, 18, 43, 90, 100]\n",
      "next_state: [100, 0, 13, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0  13   2   0]]\n",
      "rewardsum:  219.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 2, 13, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   2  13   0   0]]\n",
      "rewardsum:  224.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 4, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   4  14   0   0]]\n",
      "rewardsum:  227.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 7, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   7  15   0   0]]\n",
      "rewardsum:  230.0\n",
      "Time Slot: 66\n",
      "Rnd\n",
      "actionVec: [52, 1, 6, 19, 100]\n",
      "next_state: [100, 0, 21, 3, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0  21   3   0]]\n",
      "rewardsum:  230.0\n",
      "Time Slot: 67\n",
      "Rnd\n",
      "actionVec: [16, 35, 14, 54, 100]\n",
      "next_state: [100, 0, 17, 10, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0  17  10   0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 68\n",
      "Rnd\n",
      "actionVec: [1, 75, 27, 43, 100]\n",
      "next_state: [100, 15, 17, 10, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15  17  10   0]]\n",
      "rewardsum:  232.0\n",
      "Time Slot: 69\n",
      "Rnd\n",
      "actionVec: [36, 44, 24, 87, 100]\n",
      "next_state: [100, 16, 13, 17, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16  13  17   0]]\n",
      "rewardsum:  232.0\n",
      "Time Slot: 70\n",
      "Rnd\n",
      "actionVec: [86, 34, 78, 93, 100]\n",
      "next_state: [90, 12, 18, 14, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[90 12 18 14  0]]\n",
      "rewardsum:  236.0\n",
      "Time Slot: 71\n",
      "Rnd\n",
      "actionVec: [0, 44, 3, 98, 100]\n",
      "next_state: [100, 11, 7, 25, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11   7  25   0]]\n",
      "rewardsum:  237.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 14, 7, 18, 0]\n",
      "Reward: 9.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 14  7 18  0]]\n",
      "rewardsum:  246.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [92, 13, 5, 9, 0]\n",
      "Reward: 12.0\n",
      "----------------- \n",
      "\n",
      "state:  [[92 13  5  9  0]]\n",
      "rewardsum:  258.0\n",
      "Time Slot: 74\n",
      "Rnd\n",
      "actionVec: [32, 55, 93, 70, 100]\n",
      "next_state: [100, 12, 7, 7, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12   7   7   0]]\n",
      "rewardsum:  262.0\n",
      "Time Slot: 75\n",
      "Rnd\n",
      "actionVec: [45, 37, 26, 38, 100]\n",
      "next_state: [100, 12, 6, 7, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12   6   7   0]]\n",
      "rewardsum:  267.0\n",
      "Time Slot: 76\n",
      "Rnd\n",
      "actionVec: [16, 29, 22, 64, 100]\n",
      "next_state: [100, 14, 4, 12, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   4  12   0]]\n",
      "rewardsum:  268.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 16, 5, 2, 0]\n",
      "Reward: 10.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   5   2   0]]\n",
      "rewardsum:  278.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 3, 2, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   3   2   0]]\n",
      "rewardsum:  283.0\n",
      "Time Slot: 79\n",
      "Rnd\n",
      "actionVec: [66, 20, 6, 37, 100]\n",
      "next_state: [98, 18, 0, 4, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 18  0  4  0]]\n",
      "rewardsum:  287.0\n",
      "Time Slot: 80\n",
      "Rnd\n",
      "actionVec: [41, 27, 56, 64, 100]\n",
      "next_state: [100, 17, 4, 4, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   4   4   0]]\n",
      "rewardsum:  289.0\n",
      "Time Slot: 81\n",
      "Rnd\n",
      "actionVec: [13, 24, 58, 37, 100]\n",
      "next_state: [100, 20, 4, 3, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   4   3   0]]\n",
      "rewardsum:  293.0\n",
      "Time Slot: 82\n",
      "Rnd\n",
      "actionVec: [28, 54, 54, 53, 100]\n",
      "next_state: [100, 21, 5, 3, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21   5   3   0]]\n",
      "rewardsum:  295.0\n",
      "Time Slot: 83\n",
      "Rnd\n",
      "actionVec: [78, 14, 32, 18, 100]\n",
      "next_state: [96, 19, 6, 1, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 19  6  1  0]]\n",
      "rewardsum:  301.0\n",
      "Time Slot: 84\n",
      "Rnd\n",
      "actionVec: [50, 93, 64, 83, 100]\n",
      "next_state: [100, 19, 3, 2, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   3   2   0]]\n",
      "rewardsum:  306.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   4   0   0]]\n",
      "rewardsum:  310.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   7   0   0]]\n",
      "rewardsum:  312.0\n",
      "Time Slot: 87\n",
      "Rnd\n",
      "actionVec: [71, 71, 68, 38, 100]\n",
      "next_state: [54, 23, 7, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[54 23  7  2  0]]\n",
      "rewardsum:  314.0\n",
      "Time Slot: 88\n",
      "Rnd\n",
      "actionVec: [89, 60, 72, 90, 100]\n",
      "next_state: [100, 19, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19  11   0   0]]\n",
      "rewardsum:  318.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  11   0   0]]\n",
      "rewardsum:  322.0\n",
      "Time Slot: 90\n",
      "Rnd\n",
      "actionVec: [46, 64, 21, 39, 100]\n",
      "next_state: [97, 24, 8, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 24  8  1  0]]\n",
      "rewardsum:  326.0\n",
      "Time Slot: 91\n",
      "Rnd\n",
      "actionVec: [34, 60, 20, 44, 100]\n",
      "next_state: [100, 23, 0, 8, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   0   8   0]]\n",
      "rewardsum:  327.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 1, 0, 0]\n",
      "Reward: 10.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   1   0   0]]\n",
      "rewardsum:  337.0\n",
      "Time Slot: 93\n",
      "Rnd\n",
      "actionVec: [11, 85, 0, 94, 100]\n",
      "next_state: [100, 27, 2, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   2   1   0]]\n",
      "rewardsum:  338.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 26, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 26  5  0  0]]\n",
      "rewardsum:  341.0\n",
      "Time Slot: 95\n",
      "Rnd\n",
      "actionVec: [21, 38, 52, 51, 100]\n",
      "next_state: [100, 32, 8, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   8   1   0]]\n",
      "rewardsum:  341.0\n",
      "Time Slot: 96\n",
      "Rnd\n",
      "actionVec: [46, 10, 95, 15, 100]\n",
      "next_state: [98, 26, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 26 15  0  0]]\n",
      "rewardsum:  344.0\n",
      "Time Slot: 97\n",
      "Rnd\n",
      "actionVec: [84, 29, 86, 38, 100]\n",
      "next_state: [100, 24, 20, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  20   1   0]]\n",
      "rewardsum:  345.0\n",
      "Time Slot: 98\n",
      "Rnd\n",
      "actionVec: [86, 63, 29, 80, 100]\n",
      "next_state: [98, 21, 18, 3, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 21 18  3  0]]\n",
      "rewardsum:  349.0\n",
      "Time Slot: 99\n",
      "Rnd\n",
      "actionVec: [5, 75, 21, 3, 100]\n",
      "next_state: [100, 31, 17, 6, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  17   6   0]]\n",
      "rewardsum:  349.0\n",
      "Episode: 4\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  6635\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Rnd\n",
      "actionVec: [14, 0, 60, 36, 100]\n",
      "next_state: [85, 4, 2, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[85  4  2  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Rnd\n",
      "actionVec: [14, 48, 58, 0, 100]\n",
      "next_state: [100, 9, 3, 0, 1]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   9   3   0   1]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 12, 2, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12   2   0   0]]\n",
      "rewardsum:  5.0\n",
      "Time Slot: 3\n",
      "Rnd\n",
      "actionVec: [28, 59, 67, 64, 100]\n",
      "next_state: [100, 15, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15   3   0   0]]\n",
      "rewardsum:  8.0\n",
      "Time Slot: 4\n",
      "Rnd\n",
      "actionVec: [90, 43, 90, 91, 100]\n",
      "next_state: [100, 10, 8, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10   8   2   0]]\n",
      "rewardsum:  9.0\n",
      "Time Slot: 5\n",
      "Rnd\n",
      "actionVec: [74, 60, 77, 21, 100]\n",
      "next_state: [96, 13, 7, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 13  7  1  0]]\n",
      "rewardsum:  14.0\n",
      "Time Slot: 6\n",
      "Rnd\n",
      "actionVec: [74, 94, 64, 39, 100]\n",
      "next_state: [100, 13, 7, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13   7   1   0]]\n",
      "rewardsum:  18.0\n",
      "Time Slot: 7\n",
      "Rnd\n",
      "actionVec: [44, 27, 52, 34, 100]\n",
      "next_state: [100, 12, 6, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12   6   1   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 16, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   5   0   0]]\n",
      "rewardsum:  26.0\n",
      "Time Slot: 9\n",
      "Rnd\n",
      "actionVec: [27, 65, 94, 34, 100]\n",
      "next_state: [100, 21, 8, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21   8   1   0]]\n",
      "rewardsum:  27.0\n",
      "Time Slot: 10\n",
      "Rnd\n",
      "actionVec: [33, 97, 13, 40, 100]\n",
      "next_state: [100, 23, 1, 7, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   1   7   0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 11\n",
      "Rnd\n",
      "actionVec: [90, 72, 4, 50, 100]\n",
      "next_state: [100, 22, 0, 6, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   0   6   0]]\n",
      "rewardsum:  35.0\n",
      "Time Slot: 12\n",
      "Rnd\n",
      "actionVec: [66, 64, 7, 32, 100]\n",
      "next_state: [100, 20, 1, 4, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   1   4   0]]\n",
      "rewardsum:  41.0\n",
      "Time Slot: 13\n",
      "Rnd\n",
      "actionVec: [29, 63, 4, 84, 100]\n",
      "next_state: [100, 25, 0, 6, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   0   6   0]]\n",
      "rewardsum:  43.0\n",
      "Time Slot: 14\n",
      "Rnd\n",
      "actionVec: [85, 89, 35, 72, 100]\n",
      "next_state: [96, 18, 0, 6, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[96 18  0  6  0]]\n",
      "rewardsum:  47.0\n",
      "Time Slot: 15\n",
      "Rnd\n",
      "actionVec: [71, 15, 23, 94, 100]\n",
      "next_state: [52, 13, 3, 9, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[52 13  3  9  0]]\n",
      "rewardsum:  48.0\n",
      "Time Slot: 16\n",
      "Rnd\n",
      "actionVec: [51, 16, 67, 89, 100]\n",
      "next_state: [100, 6, 11, 9, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   6  11   9   0]]\n",
      "rewardsum:  50.0\n",
      "Time Slot: 17\n",
      "Rnd\n",
      "actionVec: [52, 86, 90, 13, 100]\n",
      "next_state: [99, 6, 11, 3, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99  6 11  3  0]]\n",
      "rewardsum:  58.0\n",
      "Time Slot: 18\n",
      "Rnd\n",
      "actionVec: [88, 58, 52, 2, 100]\n",
      "next_state: [97, 2, 11, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97  2 11  0  0]]\n",
      "rewardsum:  66.0\n",
      "Time Slot: 19\n",
      "Rnd\n",
      "actionVec: [85, 31, 14, 67, 100]\n",
      "next_state: [100, 0, 7, 6, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0   7   6   0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 20\n",
      "Rnd\n",
      "actionVec: [51, 39, 3, 56, 100]\n",
      "next_state: [100, 2, 0, 14, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   2   0  14   0]]\n",
      "rewardsum:  69.0\n",
      "Time Slot: 21\n",
      "Rnd\n",
      "actionVec: [14, 54, 91, 90, 100]\n",
      "next_state: [100, 6, 3, 14, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   6   3  14   0]]\n",
      "rewardsum:  71.0\n",
      "Time Slot: 22\n",
      "Rnd\n",
      "actionVec: [10, 96, 55, 4, 100]\n",
      "next_state: [99, 6, 3, 0, 0]\n",
      "Reward: 14.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99  6  3  0  0]]\n",
      "rewardsum:  85.0\n",
      "Time Slot: 23\n",
      "Rnd\n",
      "actionVec: [25, 59, 22, 20, 100]\n",
      "next_state: [100, 10, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10   0   0   0]]\n",
      "rewardsum:  89.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 15, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15   0   0   0]]\n",
      "rewardsum:  92.0\n",
      "Time Slot: 25\n",
      "Rnd\n",
      "actionVec: [15, 34, 17, 81, 100]\n",
      "next_state: [100, 22, 0, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   0   2   0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 26\n",
      "Rnd\n",
      "actionVec: [40, 56, 59, 19, 100]\n",
      "next_state: [99, 22, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 22  3  0  0]]\n",
      "rewardsum:  97.0\n",
      "Time Slot: 27\n",
      "Rnd\n",
      "actionVec: [65, 10, 68, 8, 100]\n",
      "next_state: [100, 11, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11  13   0   0]]\n",
      "rewardsum:  99.0\n",
      "Time Slot: 28\n",
      "Rnd\n",
      "actionVec: [2, 17, 11, 38, 100]\n",
      "next_state: [100, 22, 16, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22  16   0   0]]\n",
      "rewardsum:  99.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 16, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  16   0   0]]\n",
      "rewardsum:  101.0\n",
      "Time Slot: 30\n",
      "Rnd\n",
      "actionVec: [8, 88, 88, 24, 100]\n",
      "next_state: [100, 39, 16, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  16   0   0]]\n",
      "rewardsum:  103.0\n",
      "Time Slot: 31\n",
      "Rnd\n",
      "actionVec: [29, 98, 40, 31, 100]\n",
      "next_state: [100, 43, 14, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43  14   2   0]]\n",
      "rewardsum:  105.0\n",
      "Time Slot: 32\n",
      "Rnd\n",
      "actionVec: [10, 13, 23, 17, 100]\n",
      "next_state: [100, 51, 9, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  51   9   0   0]]\n",
      "rewardsum:  110.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 43, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 43  8  0  0]]\n",
      "rewardsum:  113.0\n",
      "Time Slot: 34\n",
      "Rnd\n",
      "actionVec: [7, 1, 32, 95, 100]\n",
      "next_state: [92, 26, 24, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[92 26 24  0  0]]\n",
      "rewardsum:  113.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 26, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  26   0   0]]\n",
      "rewardsum:  115.0\n",
      "Time Slot: 36\n",
      "Rnd\n",
      "actionVec: [9, 76, 0, 73, 100]\n",
      "next_state: [100, 34, 25, 2, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  25   2   0]]\n",
      "rewardsum:  115.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 25, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  25   0   0]]\n",
      "rewardsum:  119.0\n",
      "Time Slot: 38\n",
      "Rnd\n",
      "actionVec: [8, 7, 14, 65, 100]\n",
      "next_state: [100, 33, 18, 8, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  18   8   0]]\n",
      "rewardsum:  119.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 11, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  11   0   0]]\n",
      "rewardsum:  127.0\n",
      "Time Slot: 40\n",
      "Rnd\n",
      "actionVec: [26, 63, 88, 42, 100]\n",
      "next_state: [100, 36, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  10   0   0]]\n",
      "rewardsum:  131.0\n",
      "Time Slot: 41\n",
      "Rnd\n",
      "actionVec: [16, 7, 20, 25, 100]\n",
      "next_state: [85, 31, 12, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[85 31 12  2  0]]\n",
      "rewardsum:  132.0\n",
      "Time Slot: 42\n",
      "Rnd\n",
      "actionVec: [44, 17, 36, 51, 100]\n",
      "next_state: [98, 25, 16, 3, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 25 16  3  0]]\n",
      "rewardsum:  133.0\n",
      "Time Slot: 43\n",
      "Rnd\n",
      "actionVec: [28, 44, 41, 10, 100]\n",
      "next_state: [100, 23, 15, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  15   0   0]]\n",
      "rewardsum:  140.0\n",
      "Time Slot: 44\n",
      "Rnd\n",
      "actionVec: [58, 57, 29, 7, 100]\n",
      "next_state: [98, 19, 12, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 19 12  0  0]]\n",
      "rewardsum:  146.0\n",
      "Time Slot: 45\n",
      "Rnd\n",
      "actionVec: [62, 11, 14, 52, 100]\n",
      "next_state: [94, 13, 15, 4, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[94 13 15  4  0]]\n",
      "rewardsum:  147.0\n",
      "Time Slot: 46\n",
      "Rnd\n",
      "actionVec: [41, 54, 37, 36, 100]\n",
      "next_state: [100, 12, 14, 4, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12  14   4   0]]\n",
      "rewardsum:  151.0\n",
      "Time Slot: 47\n",
      "Rnd\n",
      "actionVec: [20, 66, 96, 18, 100]\n",
      "next_state: [100, 13, 14, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13  14   0   0]]\n",
      "rewardsum:  158.0\n",
      "Time Slot: 48\n",
      "Rnd\n",
      "actionVec: [11, 81, 2, 33, 100]\n",
      "next_state: [98, 13, 2, 12, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 13  2 12  0]]\n",
      "rewardsum:  159.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 12, 1, 0, 0]\n",
      "Reward: 13.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12   1   0   0]]\n",
      "rewardsum:  172.0\n",
      "Time Slot: 50\n",
      "Rnd\n",
      "actionVec: [39, 94, 29, 29, 100]\n",
      "next_state: [100, 17, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   0   0   0]]\n",
      "rewardsum:  176.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   1   0   0]]\n",
      "rewardsum:  178.0\n",
      "Time Slot: 52\n",
      "Rnd\n",
      "actionVec: [41, 62, 17, 73, 100]\n",
      "next_state: [100, 23, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   0   0   0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 2, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   2   1   0]]\n",
      "rewardsum:  183.0\n",
      "Time Slot: 54\n",
      "Rnd\n",
      "actionVec: [1, 60, 92, 23, 100]\n",
      "next_state: [100, 39, 2, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   2   0   0]]\n",
      "rewardsum:  184.0\n",
      "Time Slot: 55\n",
      "Rnd\n",
      "actionVec: [7, 74, 3, 6, 100]\n",
      "next_state: [100, 44, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  44   0   0   0]]\n",
      "rewardsum:  187.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   1   0   0]]\n",
      "rewardsum:  190.0\n",
      "Time Slot: 57\n",
      "Rnd\n",
      "actionVec: [27, 70, 47, 94, 100]\n",
      "next_state: [100, 43, 5, 2, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43   5   2   0]]\n",
      "rewardsum:  190.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 44, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  44   4   0   0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   3   0   0]]\n",
      "rewardsum:  199.0\n",
      "Time Slot: 60\n",
      "Rnd\n",
      "actionVec: [46, 36, 47, 62, 100]\n",
      "next_state: [100, 30, 0, 3, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   0   3   0]]\n",
      "rewardsum:  202.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 27, 1, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 27  1  0  0]]\n",
      "rewardsum:  208.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 26, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 26  1  0  0]]\n",
      "rewardsum:  211.0\n",
      "Time Slot: 63\n",
      "Rnd\n",
      "actionVec: [47, 10, 55, 57, 100]\n",
      "next_state: [93, 16, 8, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[93 16  8  2  0]]\n",
      "rewardsum:  212.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 20, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 20  9  0  0]]\n",
      "rewardsum:  215.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   8   0   0]]\n",
      "rewardsum:  219.0\n",
      "Time Slot: 66\n",
      "Rnd\n",
      "actionVec: [10, 72, 91, 94, 100]\n",
      "next_state: [100, 32, 11, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  11   0   0]]\n",
      "rewardsum:  220.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  31   9   0   0]]\n",
      "rewardsum:  224.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   9   0   0]]\n",
      "rewardsum:  227.0\n",
      "Time Slot: 69\n",
      "Rnd\n",
      "actionVec: [88, 2, 18, 63, 100]\n",
      "next_state: [95, 18, 25, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 18 25  0  0]]\n",
      "rewardsum:  227.0\n",
      "Time Slot: 70\n",
      "Rnd\n",
      "actionVec: [16, 56, 47, 20, 100]\n",
      "next_state: [100, 17, 27, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17  27   0   0]]\n",
      "rewardsum:  230.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 22, 24, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 22 24  0  0]]\n",
      "rewardsum:  234.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 26, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  26   0   0]]\n",
      "rewardsum:  236.0\n",
      "Time Slot: 73\n",
      "Rnd\n",
      "actionVec: [68, 95, 79, 87, 100]\n",
      "next_state: [100, 24, 27, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  27   1   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 18, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  18   0   0]]\n",
      "rewardsum:  244.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 14, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  14   0   0]]\n",
      "rewardsum:  248.0\n",
      "Time Slot: 76\n",
      "Rnd\n",
      "actionVec: [88, 40, 20, 63, 100]\n",
      "next_state: [69, 24, 6, 9, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[69 24  6  9  0]]\n",
      "rewardsum:  248.0\n",
      "Time Slot: 77\n",
      "Rnd\n",
      "actionVec: [26, 87, 85, 54, 100]\n",
      "next_state: [100, 24, 6, 12, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   6  12   0]]\n",
      "rewardsum:  250.0\n",
      "Time Slot: 78\n",
      "Rnd\n",
      "actionVec: [36, 81, 26, 17, 100]\n",
      "next_state: [100, 21, 3, 7, 0]\n",
      "Reward: 9.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21   3   7   0]]\n",
      "rewardsum:  259.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 3, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   3   0   0]]\n",
      "rewardsum:  267.0\n",
      "Time Slot: 80\n",
      "Rnd\n",
      "actionVec: [91, 91, 5, 1, 100]\n",
      "next_state: [100, 19, 0, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   0   0   0]]\n",
      "rewardsum:  273.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   1   0   0]]\n",
      "rewardsum:  275.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   0   0   0]]\n",
      "rewardsum:  278.0\n",
      "Time Slot: 83\n",
      "Rnd\n",
      "actionVec: [73, 3, 77, 25, 100]\n",
      "next_state: [96, 12, 15, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 12 15  0  0]]\n",
      "rewardsum:  278.0\n",
      "Time Slot: 84\n",
      "Rnd\n",
      "actionVec: [81, 80, 63, 26, 100]\n",
      "next_state: [100, 13, 14, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13  14   0   0]]\n",
      "rewardsum:  282.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 17, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 17 13  0  0]]\n",
      "rewardsum:  285.0\n",
      "Time Slot: 86\n",
      "Rnd\n",
      "actionVec: [74, 13, 26, 31, 100]\n",
      "next_state: [99, 10, 17, 3, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 10 17  3  0]]\n",
      "rewardsum:  287.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [87, 13, 18, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[87 13 18  0  0]]\n",
      "rewardsum:  292.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 17, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20  17   0   0]]\n",
      "rewardsum:  294.0\n",
      "Time Slot: 89\n",
      "Rnd\n",
      "actionVec: [15, 73, 3, 2, 100]\n",
      "next_state: [92, 21, 11, 1, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[92 21 11  1  0]]\n",
      "rewardsum:  300.0\n",
      "Time Slot: 90\n",
      "Rnd\n",
      "actionVec: [95, 94, 12, 67, 100]\n",
      "next_state: [100, 21, 4, 8, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21   4   8   0]]\n",
      "rewardsum:  302.0\n",
      "Time Slot: 91\n",
      "Rnd\n",
      "actionVec: [7, 20, 52, 48, 100]\n",
      "next_state: [100, 29, 4, 8, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   4   8   0]]\n",
      "rewardsum:  304.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 5, 0, 0]\n",
      "Reward: 10.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   5   0   0]]\n",
      "rewardsum:  314.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   5   0   0]]\n",
      "rewardsum:  317.0\n",
      "Time Slot: 94\n",
      "Rnd\n",
      "actionVec: [79, 5, 62, 25, 100]\n",
      "next_state: [100, 11, 17, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11  17   0   0]]\n",
      "rewardsum:  318.0\n",
      "Time Slot: 95\n",
      "Rnd\n",
      "actionVec: [72, 65, 47, 18, 100]\n",
      "next_state: [100, 12, 15, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12  15   0   0]]\n",
      "rewardsum:  323.0\n",
      "Time Slot: 96\n",
      "Rnd\n",
      "actionVec: [59, 29, 75, 93, 100]\n",
      "next_state: [100, 10, 18, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10  18   0   0]]\n",
      "rewardsum:  326.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 16, 19, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 16 19  0  0]]\n",
      "rewardsum:  328.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 19, 22, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19  22   0   0]]\n",
      "rewardsum:  330.0\n",
      "Time Slot: 99\n",
      "Rnd\n",
      "actionVec: [24, 21, 21, 31, 100]\n",
      "next_state: [100, 20, 21, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20  21   1   0]]\n",
      "rewardsum:  331.0\n",
      "Episode: 5\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  7397\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [82, 7, 1, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[82  7  1  1  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Rnd\n",
      "actionVec: [65, 96, 18, 82, 100]\n",
      "next_state: [100, 7, 0, 4, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   7   0   4   0]]\n",
      "rewardsum:  2.0\n",
      "Time Slot: 2\n",
      "Rnd\n",
      "actionVec: [20, 77, 21, 48, 100]\n",
      "next_state: [100, 15, 0, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15   0   2   0]]\n",
      "rewardsum:  5.0\n",
      "Time Slot: 3\n",
      "Rnd\n",
      "actionVec: [45, 80, 8, 5, 100]\n",
      "next_state: [100, 17, 0, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   0   0   0]]\n",
      "rewardsum:  11.0\n",
      "Time Slot: 4\n",
      "Rnd\n",
      "actionVec: [98, 89, 41, 93, 100]\n",
      "next_state: [100, 17, 0, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   0   1   0]]\n",
      "rewardsum:  14.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   0   0   0]]\n",
      "rewardsum:  17.0\n",
      "Time Slot: 6\n",
      "Rnd\n",
      "actionVec: [95, 35, 88, 91, 100]\n",
      "next_state: [100, 24, 0, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   0   1   0]]\n",
      "rewardsum:  20.0\n",
      "Time Slot: 7\n",
      "Rnd\n",
      "actionVec: [8, 60, 94, 0, 100]\n",
      "next_state: [100, 28, 3, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   3   2   0]]\n",
      "rewardsum:  21.0\n",
      "Time Slot: 8\n",
      "Rnd\n",
      "actionVec: [43, 59, 88, 53, 100]\n",
      "next_state: [100, 31, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   6   0   0]]\n",
      "rewardsum:  24.0\n",
      "Time Slot: 9\n",
      "Rnd\n",
      "actionVec: [54, 40, 92, 13, 100]\n",
      "next_state: [100, 29, 9, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   9   1   0]]\n",
      "rewardsum:  27.0\n",
      "Time Slot: 10\n",
      "Rnd\n",
      "actionVec: [89, 90, 18, 74, 100]\n",
      "next_state: [51, 27, 4, 5, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[51 27  4  5  0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 5, 3, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   5   3   0]]\n",
      "rewardsum:  33.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 3, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   3   0   0]]\n",
      "rewardsum:  40.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   3   0   0]]\n",
      "rewardsum:  43.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   4   0   0]]\n",
      "rewardsum:  46.0\n",
      "Time Slot: 15\n",
      "Rnd\n",
      "actionVec: [19, 8, 80, 35, 100]\n",
      "next_state: [100, 21, 11, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  11   1   0]]\n",
      "rewardsum:  47.0\n",
      "Time Slot: 16\n",
      "Rnd\n",
      "actionVec: [53, 67, 69, 92, 100]\n",
      "next_state: [100, 20, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20  15   0   0]]\n",
      "rewardsum:  49.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  17   0   0]]\n",
      "rewardsum:  52.0\n",
      "Time Slot: 18\n",
      "Rnd\n",
      "actionVec: [80, 46, 39, 89, 100]\n",
      "next_state: [100, 21, 14, 2, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  14   2   0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 19\n",
      "Rnd\n",
      "actionVec: [90, 12, 87, 50, 100]\n",
      "next_state: [100, 11, 24, 3, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11  24   3   0]]\n",
      "rewardsum:  57.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 10, 26, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10  26   0   0]]\n",
      "rewardsum:  63.0\n",
      "Time Slot: 21\n",
      "Rnd\n",
      "actionVec: [8, 12, 60, 94, 100]\n",
      "next_state: [100, 20, 25, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  20  25   1   0]]\n",
      "rewardsum:  63.0\n",
      "Time Slot: 22\n",
      "Rnd\n",
      "actionVec: [32, 66, 12, 98, 100]\n",
      "next_state: [99, 23, 20, 5, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 23 20  5  0]]\n",
      "rewardsum:  65.0\n",
      "Time Slot: 23\n",
      "Rnd\n",
      "actionVec: [80, 37, 32, 76, 100]\n",
      "next_state: [100, 26, 16, 10, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  16  10   0]]\n",
      "rewardsum:  67.0\n",
      "Time Slot: 24\n",
      "Rnd\n",
      "actionVec: [19, 9, 28, 82, 100]\n",
      "next_state: [97, 21, 17, 13, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 21 17 13  0]]\n",
      "rewardsum:  69.0\n",
      "Time Slot: 25\n",
      "Rnd\n",
      "actionVec: [88, 15, 24, 22, 100]\n",
      "next_state: [91, 16, 18, 12, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[91 16 18 12  0]]\n",
      "rewardsum:  74.0\n",
      "Time Slot: 26\n",
      "Rnd\n",
      "actionVec: [82, 99, 94, 56, 100]\n",
      "next_state: [100, 15, 17, 9, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15  17   9   0]]\n",
      "rewardsum:  81.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 12, 19, 0, 0]\n",
      "Reward: 10.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12  19   0   0]]\n",
      "rewardsum:  91.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 15, 18, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15  18   0   0]]\n",
      "rewardsum:  94.0\n",
      "Time Slot: 29\n",
      "Rnd\n",
      "actionVec: [33, 75, 0, 56, 100]\n",
      "next_state: [100, 15, 20, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15  20   0   0]]\n",
      "rewardsum:  97.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 18, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20  18   0   0]]\n",
      "rewardsum:  99.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 17, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  17   0   0]]\n",
      "rewardsum:  101.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  15   0   0]]\n",
      "rewardsum:  104.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 13, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  13   1   0]]\n",
      "rewardsum:  107.0\n",
      "Time Slot: 34\n",
      "Rnd\n",
      "actionVec: [73, 61, 20, 85, 100]\n",
      "next_state: [99, 36, 11, 4, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 36 11  4  0]]\n",
      "rewardsum:  109.0\n",
      "Time Slot: 35\n",
      "Rnd\n",
      "actionVec: [85, 34, 11, 39, 100]\n",
      "next_state: [97, 30, 2, 13, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 30  2 13  0]]\n",
      "rewardsum:  111.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [85, 22, 4, 1, 0]\n",
      "Reward: 12.0\n",
      "----------------- \n",
      "\n",
      "state:  [[85 22  4  1  0]]\n",
      "rewardsum:  123.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 19, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   4   0   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 38\n",
      "Rnd\n",
      "actionVec: [1, 61, 57, 73, 100]\n",
      "next_state: [100, 30, 4, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   4   0   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 39\n",
      "Rnd\n",
      "actionVec: [35, 78, 14, 89, 100]\n",
      "next_state: [100, 31, 0, 4, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   0   4   0]]\n",
      "rewardsum:  129.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 2, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   0   0]]\n",
      "rewardsum:  135.0\n",
      "Time Slot: 41\n",
      "Rnd\n",
      "actionVec: [10, 3, 20, 22, 100]\n",
      "next_state: [100, 39, 5, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   5   0   0]]\n",
      "rewardsum:  136.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 40, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 40  3  0  0]]\n",
      "rewardsum:  140.0\n",
      "Time Slot: 43\n",
      "Rnd\n",
      "actionVec: [23, 35, 18, 62, 100]\n",
      "next_state: [100, 32, 0, 4, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   0   4   0]]\n",
      "rewardsum:  142.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 1, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   1   0   0]]\n",
      "rewardsum:  148.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   3   0   0]]\n",
      "rewardsum:  151.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   4   0   0]]\n",
      "rewardsum:  154.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 5, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   5   0   0]]\n",
      "rewardsum:  155.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 35, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 35  4  0  0]]\n",
      "rewardsum:  158.0\n",
      "Time Slot: 49\n",
      "Rnd\n",
      "actionVec: [1, 55, 64, 24, 100]\n",
      "next_state: [100, 42, 5, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   5   0   0]]\n",
      "rewardsum:  159.0\n",
      "Time Slot: 50\n",
      "Rnd\n",
      "actionVec: [34, 34, 57, 81, 100]\n",
      "next_state: [100, 39, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  10   0   0]]\n",
      "rewardsum:  161.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 44, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  44  10   0   0]]\n",
      "rewardsum:  164.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   8   0   0]]\n",
      "rewardsum:  167.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   9   0   0]]\n",
      "rewardsum:  169.0\n",
      "Time Slot: 54\n",
      "Rnd\n",
      "actionVec: [66, 44, 26, 32, 100]\n",
      "next_state: [99, 34, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34  8  0  0]]\n",
      "rewardsum:  172.0\n",
      "Time Slot: 55\n",
      "Rnd\n",
      "actionVec: [25, 92, 85, 27, 100]\n",
      "next_state: [100, 39, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   9   0   0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   9   0   0]]\n",
      "rewardsum:  179.0\n",
      "Time Slot: 57\n",
      "Rnd\n",
      "actionVec: [24, 9, 70, 64, 100]\n",
      "next_state: [96, 28, 18, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 28 18  0  0]]\n",
      "rewardsum:  179.0\n",
      "Time Slot: 58\n",
      "Rnd\n",
      "actionVec: [36, 30, 70, 99, 100]\n",
      "next_state: [97, 29, 21, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 29 21  1  0]]\n",
      "rewardsum:  181.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 30, 23, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 30 23  0  0]]\n",
      "rewardsum:  184.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 23, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  23   0   0]]\n",
      "rewardsum:  187.0\n",
      "Time Slot: 61\n",
      "Rnd\n",
      "actionVec: [44, 62, 60, 12, 100]\n",
      "next_state: [71, 29, 23, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[71 29 23  0  0]]\n",
      "rewardsum:  190.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 18, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  18   0   0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 16, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  16   2   0]]\n",
      "rewardsum:  197.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 18, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  18   0   0]]\n",
      "rewardsum:  200.0\n",
      "Time Slot: 65\n",
      "Rnd\n",
      "actionVec: [20, 8, 88, 79, 100]\n",
      "next_state: [97, 19, 27, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 19 27  1  0]]\n",
      "rewardsum:  200.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 29, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20  29   0   0]]\n",
      "rewardsum:  202.0\n",
      "Time Slot: 67\n",
      "Rnd\n",
      "actionVec: [42, 48, 5, 82, 100]\n",
      "next_state: [90, 21, 17, 13, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[90 21 17 13  0]]\n",
      "rewardsum:  202.0\n",
      "Time Slot: 68\n",
      "Rnd\n",
      "actionVec: [20, 92, 63, 50, 100]\n",
      "next_state: [100, 25, 15, 15, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  15  15   0]]\n",
      "rewardsum:  205.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 14, 10, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  14  10   0]]\n",
      "rewardsum:  211.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 12, 1, 0]\n",
      "Reward: 10.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  12   1   0]]\n",
      "rewardsum:  221.0\n",
      "Time Slot: 71\n",
      "Rnd\n",
      "actionVec: [70, 92, 25, 57, 100]\n",
      "next_state: [100, 21, 3, 6, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21   3   6   0]]\n",
      "rewardsum:  225.0\n",
      "Time Slot: 72\n",
      "Rnd\n",
      "actionVec: [92, 99, 39, 40, 100]\n",
      "next_state: [100, 24, 0, 5, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   0   5   0]]\n",
      "rewardsum:  230.0\n",
      "Time Slot: 73\n",
      "Rnd\n",
      "actionVec: [17, 7, 46, 98, 100]\n",
      "next_state: [96, 18, 7, 6, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 18  7  6  0]]\n",
      "rewardsum:  232.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 16, 4, 1, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   4   1   0]]\n",
      "rewardsum:  240.0\n",
      "Time Slot: 75\n",
      "Rnd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [11, 19, 31, 70, 100]\n",
      "next_state: [100, 18, 7, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   7   2   0]]\n",
      "rewardsum:  241.0\n",
      "Time Slot: 76\n",
      "Rnd\n",
      "actionVec: [19, 67, 78, 94, 100]\n",
      "next_state: [100, 23, 5, 5, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   5   5   0]]\n",
      "rewardsum:  243.0\n",
      "Time Slot: 77\n",
      "Rnd\n",
      "actionVec: [89, 5, 6, 71, 100]\n",
      "next_state: [96, 19, 5, 11, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 19  5 11  0]]\n",
      "rewardsum:  243.0\n",
      "Time Slot: 78\n",
      "Rnd\n",
      "actionVec: [54, 65, 54, 18, 100]\n",
      "next_state: [98, 19, 6, 6, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 19  6  6  0]]\n",
      "rewardsum:  250.0\n",
      "Time Slot: 79\n",
      "Rnd\n",
      "actionVec: [51, 47, 31, 78, 100]\n",
      "next_state: [100, 16, 4, 9, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   4   9   0]]\n",
      "rewardsum:  254.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 16, 6, 0, 0]\n",
      "Reward: 9.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   6   0   0]]\n",
      "rewardsum:  263.0\n",
      "Time Slot: 81\n",
      "Rnd\n",
      "actionVec: [56, 68, 7, 32, 100]\n",
      "next_state: [96, 10, 0, 3, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 10  0  3  0]]\n",
      "rewardsum:  268.0\n",
      "Time Slot: 82\n",
      "Rnd\n",
      "actionVec: [7, 84, 85, 28, 100]\n",
      "next_state: [100, 19, 2, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   2   2   0]]\n",
      "rewardsum:  270.0\n",
      "Time Slot: 83\n",
      "Rnd\n",
      "actionVec: [99, 92, 62, 21, 100]\n",
      "next_state: [100, 20, 0, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   0   0   0]]\n",
      "rewardsum:  276.0\n",
      "Time Slot: 84\n",
      "Rnd\n",
      "actionVec: [33, 16, 31, 98, 100]\n",
      "next_state: [97, 18, 5, 3, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 18  5  3  0]]\n",
      "rewardsum:  276.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 4, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   4   0   0]]\n",
      "rewardsum:  282.0\n",
      "Time Slot: 86\n",
      "Rnd\n",
      "actionVec: [55, 83, 56, 9, 100]\n",
      "next_state: [100, 23, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   0   0   0]]\n",
      "rewardsum:  287.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   1   0   0]]\n",
      "rewardsum:  289.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   2   0   0]]\n",
      "rewardsum:  292.0\n",
      "Time Slot: 89\n",
      "Rnd\n",
      "actionVec: [46, 64, 68, 36, 100]\n",
      "next_state: [100, 30, 3, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   3   1   0]]\n",
      "rewardsum:  294.0\n",
      "Time Slot: 90\n",
      "Rnd\n",
      "actionVec: [21, 79, 30, 23, 100]\n",
      "next_state: [98, 32, 0, 3, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 32  0  3  0]]\n",
      "rewardsum:  297.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  301.0\n",
      "Time Slot: 92\n",
      "Rnd\n",
      "actionVec: [82, 15, 90, 82, 100]\n",
      "next_state: [96, 30, 8, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 30  8  1  0]]\n",
      "rewardsum:  302.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   7   0   0]]\n",
      "rewardsum:  306.0\n",
      "Time Slot: 94\n",
      "Rnd\n",
      "actionVec: [88, 50, 91, 43, 100]\n",
      "next_state: [100, 30, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   9   0   0]]\n",
      "rewardsum:  309.0\n",
      "Time Slot: 95\n",
      "Rnd\n",
      "actionVec: [92, 1, 68, 20, 100]\n",
      "next_state: [86, 14, 24, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[86 14 24  0  0]]\n",
      "rewardsum:  310.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 16, 26, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16  26   0   0]]\n",
      "rewardsum:  312.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 27, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18  27   1   0]]\n",
      "rewardsum:  315.0\n",
      "Time Slot: 98\n",
      "Rnd\n",
      "actionVec: [47, 69, 62, 10, 100]\n",
      "next_state: [99, 20, 26, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 20 26  0  0]]\n",
      "rewardsum:  319.0\n",
      "Time Slot: 99\n",
      "Rnd\n",
      "actionVec: [7, 94, 70, 14, 100]\n",
      "next_state: [100, 28, 25, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  25   0   0]]\n",
      "rewardsum:  322.0\n",
      "Episode: 6\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  6535\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [83, 11, 1, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[83 11  1  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 15, 3, 0, 1]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15   3   0   1]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 2\n",
      "Rnd\n",
      "actionVec: [53, 76, 39, 98, 100]\n",
      "next_state: [100, 19, 0, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   0   2   0]]\n",
      "rewardsum:  3.0\n",
      "Time Slot: 3\n",
      "Rnd\n",
      "actionVec: [14, 80, 86, 70, 100]\n",
      "next_state: [100, 25, 1, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   1   2   0]]\n",
      "rewardsum:  5.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   1   0   0]]\n",
      "rewardsum:  9.0\n",
      "Time Slot: 5\n",
      "Rnd\n",
      "actionVec: [3, 70, 53, 3, 100]\n",
      "next_state: [99, 40, 2, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 40  2  0  0]]\n",
      "rewardsum:  10.0\n",
      "Time Slot: 6\n",
      "Rnd\n",
      "actionVec: [47, 84, 80, 65, 100]\n",
      "next_state: [100, 38, 2, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   2   2   0]]\n",
      "rewardsum:  12.0\n",
      "Time Slot: 7\n",
      "Rnd\n",
      "actionVec: [38, 66, 43, 67, 100]\n",
      "next_state: [100, 38, 1, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   1   1   0]]\n",
      "rewardsum:  16.0\n",
      "Time Slot: 8\n",
      "Rnd\n",
      "actionVec: [10, 70, 66, 7, 100]\n",
      "next_state: [100, 41, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   3   0   0]]\n",
      "rewardsum:  18.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   5   0   0]]\n",
      "rewardsum:  20.0\n",
      "Time Slot: 10\n",
      "Rnd\n",
      "actionVec: [98, 83, 51, 89, 100]\n",
      "next_state: [57, 32, 0, 6, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[57 32  0  6  0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 11\n",
      "Rnd\n",
      "actionVec: [98, 34, 93, 78, 100]\n",
      "next_state: [99, 27, 4, 6, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 27  4  6  0]]\n",
      "rewardsum:  25.0\n",
      "Time Slot: 12\n",
      "Rnd\n",
      "actionVec: [43, 13, 26, 80, 100]\n",
      "next_state: [100, 23, 5, 9, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   5   9   0]]\n",
      "rewardsum:  27.0\n",
      "Time Slot: 13\n",
      "Rnd\n",
      "actionVec: [41, 84, 72, 47, 100]\n",
      "next_state: [98, 19, 6, 9, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 19  6  9  0]]\n",
      "rewardsum:  31.0\n",
      "Time Slot: 14\n",
      "Rnd\n",
      "actionVec: [79, 0, 63, 76, 100]\n",
      "next_state: [96, 13, 3, 12, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 13  3 12  0]]\n",
      "rewardsum:  35.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 14, 5, 3, 0]\n",
      "Reward: 9.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   5   3   0]]\n",
      "rewardsum:  44.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 17, 4, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   4   0   0]]\n",
      "rewardsum:  50.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   3   0   0]]\n",
      "rewardsum:  54.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 2, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   2   1   0]]\n",
      "rewardsum:  58.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   0   0   0]]\n",
      "rewardsum:  63.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   0   0   0]]\n",
      "rewardsum:  66.0\n",
      "Time Slot: 21\n",
      "Rnd\n",
      "actionVec: [45, 69, 58, 93, 100]\n",
      "next_state: [100, 28, 0, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   0   2   0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   0   0   0]]\n",
      "rewardsum:  73.0\n",
      "Time Slot: 23\n",
      "Rnd\n",
      "actionVec: [30, 9, 23, 49, 100]\n",
      "next_state: [99, 17, 10, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 17 10  1  0]]\n",
      "rewardsum:  74.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 9, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   9   0   0]]\n",
      "rewardsum:  79.0\n",
      "Time Slot: 25\n",
      "Rnd\n",
      "actionVec: [52, 96, 55, 54, 100]\n",
      "next_state: [100, 23, 5, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   5   2   0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 26\n",
      "Rnd\n",
      "actionVec: [38, 90, 50, 2, 100]\n",
      "next_state: [99, 21, 6, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 21  6  1  0]]\n",
      "rewardsum:  87.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 1, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  20   1   0   0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   3   0   0]]\n",
      "rewardsum:  95.0\n",
      "Time Slot: 29\n",
      "Rnd\n",
      "actionVec: [96, 32, 42, 59, 100]\n",
      "next_state: [100, 18, 6, 3, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   6   3   0]]\n",
      "rewardsum:  96.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 6, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   6   0   0]]\n",
      "rewardsum:  102.0\n",
      "Time Slot: 31\n",
      "Rnd\n",
      "actionVec: [84, 72, 36, 79, 100]\n",
      "next_state: [99, 22, 2, 2, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 22  2  2  0]]\n",
      "rewardsum:  106.0\n",
      "Time Slot: 32\n",
      "Rnd\n",
      "actionVec: [8, 84, 88, 52, 100]\n",
      "next_state: [100, 30, 3, 3, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   3   3   0]]\n",
      "rewardsum:  107.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 0, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   0   0   0]]\n",
      "rewardsum:  113.0\n",
      "Time Slot: 34\n",
      "Rnd\n",
      "actionVec: [20, 21, 22, 83, 100]\n",
      "next_state: [100, 26, 2, 4, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   2   4   0]]\n",
      "rewardsum:  114.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 2, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   2   0   0]]\n",
      "rewardsum:  120.0\n",
      "Time Slot: 36\n",
      "Rnd\n",
      "actionVec: [97, 66, 23, 77, 100]\n",
      "next_state: [100, 28, 0, 3, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   0   3   0]]\n",
      "rewardsum:  122.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 0, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   0   0   0]]\n",
      "rewardsum:  129.0\n",
      "Time Slot: 38\n",
      "Rnd\n",
      "actionVec: [24, 90, 27, 78, 100]\n",
      "next_state: [100, 24, 0, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   0   2   0]]\n",
      "rewardsum:  130.0\n",
      "Time Slot: 39\n",
      "Rnd\n",
      "actionVec: [68, 19, 57, 68, 100]\n",
      "next_state: [100, 20, 4, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   4   1   0]]\n",
      "rewardsum:  133.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   4   0   0]]\n",
      "rewardsum:  136.0\n",
      "Time Slot: 41\n",
      "Rnd\n",
      "actionVec: [13, 28, 18, 19, 100]\n",
      "next_state: [100, 28, 2, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   2   1   0]]\n",
      "rewardsum:  140.0\n",
      "Time Slot: 42\n",
      "Rnd\n",
      "actionVec: [81, 50, 12, 3, 100]\n",
      "next_state: [97, 26, 0, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 26  0  0  0]]\n",
      "rewardsum:  146.0\n",
      "Time Slot: 43\n",
      "Rnd\n",
      "actionVec: [61, 54, 71, 71, 100]\n",
      "next_state: [98, 22, 1, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 22  1  1  0]]\n",
      "rewardsum:  149.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   1   0   0]]\n",
      "rewardsum:  153.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 5, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   5   0   0]]\n",
      "rewardsum:  154.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   5   0   0]]\n",
      "rewardsum:  158.0\n",
      "Time Slot: 47\n",
      "Rnd\n",
      "actionVec: [64, 36, 59, 40, 100]\n",
      "next_state: [97, 23, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 23  7  0  0]]\n",
      "rewardsum:  161.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   9   0   0]]\n",
      "rewardsum:  163.0\n",
      "Time Slot: 49\n",
      "Rnd\n",
      "actionVec: [28, 66, 43, 0, 100]\n",
      "next_state: [100, 29, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   4   0   0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   4   0   0]]\n",
      "rewardsum:  172.0\n",
      "Time Slot: 51\n",
      "Rnd\n",
      "actionVec: [31, 19, 77, 87, 100]\n",
      "next_state: [40, 23, 8, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[40 23  8  1  0]]\n",
      "rewardsum:  174.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   9   0   0]]\n",
      "rewardsum:  177.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   8   0   0]]\n",
      "rewardsum:  180.0\n",
      "Time Slot: 54\n",
      "Rnd\n",
      "actionVec: [98, 42, 92, 63, 100]\n",
      "next_state: [98, 24, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 24 13  0  0]]\n",
      "rewardsum:  183.0\n",
      "Time Slot: 55\n",
      "Rnd\n",
      "actionVec: [69, 4, 62, 63, 100]\n",
      "next_state: [97, 10, 27, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 10 27  0  0]]\n",
      "rewardsum:  183.0\n",
      "Time Slot: 56\n",
      "Rnd\n",
      "actionVec: [83, 73, 22, 45, 100]\n",
      "next_state: [100, 9, 24, 5, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   9  24   5   0]]\n",
      "rewardsum:  185.0\n",
      "Time Slot: 57\n",
      "Rnd\n",
      "actionVec: [53, 86, 35, 47, 100]\n",
      "next_state: [100, 7, 21, 5, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   7  21   5   0]]\n",
      "rewardsum:  191.0\n",
      "Time Slot: 58\n",
      "Rnd\n",
      "actionVec: [20, 91, 5, 41, 100]\n",
      "next_state: [88, 6, 8, 15, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[88  6  8 15  0]]\n",
      "rewardsum:  194.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 10, 8, 12, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10   8  12   0]]\n",
      "rewardsum:  199.0\n",
      "Time Slot: 60\n",
      "Rnd\n",
      "actionVec: [28, 65, 36, 21, 100]\n",
      "next_state: [100, 10, 9, 8, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10   9   8   0]]\n",
      "rewardsum:  205.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 15, 10, 0, 0]\n",
      "Reward: 9.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15  10   0   0]]\n",
      "rewardsum:  214.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   8   0   0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 63\n",
      "Rnd\n",
      "actionVec: [14, 1, 47, 74, 100]\n",
      "next_state: [100, 3, 22, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   3  22   1   0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 64\n",
      "Rnd\n",
      "actionVec: [58, 24, 6, 76, 100]\n",
      "next_state: [100, 0, 21, 6, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0  21   6   0]]\n",
      "rewardsum:  219.0\n",
      "Time Slot: 65\n",
      "Rnd\n",
      "actionVec: [1, 86, 82, 27, 100]\n",
      "next_state: [100, 14, 19, 9, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14  19   9   0]]\n",
      "rewardsum:  219.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 17, 18, 1, 0]\n",
      "Reward: 9.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17  18   1   0]]\n",
      "rewardsum:  228.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 18, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18  18   0   0]]\n",
      "rewardsum:  233.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  14   0   0]]\n",
      "rewardsum:  236.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22  11   0   0]]\n",
      "rewardsum:  240.0\n",
      "Time Slot: 70\n",
      "Rnd\n",
      "actionVec: [88, 46, 33, 73, 100]\n",
      "next_state: [98, 23, 6, 3, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 23  6  3  0]]\n",
      "rewardsum:  244.0\n",
      "Time Slot: 71\n",
      "Rnd\n",
      "actionVec: [30, 45, 79, 35, 100]\n",
      "next_state: [100, 21, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  10   0   0]]\n",
      "rewardsum:  248.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  13   0   0]]\n",
      "rewardsum:  251.0\n",
      "Time Slot: 73\n",
      "Rnd\n",
      "actionVec: [53, 90, 66, 5, 100]\n",
      "next_state: [100, 23, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  12   0   0]]\n",
      "rewardsum:  255.0\n",
      "Time Slot: 74\n",
      "Rnd\n",
      "actionVec: [10, 16, 44, 91, 100]\n",
      "next_state: [100, 24, 13, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  13   2   0]]\n",
      "rewardsum:  256.0\n",
      "Time Slot: 75\n",
      "Rnd\n",
      "actionVec: [3, 4, 54, 3, 100]\n",
      "next_state: [100, 23, 19, 3, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  19   3   0]]\n",
      "rewardsum:  256.0\n",
      "Time Slot: 76\n",
      "Rnd\n",
      "actionVec: [83, 61, 48, 73, 100]\n",
      "next_state: [100, 26, 18, 4, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  18   4   0]]\n",
      "rewardsum:  259.0\n",
      "Time Slot: 77\n",
      "Rnd\n",
      "actionVec: [68, 24, 6, 29, 100]\n",
      "next_state: [43, 24, 8, 16, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[43 24  8 16  0]]\n",
      "rewardsum:  259.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 22, 6, 6, 0]\n",
      "Reward: 12.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 22  6  6  0]]\n",
      "rewardsum:  271.0\n",
      "Time Slot: 79\n",
      "Rnd\n",
      "actionVec: [17, 63, 39, 30, 100]\n",
      "next_state: [100, 20, 5, 3, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   5   3   0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 5, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  20   5   0   0]]\n",
      "rewardsum:  283.0\n",
      "Time Slot: 81\n",
      "Rnd\n",
      "actionVec: [91, 10, 3, 86, 100]\n",
      "next_state: [95, 13, 0, 10, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 13  0 10  0]]\n",
      "rewardsum:  283.0\n",
      "Time Slot: 82\n",
      "Rnd\n",
      "actionVec: [41, 64, 52, 7, 100]\n",
      "next_state: [100, 12, 1, 0, 0]\n",
      "Reward: 11.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12   1   0   0]]\n",
      "rewardsum:  294.0\n",
      "Time Slot: 83\n",
      "Rnd\n",
      "actionVec: [13, 70, 54, 21, 100]\n",
      "next_state: [100, 17, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   0   0   0]]\n",
      "rewardsum:  297.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 2, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   2   0   0]]\n",
      "rewardsum:  298.0\n",
      "Time Slot: 85\n",
      "Rnd\n",
      "actionVec: [75, 48, 41, 49, 100]\n",
      "next_state: [99, 23, 3, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 23  3  2  0]]\n",
      "rewardsum:  300.0\n",
      "Time Slot: 86\n",
      "Rnd\n",
      "actionVec: [80, 87, 32, 48, 100]\n",
      "next_state: [100, 25, 0, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   0   0   0]]\n",
      "rewardsum:  306.0\n",
      "Time Slot: 87\n",
      "Rnd\n",
      "actionVec: [87, 20, 1, 46, 100]\n",
      "next_state: [98, 21, 0, 2, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 21  0  2  0]]\n",
      "rewardsum:  310.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   0   0   0]]\n",
      "rewardsum:  313.0\n",
      "Time Slot: 89\n",
      "Rnd\n",
      "actionVec: [48, 12, 58, 83, 100]\n",
      "next_state: [98, 22, 6, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 22  6  1  0]]\n",
      "rewardsum:  315.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 26, 9, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 26  9  1  0]]\n",
      "rewardsum:  317.0\n",
      "Time Slot: 91\n",
      "Rnd\n",
      "actionVec: [50, 53, 44, 22, 100]\n",
      "next_state: [100, 28, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   8   0   0]]\n",
      "rewardsum:  321.0\n",
      "Time Slot: 92\n",
      "Rnd\n",
      "actionVec: [49, 16, 60, 51, 100]\n",
      "next_state: [100, 21, 13, 3, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  13   3   0]]\n",
      "rewardsum:  322.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 11, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  11   0   0]]\n",
      "rewardsum:  328.0\n",
      "Time Slot: 94\n",
      "Rnd\n",
      "actionVec: [13, 50, 23, 54, 100]\n",
      "next_state: [100, 27, 10, 4, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  10   4   0]]\n",
      "rewardsum:  329.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 10, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  10   0   0]]\n",
      "rewardsum:  335.0\n",
      "Time Slot: 96\n",
      "Rnd\n",
      "actionVec: [80, 56, 63, 84, 100]\n",
      "next_state: [100, 25, 7, 3, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   7   3   0]]\n",
      "rewardsum:  337.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 7, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   7   0   0]]\n",
      "rewardsum:  343.0\n",
      "Time Slot: 98\n",
      "Rnd\n",
      "actionVec: [0, 71, 79, 13, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  346.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   5   0   0]]\n",
      "rewardsum:  350.0\n",
      "Episode: 7\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  5748\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Rnd\n",
      "actionVec: [38, 62, 64, 15, 100]\n",
      "next_state: [87, 4, 3, 0, 1]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[87  4  3  0  1]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 10, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10   2   0   0]]\n",
      "rewardsum:  3.0\n",
      "Time Slot: 2\n",
      "Rnd\n",
      "actionVec: [52, 71, 37, 15, 100]\n",
      "next_state: [100, 15, 0, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15   0   1   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 3\n",
      "Rnd\n",
      "actionVec: [27, 89, 29, 50, 100]\n",
      "next_state: [100, 18, 0, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   0   1   0]]\n",
      "rewardsum:  9.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   0   0   0]]\n",
      "rewardsum:  13.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 29, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 29  0  0  0]]\n",
      "rewardsum:  15.0\n",
      "Time Slot: 6\n",
      "Rnd\n",
      "actionVec: [3, 36, 62, 70, 100]\n",
      "next_state: [100, 43, 0, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43   0   0   0]]\n",
      "rewardsum:  16.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 44, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  44   0   0   0]]\n",
      "rewardsum:  19.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 49, 2, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  49   2   0   0]]\n",
      "rewardsum:  20.0\n",
      "Time Slot: 9\n",
      "Rnd\n",
      "actionVec: [95, 10, 20, 56, 100]\n",
      "next_state: [100, 41, 2, 4, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   2   4   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [95, 39, 2, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 39  2  0  0]]\n",
      "rewardsum:  28.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 32, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 32  2  0  0]]\n",
      "rewardsum:  31.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   1   0   0]]\n",
      "rewardsum:  35.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   3   0   0]]\n",
      "rewardsum:  38.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 2, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   2   1   0]]\n",
      "rewardsum:  40.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [87, 33, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[87 33  2  0  0]]\n",
      "rewardsum:  44.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   2   0   0]]\n",
      "rewardsum:  48.0\n",
      "Time Slot: 17\n",
      "Rnd\n",
      "actionVec: [45, 24, 77, 84, 100]\n",
      "next_state: [100, 24, 11, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  11   0   0]]\n",
      "rewardsum:  48.0\n",
      "Time Slot: 18\n",
      "Rnd\n",
      "actionVec: [42, 48, 31, 67, 100]\n",
      "next_state: [99, 23, 10, 3, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 23 10  3  0]]\n",
      "rewardsum:  50.0\n",
      "Time Slot: 19\n",
      "Rnd\n",
      "actionVec: [61, 48, 91, 81, 100]\n",
      "next_state: [99, 22, 11, 4, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 22 11  4  0]]\n",
      "rewardsum:  53.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 21, 11, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 21 11  0  0]]\n",
      "rewardsum:  59.0\n",
      "Time Slot: 21\n",
      "Rnd\n",
      "actionVec: [30, 84, 24, 33, 100]\n",
      "next_state: [100, 23, 8, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   8   2   0]]\n",
      "rewardsum:  62.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 23, 6, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 23  6  0  0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 23\n",
      "Rnd\n",
      "actionVec: [1, 64, 72, 26, 100]\n",
      "next_state: [100, 35, 6, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   6   1   0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   4   0   0]]\n",
      "rewardsum:  73.0\n",
      "Time Slot: 25\n",
      "Rnd\n",
      "actionVec: [26, 95, 65, 30, 100]\n",
      "next_state: [100, 41, 2, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   2   1   0]]\n",
      "rewardsum:  75.0\n",
      "Time Slot: 26\n",
      "Rnd\n",
      "actionVec: [24, 85, 60, 91, 100]\n",
      "next_state: [97, 40, 1, 4, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 40  1  4  0]]\n",
      "rewardsum:  77.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 1, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   1   0   0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 32, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 32  0  0  0]]\n",
      "rewardsum:  87.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   0   0   0]]\n",
      "rewardsum:  89.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   0   0   0]]\n",
      "rewardsum:  92.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  94.0\n",
      "Time Slot: 32\n",
      "Rnd\n",
      "actionVec: [35, 19, 33, 24, 100]\n",
      "next_state: [100, 35, 1, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   1   0]]\n",
      "rewardsum:  97.0\n",
      "Time Slot: 33\n",
      "Rnd\n",
      "actionVec: [26, 61, 27, 35, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  100.0\n",
      "Time Slot: 34\n",
      "Rnd\n",
      "actionVec: [58, 13, 52, 99, 100]\n",
      "next_state: [100, 31, 7, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   7   1   0]]\n",
      "rewardsum:  102.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [92, 31, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[92 31  8  0  0]]\n",
      "rewardsum:  106.0\n",
      "Time Slot: 36\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  10   0   0]]\n",
      "rewardsum:  108.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  10   0   0]]\n",
      "rewardsum:  110.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  10   0   0]]\n",
      "rewardsum:  113.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  10   0   0]]\n",
      "rewardsum:  117.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 12, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  12   0   0]]\n",
      "rewardsum:  118.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34 12  0  0]]\n",
      "rewardsum:  122.0\n",
      "Time Slot: 42\n",
      "Rnd\n",
      "actionVec: [3, 64, 84, 5, 100]\n",
      "next_state: [100, 40, 12, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  12   0   0]]\n",
      "rewardsum:  123.0\n",
      "Time Slot: 43\n",
      "Rnd\n",
      "actionVec: [40, 77, 68, 36, 100]\n",
      "next_state: [94, 38, 9, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[94 38  9  1  0]]\n",
      "rewardsum:  127.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   8   0   0]]\n",
      "rewardsum:  131.0\n",
      "Time Slot: 45\n",
      "Rnd\n",
      "actionVec: [28, 2, 98, 67, 100]\n",
      "next_state: [96, 30, 17, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 30 17  1  0]]\n",
      "rewardsum:  131.0\n",
      "Time Slot: 46\n",
      "Rnd\n",
      "actionVec: [25, 49, 92, 35, 100]\n",
      "next_state: [100, 35, 18, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  18   0   0]]\n",
      "rewardsum:  134.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 19, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  19   0   0]]\n",
      "rewardsum:  136.0\n",
      "Time Slot: 48\n",
      "Rnd\n",
      "actionVec: [21, 78, 94, 37, 100]\n",
      "next_state: [100, 36, 21, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  21   1   0]]\n",
      "rewardsum:  137.0\n",
      "Time Slot: 49\n",
      "Rnd\n",
      "actionVec: [19, 41, 36, 22, 100]\n",
      "next_state: [99, 38, 20, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 38 20  0  0]]\n",
      "rewardsum:  141.0\n",
      "Time Slot: 50\n",
      "Rnd\n",
      "actionVec: [51, 59, 32, 68, 100]\n",
      "next_state: [100, 37, 17, 4, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  17   4   0]]\n",
      "rewardsum:  142.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 14, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  14   0   0]]\n",
      "rewardsum:  149.0\n",
      "Time Slot: 52\n",
      "Rnd\n",
      "actionVec: [34, 3, 52, 88, 100]\n",
      "next_state: [96, 27, 20, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 27 20  0  0]]\n",
      "rewardsum:  150.0\n",
      "Time Slot: 53\n",
      "Rnd\n",
      "actionVec: [32, 21, 61, 52, 100]\n",
      "next_state: [100, 23, 24, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  24   2   0]]\n",
      "rewardsum:  151.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 25, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  25   0   0]]\n",
      "rewardsum:  155.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 28, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  28   0   0]]\n",
      "rewardsum:  158.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 22, 27, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 22 27  0  0]]\n",
      "rewardsum:  162.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 23, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  23   0   0]]\n",
      "rewardsum:  165.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  17   0   0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 16, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  16   0   0]]\n",
      "rewardsum:  172.0\n",
      "Time Slot: 60\n",
      "Rnd\n",
      "actionVec: [97, 22, 53, 19, 100]\n",
      "next_state: [99, 28, 15, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 28 15  0  0]]\n",
      "rewardsum:  176.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 12, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  12   0   0]]\n",
      "rewardsum:  181.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  11   0   0]]\n",
      "rewardsum:  183.0\n",
      "Time Slot: 63\n",
      "Rnd\n",
      "actionVec: [12, 73, 12, 31, 100]\n",
      "next_state: [99, 29, 6, 5, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 29  6  5  0]]\n",
      "rewardsum:  184.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 6, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   6   0   0]]\n",
      "rewardsum:  191.0\n",
      "Time Slot: 65\n",
      "Rnd\n",
      "actionVec: [30, 22, 0, 42, 100]\n",
      "next_state: [100, 32, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   7   0   0]]\n",
      "rewardsum:  193.0\n",
      "Time Slot: 66\n",
      "Rnd\n",
      "actionVec: [38, 88, 87, 87, 100]\n",
      "next_state: [99, 34, 7, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34  7  2  0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 67\n",
      "Rnd\n",
      "actionVec: [29, 34, 40, 80, 100]\n",
      "next_state: [100, 31, 8, 2, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   8   2   0]]\n",
      "rewardsum:  199.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 7, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   7   0   0]]\n",
      "rewardsum:  204.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  9  0  0]]\n",
      "rewardsum:  206.0\n",
      "Time Slot: 70\n",
      "Rnd\n",
      "actionVec: [69, 85, 76, 93, 100]\n",
      "next_state: [100, 30, 5, 4, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   5   4   0]]\n",
      "rewardsum:  208.0\n",
      "Time Slot: 71\n",
      "Rnd\n",
      "actionVec: [16, 15, 79, 19, 100]\n",
      "next_state: [100, 25, 6, 2, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   6   2   0]]\n",
      "rewardsum:  214.0\n",
      "Time Slot: 72\n",
      "Rnd\n",
      "actionVec: [1, 7, 19, 23, 100]\n",
      "next_state: [100, 31, 10, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  10   1   0]]\n",
      "rewardsum:  215.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 29, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 29  8  0  0]]\n",
      "rewardsum:  219.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   9   0   0]]\n",
      "rewardsum:  222.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   7   0   0]]\n",
      "rewardsum:  226.0\n",
      "Time Slot: 76\n",
      "Rnd\n",
      "actionVec: [14, 36, 16, 77, 100]\n",
      "next_state: [100, 36, 2, 7, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   7   0]]\n",
      "rewardsum:  226.0\n",
      "Time Slot: 77\n",
      "Rnd\n",
      "actionVec: [69, 36, 63, 58, 100]\n",
      "next_state: [97, 29, 4, 5, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 29  4  5  0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 78\n",
      "Rnd\n",
      "actionVec: [5, 20, 86, 30, 100]\n",
      "next_state: [100, 32, 8, 7, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   8   7   0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 79\n",
      "Rnd\n",
      "actionVec: [2, 12, 70, 2, 100]\n",
      "next_state: [100, 33, 10, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  10   1   0]]\n",
      "rewardsum:  236.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  11   0   0]]\n",
      "rewardsum:  240.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  11   0   0]]\n",
      "rewardsum:  243.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   9   0   0]]\n",
      "rewardsum:  246.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 6, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  6  0  0]]\n",
      "rewardsum:  251.0\n",
      "Time Slot: 84\n",
      "Rnd\n",
      "actionVec: [72, 68, 74, 5, 100]\n",
      "next_state: [100, 32, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   9   0   0]]\n",
      "rewardsum:  253.0\n",
      "Time Slot: 85\n",
      "Rnd\n",
      "actionVec: [97, 31, 36, 67, 100]\n",
      "next_state: [94, 25, 10, 3, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[94 25 10  3  0]]\n",
      "rewardsum:  255.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 24, 11, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 24 11  0  0]]\n",
      "rewardsum:  261.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22  14   0   0]]\n",
      "rewardsum:  264.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  13   0   0]]\n",
      "rewardsum:  267.0\n",
      "Time Slot: 89\n",
      "Rnd\n",
      "actionVec: [14, 35, 54, 29, 100]\n",
      "next_state: [100, 22, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  22  17   0   0]]\n",
      "rewardsum:  270.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  15   0   0]]\n",
      "rewardsum:  273.0\n",
      "Time Slot: 91\n",
      "Rnd\n",
      "actionVec: [70, 39, 49, 13, 100]\n",
      "next_state: [54, 24, 17, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[54 24 17  0  0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 92\n",
      "Rnd\n",
      "actionVec: [74, 87, 92, 21, 100]\n",
      "next_state: [98, 22, 16, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 22 16  0  0]]\n",
      "rewardsum:  281.0\n",
      "Time Slot: 93\n",
      "Rnd\n",
      "actionVec: [51, 79, 2, 73, 100]\n",
      "next_state: [86, 19, 0, 17, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[86 19  0 17  0]]\n",
      "rewardsum:  281.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 15, 2, 4, 0]\n",
      "Reward: 12.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 15  2  4  0]]\n",
      "rewardsum:  293.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 14, 1, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   1   0   0]]\n",
      "rewardsum:  300.0\n",
      "Time Slot: 96\n",
      "Rnd\n",
      "actionVec: [78, 42, 31, 76, 100]\n",
      "next_state: [95, 11, 1, 4, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 11  1  4  0]]\n",
      "rewardsum:  302.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 15, 0, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15   0   0   0]]\n",
      "rewardsum:  308.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 15, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15   5   0   0]]\n",
      "rewardsum:  310.0\n",
      "Time Slot: 99\n",
      "Rnd\n",
      "actionVec: [63, 19, 85, 76, 100]\n",
      "next_state: [99, 7, 11, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99  7 11  1  0]]\n",
      "rewardsum:  312.0\n",
      "Episode: 8\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  6130\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Rnd\n",
      "actionVec: [21, 26, 14, 55, 100]\n",
      "next_state: [90, 4, 1, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[90  4  1  1  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Rnd\n",
      "actionVec: [4, 76, 86, 76, 100]\n",
      "next_state: [100, 16, 0, 0, 1]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   0   0   1]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 16, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   5   0   0]]\n",
      "rewardsum:  4.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21   5   0   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 4\n",
      "Rnd\n",
      "actionVec: [18, 67, 21, 63, 100]\n",
      "next_state: [100, 28, 3, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   3   2   0]]\n",
      "rewardsum:  8.0\n",
      "Time Slot: 5\n",
      "Rnd\n",
      "actionVec: [15, 93, 51, 48, 100]\n",
      "next_state: [90, 35, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[90 35  2  0  0]]\n",
      "rewardsum:  12.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   2   0   0]]\n",
      "rewardsum:  16.0\n",
      "Time Slot: 7\n",
      "Rnd\n",
      "actionVec: [38, 60, 30, 91, 100]\n",
      "next_state: [100, 37, 1, 3, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   3   0]]\n",
      "rewardsum:  18.0\n",
      "Time Slot: 8\n",
      "Rnd\n",
      "actionVec: [34, 89, 36, 74, 100]\n",
      "next_state: [100, 34, 0, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   0   0]]\n",
      "rewardsum:  24.0\n",
      "Time Slot: 9\n",
      "Rnd\n",
      "actionVec: [73, 37, 70, 87, 100]\n",
      "next_state: [100, 28, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   4   0   0]]\n",
      "rewardsum:  26.0\n",
      "Time Slot: 10\n",
      "Rnd\n",
      "actionVec: [63, 13, 31, 22, 100]\n",
      "next_state: [60, 22, 7, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[60 22  7  1  0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 11\n",
      "Rnd\n",
      "actionVec: [55, 27, 8, 6, 100]\n",
      "next_state: [91, 18, 2, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[91 18  2  0  0]]\n",
      "rewardsum:  36.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 19, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   3   0   0]]\n",
      "rewardsum:  39.0\n",
      "Time Slot: 13\n",
      "Rnd\n",
      "actionVec: [49, 38, 16, 96, 100]\n",
      "next_state: [98, 14, 7, 5, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 14  7  5  0]]\n",
      "rewardsum:  39.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 17, 5, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   5   0   0]]\n",
      "rewardsum:  46.0\n",
      "Time Slot: 15\n",
      "Rnd\n",
      "actionVec: [6, 69, 32, 50, 100]\n",
      "next_state: [100, 24, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   3   0   0]]\n",
      "rewardsum:  50.0\n",
      "Time Slot: 16\n",
      "Rnd\n",
      "actionVec: [82, 27, 88, 23, 100]\n",
      "next_state: [100, 18, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   9   0   0]]\n",
      "rewardsum:  52.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 22, 12, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 22 12  0  0]]\n",
      "rewardsum:  53.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  14   0   0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 19\n",
      "Rnd\n",
      "actionVec: [79, 56, 64, 86, 100]\n",
      "next_state: [100, 24, 14, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  14   2   0]]\n",
      "rewardsum:  58.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 13, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  13   0   0]]\n",
      "rewardsum:  63.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  13   0   0]]\n",
      "rewardsum:  67.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  16   0   0]]\n",
      "rewardsum:  70.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 16, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  16   0   0]]\n",
      "rewardsum:  72.0\n",
      "Time Slot: 24\n",
      "Rnd\n",
      "actionVec: [93, 25, 88, 11, 100]\n",
      "next_state: [100, 26, 16, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  16   0   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 25\n",
      "Rnd\n",
      "actionVec: [71, 50, 61, 69, 100]\n",
      "next_state: [100, 23, 18, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  18   1   0]]\n",
      "rewardsum:  79.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 24, 19, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 24 19  0  0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 19, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  19   0   0]]\n",
      "rewardsum:  86.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 18, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  18   0   0]]\n",
      "rewardsum:  88.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 16, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  16   0   0]]\n",
      "rewardsum:  92.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  12   0   0]]\n",
      "rewardsum:  95.0\n",
      "Time Slot: 31\n",
      "Rnd\n",
      "actionVec: [32, 79, 88, 43, 100]\n",
      "next_state: [100, 34, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  12   0   0]]\n",
      "rewardsum:  99.0\n",
      "Time Slot: 32\n",
      "Rnd\n",
      "actionVec: [13, 25, 14, 12, 100]\n",
      "next_state: [100, 34, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  12   0   0]]\n",
      "rewardsum:  102.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  14   0   0]]\n",
      "rewardsum:  104.0\n",
      "Time Slot: 34\n",
      "Rnd\n",
      "actionVec: [40, 42, 95, 5, 100]\n",
      "next_state: [100, 32, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  14   0   0]]\n",
      "rewardsum:  107.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 14, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  14   0   0]]\n",
      "rewardsum:  111.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  13   0   0]]\n",
      "rewardsum:  115.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  12   0   0]]\n",
      "rewardsum:  118.0\n",
      "Time Slot: 38\n",
      "Rnd\n",
      "actionVec: [91, 33, 62, 40, 100]\n",
      "next_state: [95, 24, 12, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 24 12  1  0]]\n",
      "rewardsum:  122.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 11, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  11   1   0]]\n",
      "rewardsum:  126.0\n",
      "Time Slot: 40\n",
      "Rnd\n",
      "actionVec: [59, 30, 15, 58, 100]\n",
      "next_state: [99, 21, 6, 5, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 21  6  5  0]]\n",
      "rewardsum:  130.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 7, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   7   0   0]]\n",
      "rewardsum:  136.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21   5   0   0]]\n",
      "rewardsum:  140.0\n",
      "Time Slot: 43\n",
      "Rnd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [18, 12, 57, 48, 100]\n",
      "next_state: [100, 18, 11, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18  11   1   0]]\n",
      "rewardsum:  142.0\n",
      "Time Slot: 44\n",
      "Rnd\n",
      "actionVec: [78, 18, 24, 32, 100]\n",
      "next_state: [99, 13, 12, 3, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 13 12  3  0]]\n",
      "rewardsum:  145.0\n",
      "Time Slot: 45\n",
      "Rnd\n",
      "actionVec: [97, 37, 86, 37, 100]\n",
      "next_state: [100, 10, 15, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10  15   0   0]]\n",
      "rewardsum:  150.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [92, 15, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[92 15 16  0  0]]\n",
      "rewardsum:  153.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 19, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19  16   0   0]]\n",
      "rewardsum:  156.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22  16   0   0]]\n",
      "rewardsum:  159.0\n",
      "Time Slot: 49\n",
      "Rnd\n",
      "actionVec: [51, 44, 59, 15, 100]\n",
      "next_state: [100, 23, 19, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  19   0   0]]\n",
      "rewardsum:  161.0\n",
      "Time Slot: 50\n",
      "Rnd\n",
      "actionVec: [93, 54, 3, 96, 100]\n",
      "next_state: [98, 22, 9, 13, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 22  9 13  0]]\n",
      "rewardsum:  161.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 25, 8, 5, 0]\n",
      "Reward: 9.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 25  8  5  0]]\n",
      "rewardsum:  170.0\n",
      "Time Slot: 52\n",
      "Rnd\n",
      "actionVec: [79, 58, 64, 65, 100]\n",
      "next_state: [100, 20, 7, 6, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   7   6   0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 17, 7, 1, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   7   1   0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 54\n",
      "Rnd\n",
      "actionVec: [22, 42, 59, 39, 100]\n",
      "next_state: [100, 17, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   7   0   0]]\n",
      "rewardsum:  186.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   8   0   0]]\n",
      "rewardsum:  189.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   5   0   0]]\n",
      "rewardsum:  193.0\n",
      "Time Slot: 57\n",
      "Rnd\n",
      "actionVec: [45, 79, 89, 98, 100]\n",
      "next_state: [95, 24, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 24  8  0  0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 58\n",
      "Rnd\n",
      "actionVec: [42, 65, 30, 87, 100]\n",
      "next_state: [100, 25, 6, 6, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   6   6   0]]\n",
      "rewardsum:  196.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 8, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   8   0   0]]\n",
      "rewardsum:  203.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   8   0   0]]\n",
      "rewardsum:  206.0\n",
      "Time Slot: 61\n",
      "Rnd\n",
      "actionVec: [7, 88, 54, 84, 100]\n",
      "next_state: [100, 34, 9, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   9   0   0]]\n",
      "rewardsum:  207.0\n",
      "Time Slot: 62\n",
      "Rnd\n",
      "actionVec: [99, 93, 56, 50, 100]\n",
      "next_state: [100, 31, 6, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   6   0   0]]\n",
      "rewardsum:  212.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 32, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 32  6  0  0]]\n",
      "rewardsum:  216.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 8, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   8   0   0]]\n",
      "rewardsum:  217.0\n",
      "Time Slot: 65\n",
      "Rnd\n",
      "actionVec: [72, 64, 98, 8, 100]\n",
      "next_state: [98, 30, 9, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 30  9  0  0]]\n",
      "rewardsum:  222.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   8   0   0]]\n",
      "rewardsum:  225.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   9   0   0]]\n",
      "rewardsum:  227.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   9   0   0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  10   0   0]]\n",
      "rewardsum:  234.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 10, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  10   2   0]]\n",
      "rewardsum:  235.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  12   0   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  12   0   0]]\n",
      "rewardsum:  240.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 43, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43  12   0   0]]\n",
      "rewardsum:  242.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 40, 10, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 40 10  1  0]]\n",
      "rewardsum:  246.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   9   0   0]]\n",
      "rewardsum:  250.0\n",
      "Time Slot: 76\n",
      "Rnd\n",
      "actionVec: [41, 51, 87, 39, 100]\n",
      "next_state: [86, 33, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[86 33 12  0  0]]\n",
      "rewardsum:  252.0\n",
      "Time Slot: 77\n",
      "Rnd\n",
      "actionVec: [53, 0, 21, 72, 100]\n",
      "next_state: [100, 31, 10, 4, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  10   4   0]]\n",
      "rewardsum:  253.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 9, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   9   0   0]]\n",
      "rewardsum:  260.0\n",
      "Time Slot: 79\n",
      "Rnd\n",
      "actionVec: [87, 94, 77, 7, 100]\n",
      "next_state: [99, 25, 4, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 25  4  0  0]]\n",
      "rewardsum:  266.0\n",
      "Time Slot: 80\n",
      "Rnd\n",
      "actionVec: [49, 87, 53, 12, 100]\n",
      "next_state: [100, 19, 1, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   1   0   0]]\n",
      "rewardsum:  272.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 17, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   1   0   0]]\n",
      "rewardsum:  276.0\n",
      "Time Slot: 82\n",
      "Rnd\n",
      "actionVec: [59, 85, 34, 94, 100]\n",
      "next_state: [100, 20, 0, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   0   1   0]]\n",
      "rewardsum:  279.0\n",
      "Time Slot: 83\n",
      "Rnd\n",
      "actionVec: [39, 94, 24, 3, 100]\n",
      "next_state: [100, 23, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   0   0   0]]\n",
      "rewardsum:  282.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   0   0   0]]\n",
      "rewardsum:  285.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   0   0   0]]\n",
      "rewardsum:  288.0\n",
      "Time Slot: 86\n",
      "Rnd\n",
      "actionVec: [40, 79, 61, 41, 100]\n",
      "next_state: [100, 30, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   3   0   0]]\n",
      "rewardsum:  290.0\n",
      "Time Slot: 87\n",
      "Rnd\n",
      "actionVec: [18, 39, 92, 87, 100]\n",
      "next_state: [100, 38, 6, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   6   0   0]]\n",
      "rewardsum:  291.0\n",
      "Time Slot: 88\n",
      "Rnd\n",
      "actionVec: [56, 33, 72, 88, 100]\n",
      "next_state: [93, 30, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[93 30 10  0  0]]\n",
      "rewardsum:  294.0\n",
      "Time Slot: 89\n",
      "Rnd\n",
      "actionVec: [58, 48, 41, 30, 100]\n",
      "next_state: [100, 29, 9, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   9   1   0]]\n",
      "rewardsum:  298.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 28, 8, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 28  8  0  0]]\n",
      "rewardsum:  303.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 29, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 29  9  0  0]]\n",
      "rewardsum:  306.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [91, 21, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[91 21  8  0  0]]\n",
      "rewardsum:  310.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   9   0   0]]\n",
      "rewardsum:  312.0\n",
      "Time Slot: 94\n",
      "Rnd\n",
      "actionVec: [76, 96, 58, 37, 100]\n",
      "next_state: [100, 29, 6, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   6   1   0]]\n",
      "rewardsum:  316.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  29   7   0   0]]\n",
      "rewardsum:  320.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   8   0   0]]\n",
      "rewardsum:  324.0\n",
      "Time Slot: 97\n",
      "Rnd\n",
      "actionVec: [20, 12, 83, 56, 100]\n",
      "next_state: [98, 25, 15, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 25 15  0  0]]\n",
      "rewardsum:  324.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 15, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  15   0   0]]\n",
      "rewardsum:  328.0\n",
      "Time Slot: 99\n",
      "Rnd\n",
      "actionVec: [82, 20, 91, 73, 100]\n",
      "next_state: [100, 20, 22, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20  22   0   0]]\n",
      "rewardsum:  330.0\n",
      "Episode: 9\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  8555\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [87, 4, 1, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[87  4  1  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Rnd\n",
      "actionVec: [31, 2, 76, 85, 100]\n",
      "next_state: [100, 0, 2, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0   2   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 2\n",
      "Rnd\n",
      "actionVec: [29, 44, 11, 41, 100]\n",
      "next_state: [100, 3, 0, 4, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   3   0   4   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 3\n",
      "Rnd\n",
      "actionVec: [49, 89, 98, 28, 100]\n",
      "next_state: [100, 6, 1, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   6   1   0   0]]\n",
      "rewardsum:  5.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 7, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   7   1   0   0]]\n",
      "rewardsum:  9.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [77, 11, 0, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[77 11  0  1  0]]\n",
      "rewardsum:  12.0\n",
      "Time Slot: 6\n",
      "Rnd\n",
      "actionVec: [58, 71, 90, 76, 100]\n",
      "next_state: [100, 11, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11   3   0   0]]\n",
      "rewardsum:  15.0\n",
      "Time Slot: 7\n",
      "Rnd\n",
      "actionVec: [31, 15, 73, 83, 100]\n",
      "next_state: [100, 7, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   7   9   0   0]]\n",
      "rewardsum:  17.0\n",
      "Time Slot: 8\n",
      "Rnd\n",
      "actionVec: [74, 91, 85, 8, 100]\n",
      "next_state: [100, 8, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   8   9   0   0]]\n",
      "rewardsum:  21.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 14, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   9   0   0]]\n",
      "rewardsum:  24.0\n",
      "Time Slot: 10\n",
      "Rnd\n",
      "actionVec: [92, 16, 87, 10, 100]\n",
      "next_state: [100, 5, 17, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   5  17   0   0]]\n",
      "rewardsum:  26.0\n",
      "Time Slot: 11\n",
      "Rnd\n",
      "actionVec: [93, 92, 39, 0, 100]\n",
      "next_state: [100, 5, 12, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   5  12   0   0]]\n",
      "rewardsum:  32.0\n",
      "Time Slot: 12\n",
      "Rnd\n",
      "actionVec: [78, 84, 45, 35, 100]\n",
      "next_state: [100, 6, 10, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   6  10   1   0]]\n",
      "rewardsum:  37.0\n",
      "Time Slot: 13\n",
      "Rnd\n",
      "actionVec: [75, 80, 30, 18, 100]\n",
      "next_state: [100, 5, 8, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   5   8   1   0]]\n",
      "rewardsum:  42.0\n",
      "Time Slot: 14\n",
      "Rnd\n",
      "actionVec: [53, 57, 79, 92, 100]\n",
      "next_state: [99, 6, 8, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99  6  8  2  0]]\n",
      "rewardsum:  44.0\n",
      "Time Slot: 15\n",
      "Rnd\n",
      "actionVec: [93, 58, 51, 67, 100]\n",
      "next_state: [62, 2, 8, 3, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[62  2  8  3  0]]\n",
      "rewardsum:  49.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 6, 8, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   6   8   0   0]]\n",
      "rewardsum:  54.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 10, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10   8   0   0]]\n",
      "rewardsum:  57.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 10, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10  10   0   0]]\n",
      "rewardsum:  60.0\n",
      "Time Slot: 19\n",
      "Rnd\n",
      "actionVec: [77, 76, 75, 73, 100]\n",
      "next_state: [100, 10, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10  13   0   0]]\n",
      "rewardsum:  63.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 16, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16  12   0   0]]\n",
      "rewardsum:  66.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  10   0   0]]\n",
      "rewardsum:  70.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   9   0   0]]\n",
      "rewardsum:  73.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   9   0   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  10   0   0]]\n",
      "rewardsum:  79.0\n",
      "Time Slot: 25\n",
      "Rnd\n",
      "actionVec: [74, 11, 42, 38, 100]\n",
      "next_state: [100, 28, 14, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  14   1   0]]\n",
      "rewardsum:  81.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 17, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  17   0   0]]\n",
      "rewardsum:  85.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 16, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  16   0   0]]\n",
      "rewardsum:  89.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 16, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  16   0   0]]\n",
      "rewardsum:  90.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  17   0   0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 30\n",
      "Rnd\n",
      "actionVec: [97, 16, 38, 91, 100]\n",
      "next_state: [100, 23, 17, 4, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  17   4   0]]\n",
      "rewardsum:  96.0\n",
      "Time Slot: 31\n",
      "Rnd\n",
      "actionVec: [6, 17, 54, 13, 100]\n",
      "next_state: [100, 19, 23, 4, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19  23   4   0]]\n",
      "rewardsum:  98.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 20, 23, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 20 23  0  0]]\n",
      "rewardsum:  104.0\n",
      "Time Slot: 33\n",
      "Rnd\n",
      "actionVec: [31, 58, 92, 88, 100]\n",
      "next_state: [100, 23, 24, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  24   2   0]]\n",
      "rewardsum:  106.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 23, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  23   0   0]]\n",
      "rewardsum:  111.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 22, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  22   0   0]]\n",
      "rewardsum:  113.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  17   0   0]]\n",
      "rewardsum:  116.0\n",
      "Time Slot: 37\n",
      "Rnd\n",
      "actionVec: [4, 12, 58, 52, 100]\n",
      "next_state: [100, 43, 13, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43  13   0   0]]\n",
      "rewardsum:  117.0\n",
      "Time Slot: 38\n",
      "Rnd\n",
      "actionVec: [42, 8, 80, 71, 100]\n",
      "next_state: [100, 31, 21, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  21   0   0]]\n",
      "rewardsum:  118.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 19, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  19   0   0]]\n",
      "rewardsum:  123.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 18, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  18   0   0]]\n",
      "rewardsum:  126.0\n",
      "Time Slot: 41\n",
      "Rnd\n",
      "actionVec: [77, 68, 89, 78, 100]\n",
      "next_state: [100, 34, 17, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  17   1   0]]\n",
      "rewardsum:  129.0\n",
      "Time Slot: 42\n",
      "Rnd\n",
      "actionVec: [52, 0, 99, 18, 100]\n",
      "next_state: [100, 26, 18, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  18   0   0]]\n",
      "rewardsum:  132.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  12   0   0]]\n",
      "rewardsum:  136.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  12   0   0]]\n",
      "rewardsum:  139.0\n",
      "Time Slot: 45\n",
      "Rnd\n",
      "actionVec: [97, 35, 84, 11, 100]\n",
      "next_state: [100, 27, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  13   0   0]]\n",
      "rewardsum:  143.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  12   0   0]]\n",
      "rewardsum:  146.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 27, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 27 12  0  0]]\n",
      "rewardsum:  150.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  11   0   0]]\n",
      "rewardsum:  152.0\n",
      "Time Slot: 49\n",
      "Rnd\n",
      "actionVec: [61, 77, 58, 54, 100]\n",
      "next_state: [100, 30, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  30  10   0   0]]\n",
      "rewardsum:  156.0\n",
      "Time Slot: 50\n",
      "Rnd\n",
      "actionVec: [1, 45, 79, 43, 100]\n",
      "next_state: [100, 39, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   9   0   0]]\n",
      "rewardsum:  158.0\n",
      "Time Slot: 51\n",
      "Rnd\n",
      "actionVec: [33, 87, 63, 33, 100]\n",
      "next_state: [100, 39, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   8   0   0]]\n",
      "rewardsum:  161.0\n",
      "Time Slot: 52\n",
      "Rnd\n",
      "actionVec: [78, 0, 40, 65, 100]\n",
      "next_state: [98, 35, 5, 2, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 35  5  2  0]]\n",
      "rewardsum:  165.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 6, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   6   0   0]]\n",
      "rewardsum:  170.0\n",
      "Time Slot: 54\n",
      "Rnd\n",
      "actionVec: [0, 65, 62, 43, 100]\n",
      "next_state: [100, 31, 6, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   6   1   0]]\n",
      "rewardsum:  172.0\n",
      "Time Slot: 55\n",
      "Rnd\n",
      "actionVec: [11, 52, 33, 73, 100]\n",
      "next_state: [100, 32, 9, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   9   1   0]]\n",
      "rewardsum:  173.0\n",
      "Time Slot: 56\n",
      "Rnd\n",
      "actionVec: [15, 12, 19, 2, 100]\n",
      "next_state: [98, 26, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 26 11  0  0]]\n",
      "rewardsum:  177.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  12   0   0]]\n",
      "rewardsum:  181.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 13, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  13   1   0]]\n",
      "rewardsum:  183.0\n",
      "Time Slot: 59\n",
      "Rnd\n",
      "actionVec: [5, 70, 13, 86, 100]\n",
      "next_state: [100, 40, 12, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  12   1   0]]\n",
      "rewardsum:  184.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 11, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  11   1   0]]\n",
      "rewardsum:  187.0\n",
      "Time Slot: 61\n",
      "Rnd\n",
      "actionVec: [50, 44, 85, 17, 100]\n",
      "next_state: [100, 34, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  13   0   0]]\n",
      "rewardsum:  191.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  13   0   0]]\n",
      "rewardsum:  194.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  13   0   0]]\n",
      "rewardsum:  197.0\n",
      "Time Slot: 64\n",
      "Rnd\n",
      "actionVec: [77, 76, 42, 13, 100]\n",
      "next_state: [98, 30, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 30 13  0  0]]\n",
      "rewardsum:  201.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  13   0   0]]\n",
      "rewardsum:  205.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 15, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  15   1   0]]\n",
      "rewardsum:  207.0\n",
      "Time Slot: 67\n",
      "Rnd\n",
      "actionVec: [77, 48, 3, 66, 100]\n",
      "next_state: [86, 21, 2, 12, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[86 21  2 12  0]]\n",
      "rewardsum:  209.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 17, 1, 5, 0]\n",
      "Reward: 9.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 17  1  5  0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 69\n",
      "Rnd\n",
      "actionVec: [42, 65, 2, 62, 100]\n",
      "next_state: [100, 18, 0, 7, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   0   7   0]]\n",
      "rewardsum:  221.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 19, 1, 0, 0]\n",
      "Reward: 9.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   1   0   0]]\n",
      "rewardsum:  230.0\n",
      "Time Slot: 71\n",
      "Rnd\n",
      "actionVec: [38, 63, 6, 81, 100]\n",
      "next_state: [100, 19, 0, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   0   2   0]]\n",
      "rewardsum:  232.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   0   0   0]]\n",
      "rewardsum:  236.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   2   0   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 74\n",
      "Rnd\n",
      "actionVec: [90, 7, 53, 49, 100]\n",
      "next_state: [97, 21, 12, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 21 12  1  0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  13   0   0]]\n",
      "rewardsum:  241.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [60, 35, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[60 35 11  0  0]]\n",
      "rewardsum:  243.0\n",
      "Time Slot: 77\n",
      "Rnd\n",
      "actionVec: [66, 76, 57, 14, 100]\n",
      "next_state: [99, 33, 12, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33 12  1  0]]\n",
      "rewardsum:  246.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 9, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   9   0   0]]\n",
      "rewardsum:  252.0\n",
      "Time Slot: 79\n",
      "Rnd\n",
      "actionVec: [18, 3, 64, 73, 100]\n",
      "next_state: [99, 23, 16, 2, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 23 16  2  0]]\n",
      "rewardsum:  252.0\n",
      "Time Slot: 80\n",
      "Rnd\n",
      "actionVec: [9, 58, 98, 21, 100]\n",
      "next_state: [100, 30, 18, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  18   0   0]]\n",
      "rewardsum:  255.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 18, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  18   0   0]]\n",
      "rewardsum:  257.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 17, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  17   0   0]]\n",
      "rewardsum:  262.0\n",
      "Time Slot: 83\n",
      "Rnd\n",
      "actionVec: [59, 88, 16, 40, 100]\n",
      "next_state: [97, 29, 8, 6, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 29  8  6  0]]\n",
      "rewardsum:  265.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 5, 0, 0]\n",
      "Reward: 10.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   5   0   0]]\n",
      "rewardsum:  275.0\n",
      "Time Slot: 85\n",
      "Rnd\n",
      "actionVec: [64, 65, 42, 83, 100]\n",
      "next_state: [100, 21, 3, 4, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21   3   4   0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 3, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   3   0   0]]\n",
      "rewardsum:  283.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   0   0   0]]\n",
      "rewardsum:  287.0\n",
      "Time Slot: 88\n",
      "Rnd\n",
      "actionVec: [79, 45, 8, 54, 100]\n",
      "next_state: [100, 16, 0, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   0   1   0]]\n",
      "rewardsum:  291.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 14, 1, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   1   0   0]]\n",
      "rewardsum:  296.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 18, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 18  1  0  0]]\n",
      "rewardsum:  299.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 21, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 21  3  0  0]]\n",
      "rewardsum:  301.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   2   0   0]]\n",
      "rewardsum:  305.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   1   0   0]]\n",
      "rewardsum:  308.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   0   0]]\n",
      "rewardsum:  310.0\n",
      "Time Slot: 95\n",
      "Rnd\n",
      "actionVec: [64, 60, 97, 13, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  313.0\n",
      "Time Slot: 96\n",
      "Rnd\n",
      "actionVec: [37, 87, 96, 75, 100]\n",
      "next_state: [100, 34, 4, 4, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   4   0]]\n",
      "rewardsum:  313.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  319.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 7, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  7  1  0]]\n",
      "rewardsum:  321.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 5, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   5   0   0]]\n",
      "rewardsum:  326.0\n",
      "Episode: 10\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  9269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [91, 6, 0, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[91  6  0  1  0]]\n",
      "rewardsum:  1.0\n",
      "Time Slot: 1\n",
      "Rnd\n",
      "actionVec: [91, 74, 14, 65, 100]\n",
      "next_state: [100, 4, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   4   0   0   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 3, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   3   0   0   0]]\n",
      "rewardsum:  10.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 5, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   5   2   0   0]]\n",
      "rewardsum:  13.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 6, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   6   3   0   0]]\n",
      "rewardsum:  16.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [90, 14, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[90 14  2  0  0]]\n",
      "rewardsum:  18.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 17, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   2   0   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   1   0   0]]\n",
      "rewardsum:  25.0\n",
      "Time Slot: 8\n",
      "Rnd\n",
      "actionVec: [58, 66, 71, 16, 100]\n",
      "next_state: [100, 26, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   2   0   0]]\n",
      "rewardsum:  28.0\n",
      "Time Slot: 9\n",
      "Rnd\n",
      "actionVec: [42, 7, 13, 3, 100]\n",
      "next_state: [100, 17, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17  10   0   0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [89, 20, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[89 20  9  0  0]]\n",
      "rewardsum:  34.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   9   0   0]]\n",
      "rewardsum:  37.0\n",
      "Time Slot: 12\n",
      "Rnd\n",
      "actionVec: [67, 70, 76, 19, 100]\n",
      "next_state: [100, 22, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22  10   0   0]]\n",
      "rewardsum:  41.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 9, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   9   1   0]]\n",
      "rewardsum:  44.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  10   0   0]]\n",
      "rewardsum:  47.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  12   0   0]]\n",
      "rewardsum:  49.0\n",
      "Time Slot: 16\n",
      "Rnd\n",
      "actionVec: [10, 47, 4, 80, 100]\n",
      "next_state: [100, 26, 1, 12, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   1  12   0]]\n",
      "rewardsum:  49.0\n",
      "Time Slot: 17\n",
      "Rnd\n",
      "actionVec: [30, 9, 87, 15, 100]\n",
      "next_state: [99, 20, 8, 10, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 20  8 10  0]]\n",
      "rewardsum:  53.0\n",
      "Time Slot: 18\n",
      "Rnd\n",
      "actionVec: [72, 23, 44, 81, 100]\n",
      "next_state: [99, 14, 13, 10, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 14 13 10  0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 16, 11, 10, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16  11  10   0]]\n",
      "rewardsum:  60.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 16, 11, 0, 0]\n",
      "Reward: 11.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16  11   0   0]]\n",
      "rewardsum:  71.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 17, 14, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17  14   1   0]]\n",
      "rewardsum:  73.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20  16   0   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 14, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  14   0   0]]\n",
      "rewardsum:  80.0\n",
      "Time Slot: 24\n",
      "Rnd\n",
      "actionVec: [15, 72, 35, 93, 100]\n",
      "next_state: [100, 35, 9, 3, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   9   3   0]]\n",
      "rewardsum:  80.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [68, 35, 10, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[68 35 10  0  0]]\n",
      "rewardsum:  86.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  10   0   0]]\n",
      "rewardsum:  88.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  12   0   0]]\n",
      "rewardsum:  90.0\n",
      "Time Slot: 28\n",
      "Rnd\n",
      "actionVec: [24, 60, 61, 54, 100]\n",
      "next_state: [100, 42, 10, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42  10   1   0]]\n",
      "rewardsum:  92.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  14   0   0]]\n",
      "rewardsum:  95.0\n",
      "Time Slot: 30\n",
      "Rnd\n",
      "actionVec: [97, 15, 76, 48, 100]\n",
      "next_state: [100, 28, 20, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  20   1   0]]\n",
      "rewardsum:  97.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 22, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  22   0   0]]\n",
      "rewardsum:  100.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 23, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  23   0   0]]\n",
      "rewardsum:  102.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 23, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  23   0   0]]\n",
      "rewardsum:  106.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 20, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  20   0   0]]\n",
      "rewardsum:  109.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  13   0   0]]\n",
      "rewardsum:  112.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  12   0   0]]\n",
      "rewardsum:  115.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  10   0   0]]\n",
      "rewardsum:  117.0\n",
      "Time Slot: 38\n",
      "Rnd\n",
      "actionVec: [1, 42, 22, 64, 100]\n",
      "next_state: [100, 48, 7, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  48   7   0   0]]\n",
      "rewardsum:  117.0\n",
      "Time Slot: 39\n",
      "Rnd\n",
      "actionVec: [39, 47, 70, 80, 100]\n",
      "next_state: [100, 47, 9, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  47   9   1   0]]\n",
      "rewardsum:  119.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 43, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43   9   0   0]]\n",
      "rewardsum:  123.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 45, 8, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 45  8  1  0]]\n",
      "rewardsum:  126.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 45, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  45  10   0   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 43\n",
      "Rnd\n",
      "actionVec: [81, 11, 99, 62, 100]\n",
      "next_state: [96, 31, 18, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 31 18  1  0]]\n",
      "rewardsum:  129.0\n",
      "Time Slot: 44\n",
      "Rnd\n",
      "actionVec: [74, 20, 14, 75, 100]\n",
      "next_state: [100, 27, 16, 5, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  16   5   0]]\n",
      "rewardsum:  131.0\n",
      "Time Slot: 45\n",
      "Rnd\n",
      "actionVec: [90, 70, 78, 9, 100]\n",
      "next_state: [97, 22, 13, 0, 0]\n",
      "Reward: 10.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 22 13  0  0]]\n",
      "rewardsum:  141.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  14   0   0]]\n",
      "rewardsum:  144.0\n",
      "Time Slot: 47\n",
      "Rnd\n",
      "actionVec: [30, 23, 15, 52, 100]\n",
      "next_state: [100, 17, 14, 4, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17  14   4   0]]\n",
      "rewardsum:  145.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 15, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18  15   0   0]]\n",
      "rewardsum:  151.0\n",
      "Time Slot: 49\n",
      "Rnd\n",
      "actionVec: [64, 2, 16, 90, 100]\n",
      "next_state: [97, 2, 29, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97  2 29  0  0]]\n",
      "rewardsum:  151.0\n",
      "Time Slot: 50\n",
      "Rnd\n",
      "actionVec: [60, 0, 25, 76, 100]\n",
      "next_state: [100, 0, 28, 5, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0  28   5   0]]\n",
      "rewardsum:  152.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 4, 25, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   4  25   0   0]]\n",
      "rewardsum:  160.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 9, 28, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98  9 28  0  0]]\n",
      "rewardsum:  162.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 13, 30, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13  30   0   0]]\n",
      "rewardsum:  163.0\n",
      "Time Slot: 54\n",
      "Rnd\n",
      "actionVec: [1, 72, 10, 50, 100]\n",
      "next_state: [100, 26, 15, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  26  15   0   0]]\n",
      "rewardsum:  163.0\n",
      "Time Slot: 55\n",
      "Rnd\n",
      "actionVec: [24, 10, 71, 51, 100]\n",
      "next_state: [100, 27, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  14   0   0]]\n",
      "rewardsum:  165.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [52, 27, 14, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[52 27 14  0  0]]\n",
      "rewardsum:  170.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  15   0   0]]\n",
      "rewardsum:  172.0\n",
      "Time Slot: 58\n",
      "Rnd\n",
      "actionVec: [60, 31, 72, 2, 100]\n",
      "next_state: [99, 30, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 30 17  0  0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 59\n",
      "Rnd\n",
      "actionVec: [4, 44, 23, 26, 100]\n",
      "next_state: [100, 26, 18, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  18   0   0]]\n",
      "rewardsum:  179.0\n",
      "Time Slot: 60\n",
      "Rnd\n",
      "actionVec: [66, 62, 49, 41, 100]\n",
      "next_state: [100, 24, 16, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  16   1   0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 19, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22  19   0   0]]\n",
      "rewardsum:  186.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 17, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22  17   2   0]]\n",
      "rewardsum:  189.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 17, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  17   0   0]]\n",
      "rewardsum:  193.0\n",
      "Time Slot: 64\n",
      "Rnd\n",
      "actionVec: [3, 45, 39, 89, 100]\n",
      "next_state: [100, 37, 14, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  14   0   0]]\n",
      "rewardsum:  193.0\n",
      "Time Slot: 65\n",
      "Rnd\n",
      "actionVec: [25, 6, 76, 17, 100]\n",
      "next_state: [100, 29, 21, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  21   0   0]]\n",
      "rewardsum:  194.0\n",
      "Time Slot: 66\n",
      "Rnd\n",
      "actionVec: [4, 84, 48, 88, 100]\n",
      "next_state: [100, 45, 17, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  45  17   0   0]]\n",
      "rewardsum:  194.0\n",
      "Time Slot: 67\n",
      "Rnd\n",
      "actionVec: [37, 73, 48, 47, 100]\n",
      "next_state: [100, 48, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  48  17   0   0]]\n",
      "rewardsum:  197.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 47, 15, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  47  15   0   0]]\n",
      "rewardsum:  201.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 38, 19, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 38 19  0  0]]\n",
      "rewardsum:  203.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 16, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  16   0   0]]\n",
      "rewardsum:  204.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 33, 16, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 33 16  1  0]]\n",
      "rewardsum:  207.0\n",
      "Time Slot: 72\n",
      "Rnd\n",
      "actionVec: [78, 35, 27, 72, 100]\n",
      "next_state: [96, 29, 10, 6, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 29 10  6  0]]\n",
      "rewardsum:  210.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 26, 11, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 26 11  0  0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  11   0   0]]\n",
      "rewardsum:  221.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  10   0   0]]\n",
      "rewardsum:  225.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  10   0   0]]\n",
      "rewardsum:  227.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  12   0   0]]\n",
      "rewardsum:  230.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  11   0   0]]\n",
      "rewardsum:  233.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  11   0   0]]\n",
      "rewardsum:  236.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  10   0   0]]\n",
      "rewardsum:  239.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  10   0   0]]\n",
      "rewardsum:  242.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  10   0   0]]\n",
      "rewardsum:  245.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35 11  0  0]]\n",
      "rewardsum:  248.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 9, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   9   0   0]]\n",
      "rewardsum:  253.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   7   0   0]]\n",
      "rewardsum:  257.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   4   0   0]]\n",
      "rewardsum:  261.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   4   0   0]]\n",
      "rewardsum:  264.0\n",
      "Time Slot: 88\n",
      "Rnd\n",
      "actionVec: [49, 56, 74, 28, 100]\n",
      "next_state: [100, 29, 7, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   7   1   0]]\n",
      "rewardsum:  266.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   9   0   0]]\n",
      "rewardsum:  269.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  11   0   0]]\n",
      "rewardsum:  271.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  10   0   0]]\n",
      "rewardsum:  274.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  10   0   0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 93\n",
      "Rnd\n",
      "actionVec: [71, 17, 97, 65, 100]\n",
      "next_state: [98, 21, 21, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 21 21  0  0]]\n",
      "rewardsum:  278.0\n",
      "Time Slot: 94\n",
      "Rnd\n",
      "actionVec: [13, 91, 73, 40, 100]\n",
      "next_state: [100, 27, 21, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  21   0   0]]\n",
      "rewardsum:  281.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 20, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  20   0   0]]\n",
      "rewardsum:  284.0\n",
      "Time Slot: 96\n",
      "Rnd\n",
      "actionVec: [5, 5, 86, 21, 100]\n",
      "next_state: [100, 28, 27, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  27   0   0]]\n",
      "rewardsum:  285.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 27, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  27   0   0]]\n",
      "rewardsum:  288.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 20, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  20   0   0]]\n",
      "rewardsum:  290.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 18, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  18   0   0]]\n",
      "rewardsum:  295.0\n",
      "Episode: 11\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  7767\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [81, 6, 0, 0, 1]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[81  6  0  0  1]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 9, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   9   0   0   0]]\n",
      "rewardsum:  4.0\n",
      "Time Slot: 2\n",
      "Rnd\n",
      "actionVec: [36, 32, 91, 62, 100]\n",
      "next_state: [100, 8, 4, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   8   4   1   0]]\n",
      "rewardsum:  5.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 15, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15   5   0   0]]\n",
      "rewardsum:  8.0\n",
      "Time Slot: 4\n",
      "Rnd\n",
      "actionVec: [61, 45, 97, 39, 100]\n",
      "next_state: [100, 12, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12   8   0   0]]\n",
      "rewardsum:  11.0\n",
      "Time Slot: 5\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 15, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 15  7  0  0]]\n",
      "rewardsum:  15.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   7   0   0]]\n",
      "rewardsum:  17.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  10   0   0]]\n",
      "rewardsum:  19.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   9   0   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 9\n",
      "Rnd\n",
      "actionVec: [75, 38, 3, 16, 100]\n",
      "next_state: [98, 28, 0, 6, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 28  0  6  0]]\n",
      "rewardsum:  26.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 1, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   1   0   0]]\n",
      "rewardsum:  34.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   1   0   0]]\n",
      "rewardsum:  36.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   1   0   0]]\n",
      "rewardsum:  39.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   2   0   0]]\n",
      "rewardsum:  43.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   3   0   0]]\n",
      "rewardsum:  46.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [74, 33, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[74 33  4  0  0]]\n",
      "rewardsum:  48.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   5   0   0]]\n",
      "rewardsum:  51.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  54.0\n",
      "Time Slot: 18\n",
      "Rnd\n",
      "actionVec: [41, 44, 25, 81, 100]\n",
      "next_state: [100, 32, 4, 5, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   5   0]]\n",
      "rewardsum:  55.0\n",
      "Time Slot: 19\n",
      "Rnd\n",
      "actionVec: [6, 65, 77, 28, 100]\n",
      "next_state: [100, 35, 2, 6, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   6   0]]\n",
      "rewardsum:  57.0\n",
      "Time Slot: 20\n",
      "Rnd\n",
      "actionVec: [26, 65, 96, 50, 100]\n",
      "next_state: [100, 37, 2, 5, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   5   0]]\n",
      "rewardsum:  60.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 1, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  1  0  0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 22\n",
      "Rnd\n",
      "actionVec: [79, 89, 79, 35, 100]\n",
      "next_state: [100, 31, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   0   0   0]]\n",
      "rewardsum:  72.0\n",
      "Time Slot: 23\n",
      "Rnd\n",
      "actionVec: [84, 70, 7, 21, 100]\n",
      "next_state: [100, 28, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   0   0   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 24\n",
      "Rnd\n",
      "actionVec: [90, 28, 93, 56, 100]\n",
      "next_state: [97, 21, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 21  8  0  0]]\n",
      "rewardsum:  78.0\n",
      "Time Slot: 25\n",
      "Rnd\n",
      "actionVec: [59, 67, 80, 52, 100]\n",
      "next_state: [100, 19, 7, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   7   2   0]]\n",
      "rewardsum:  81.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21   7   0   0]]\n",
      "rewardsum:  85.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   6   0   0]]\n",
      "rewardsum:  88.0\n",
      "Time Slot: 28\n",
      "Rnd\n",
      "actionVec: [12, 22, 87, 56, 100]\n",
      "next_state: [100, 24, 10, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  10   2   0]]\n",
      "rewardsum:  89.0\n",
      "Time Slot: 29\n",
      "Rnd\n",
      "actionVec: [31, 1, 22, 54, 100]\n",
      "next_state: [97, 10, 22, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 10 22  0  0]]\n",
      "rewardsum:  91.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [87, 15, 24, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[87 15 24  0  0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 24, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  24   0   0]]\n",
      "rewardsum:  96.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 26, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  26   1   0]]\n",
      "rewardsum:  98.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 26, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  26   0   0]]\n",
      "rewardsum:  100.0\n",
      "Time Slot: 34\n",
      "Rnd\n",
      "actionVec: [47, 33, 85, 30, 100]\n",
      "next_state: [100, 29, 18, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  18   1   0]]\n",
      "rewardsum:  102.0\n",
      "Time Slot: 35\n",
      "Rnd\n",
      "actionVec: [52, 43, 30, 69, 100]\n",
      "next_state: [96, 30, 17, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 30 17  1  0]]\n",
      "rewardsum:  105.0\n",
      "Time Slot: 36\n",
      "Rnd\n",
      "actionVec: [0, 24, 27, 30, 100]\n",
      "next_state: [84, 27, 16, 3, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[84 27 16  3  0]]\n",
      "rewardsum:  109.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 18, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  18   1   0]]\n",
      "rewardsum:  114.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 18, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  18   0   0]]\n",
      "rewardsum:  117.0\n",
      "Time Slot: 39\n",
      "Rnd\n",
      "actionVec: [30, 94, 61, 58, 100]\n",
      "next_state: [100, 24, 18, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  18   0   0]]\n",
      "rewardsum:  120.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 17, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  17   1   0]]\n",
      "rewardsum:  123.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 15, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  15   0   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  14   0   0]]\n",
      "rewardsum:  131.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 29, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 29 13  0  0]]\n",
      "rewardsum:  135.0\n",
      "Time Slot: 44\n",
      "Rnd\n",
      "actionVec: [8, 6, 38, 99, 100]\n",
      "next_state: [100, 32, 11, 3, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  11   3   0]]\n",
      "rewardsum:  136.0\n",
      "Time Slot: 45\n",
      "Rnd\n",
      "actionVec: [16, 49, 60, 93, 100]\n",
      "next_state: [100, 37, 10, 3, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  10   3   0]]\n",
      "rewardsum:  138.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 36, 12, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 36 12  0  0]]\n",
      "rewardsum:  143.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  12   0   0]]\n",
      "rewardsum:  147.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  10   0   0]]\n",
      "rewardsum:  150.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 8, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   8   0   0]]\n",
      "rewardsum:  155.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   6   0   0]]\n",
      "rewardsum:  158.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   7   0   0]]\n",
      "rewardsum:  160.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   7   0   0]]\n",
      "rewardsum:  164.0\n",
      "Time Slot: 53\n",
      "Rnd\n",
      "actionVec: [40, 98, 69, 91, 100]\n",
      "next_state: [100, 35, 5, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   5   1   0]]\n",
      "rewardsum:  167.0\n",
      "Time Slot: 54\n",
      "Rnd\n",
      "actionVec: [67, 21, 31, 98, 100]\n",
      "next_state: [99, 27, 11, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 27 11  2  0]]\n",
      "rewardsum:  169.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  11   0   0]]\n",
      "rewardsum:  173.0\n",
      "Time Slot: 56\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  11   0   0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  12   0   0]]\n",
      "rewardsum:  178.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  12   0   0]]\n",
      "rewardsum:  180.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  10   0   0]]\n",
      "rewardsum:  184.0\n",
      "Time Slot: 60\n",
      "Rnd\n",
      "actionVec: [28, 98, 50, 23, 100]\n",
      "next_state: [100, 41, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   8   0   0]]\n",
      "rewardsum:  187.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   6   0   0]]\n",
      "rewardsum:  190.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   5   0   0]]\n",
      "rewardsum:  193.0\n",
      "Time Slot: 63\n",
      "Rnd\n",
      "actionVec: [25, 21, 16, 6, 100]\n",
      "next_state: [100, 36, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   0   0   0]]\n",
      "rewardsum:  197.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  201.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   0   0]]\n",
      "rewardsum:  203.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   3   0   0]]\n",
      "rewardsum:  206.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   3   0   0]]\n",
      "rewardsum:  209.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   3   0   0]]\n",
      "rewardsum:  212.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   5   0   0]]\n",
      "rewardsum:  214.0\n",
      "Time Slot: 70\n",
      "Rnd\n",
      "actionVec: [10, 75, 40, 82, 100]\n",
      "next_state: [100, 39, 2, 5, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   2   5   0]]\n",
      "rewardsum:  214.0\n",
      "Time Slot: 71\n",
      "Rnd\n",
      "actionVec: [57, 51, 88, 50, 100]\n",
      "next_state: [100, 37, 4, 4, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   4   4   0]]\n",
      "rewardsum:  217.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 34, 5, 1, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 34  5  1  0]]\n",
      "rewardsum:  223.0\n",
      "Time Slot: 73\n",
      "Rnd\n",
      "actionVec: [23, 10, 0, 76, 100]\n",
      "next_state: [100, 28, 16, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  16   0   0]]\n",
      "rewardsum:  224.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  15   0   0]]\n",
      "rewardsum:  227.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  14   0   0]]\n",
      "rewardsum:  230.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 26, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 26 14  0  0]]\n",
      "rewardsum:  233.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 12, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  12   0   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  12   0   0]]\n",
      "rewardsum:  240.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 34, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 34 13  0  0]]\n",
      "rewardsum:  242.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  14   0   0]]\n",
      "rewardsum:  245.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 14, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  14   1   0]]\n",
      "rewardsum:  248.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  12   0   0]]\n",
      "rewardsum:  252.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  12   0   0]]\n",
      "rewardsum:  255.0\n",
      "Time Slot: 84\n",
      "Rnd\n",
      "actionVec: [46, 71, 53, 69, 100]\n",
      "next_state: [100, 33, 9, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   9   2   0]]\n",
      "rewardsum:  258.0\n",
      "Time Slot: 85\n",
      "Rnd\n",
      "actionVec: [13, 92, 46, 78, 100]\n",
      "next_state: [100, 33, 5, 6, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   6   0]]\n",
      "rewardsum:  259.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  267.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   4   0   0]]\n",
      "rewardsum:  271.0\n",
      "Time Slot: 88\n",
      "Rnd\n",
      "actionVec: [95, 51, 19, 57, 100]\n",
      "next_state: [95, 27, 0, 3, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 27  0  3  0]]\n",
      "rewardsum:  275.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   4   0   0]]\n",
      "rewardsum:  279.0\n",
      "Time Slot: 90\n",
      "Rnd\n",
      "actionVec: [30, 29, 11, 20, 100]\n",
      "next_state: [95, 21, 0, 2, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 21  0  2  0]]\n",
      "rewardsum:  284.0\n",
      "Time Slot: 91\n",
      "Rnd\n",
      "actionVec: [92, 40, 53, 82, 100]\n",
      "next_state: [99, 20, 1, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 20  1  2  0]]\n",
      "rewardsum:  286.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [88, 19, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[88 19  4  0  0]]\n",
      "rewardsum:  291.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   4   0   0]]\n",
      "rewardsum:  294.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 28, 4, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 28  4  0  0]]\n",
      "rewardsum:  295.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   4   0   0]]\n",
      "rewardsum:  299.0\n",
      "Time Slot: 96\n",
      "Rnd\n",
      "actionVec: [57, 21, 35, 95, 100]\n",
      "next_state: [63, 26, 9, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[63 26  9  2  0]]\n",
      "rewardsum:  300.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  12   0   0]]\n",
      "rewardsum:  304.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  12   0   0]]\n",
      "rewardsum:  306.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 15, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  15   0   0]]\n",
      "rewardsum:  307.0\n",
      "Episode: 12\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  6404\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [85, 8, 2, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[85  8  2  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 12, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12   1   0   0]]\n",
      "rewardsum:  3.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 14, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   3   0   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   2   0   0]]\n",
      "rewardsum:  9.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   2   0   0]]\n",
      "rewardsum:  12.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   0   0   0]]\n",
      "rewardsum:  16.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 0, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   0   0   0]]\n",
      "rewardsum:  17.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   0   0   0]]\n",
      "rewardsum:  20.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   1   0   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   0   0   0]]\n",
      "rewardsum:  26.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [95, 43, 2, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 43  2  0  0]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewardsum:  27.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   0   0   0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 12\n",
      "Rnd\n",
      "actionVec: [39, 98, 91, 78, 100]\n",
      "next_state: [100, 44, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  44   1   0   0]]\n",
      "rewardsum:  32.0\n",
      "Time Slot: 13\n",
      "Rnd\n",
      "actionVec: [3, 14, 29, 9, 100]\n",
      "next_state: [100, 51, 2, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  51   2   0   0]]\n",
      "rewardsum:  32.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 52, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  52   0   0   0]]\n",
      "rewardsum:  36.0\n",
      "Time Slot: 15\n",
      "Rnd\n",
      "actionVec: [59, 21, 39, 45, 100]\n",
      "next_state: [100, 43, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43   5   0   0]]\n",
      "rewardsum:  38.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 3, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   3   0   0]]\n",
      "rewardsum:  43.0\n",
      "Time Slot: 17\n",
      "Rnd\n",
      "actionVec: [31, 57, 43, 64, 100]\n",
      "next_state: [100, 36, 2, 3, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   3   0]]\n",
      "rewardsum:  45.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 24, 5, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 24  5  0  0]]\n",
      "rewardsum:  50.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   4   0   0]]\n",
      "rewardsum:  53.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [88, 27, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[88 27  5  0  0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 21\n",
      "Rnd\n",
      "actionVec: [60, 69, 81, 40, 100]\n",
      "next_state: [100, 27, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   6   0   0]]\n",
      "rewardsum:  59.0\n",
      "Time Slot: 22\n",
      "Rnd\n",
      "actionVec: [9, 10, 49, 24, 100]\n",
      "next_state: [100, 20, 15, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20  15   1   0]]\n",
      "rewardsum:  60.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 14, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  14   1   0]]\n",
      "rewardsum:  63.0\n",
      "Time Slot: 24\n",
      "Rnd\n",
      "actionVec: [44, 81, 78, 88, 100]\n",
      "next_state: [100, 29, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  15   0   0]]\n",
      "rewardsum:  66.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [82, 25, 14, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[82 25 14  1  0]]\n",
      "rewardsum:  70.0\n",
      "Time Slot: 26\n",
      "Rnd\n",
      "actionVec: [44, 43, 63, 1, 100]\n",
      "next_state: [100, 25, 15, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  15   0   0]]\n",
      "rewardsum:  74.0\n",
      "Time Slot: 27\n",
      "Rnd\n",
      "actionVec: [56, 47, 55, 47, 100]\n",
      "next_state: [95, 26, 11, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 26 11  1  0]]\n",
      "rewardsum:  79.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  11   0   0]]\n",
      "rewardsum:  83.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 24, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 24 10  0  0]]\n",
      "rewardsum:  86.0\n",
      "Time Slot: 30\n",
      "Rnd\n",
      "actionVec: [45, 43, 54, 74, 100]\n",
      "next_state: [100, 22, 13, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22  13   1   0]]\n",
      "rewardsum:  89.0\n",
      "Time Slot: 31\n",
      "Rnd\n",
      "actionVec: [25, 1, 71, 34, 100]\n",
      "next_state: [57, 9, 26, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[57  9 26  1  0]]\n",
      "rewardsum:  89.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 10, 30, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10  30   0   0]]\n",
      "rewardsum:  92.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 15, 30, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15  30   0   0]]\n",
      "rewardsum:  95.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 28, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  28   1   0]]\n",
      "rewardsum:  98.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 26, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  26   0   0]]\n",
      "rewardsum:  102.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  16   0   0]]\n",
      "rewardsum:  105.0\n",
      "Time Slot: 37\n",
      "Rnd\n",
      "actionVec: [50, 60, 95, 3, 100]\n",
      "next_state: [100, 29, 14, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  14   0   0]]\n",
      "rewardsum:  109.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  13   0   0]]\n",
      "rewardsum:  111.0\n",
      "Time Slot: 39\n",
      "Rnd\n",
      "actionVec: [34, 18, 2, 38, 100]\n",
      "next_state: [100, 29, 1, 13, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   1  13   0]]\n",
      "rewardsum:  111.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 3, 4, 0]\n",
      "Reward: 9.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   3   4   0]]\n",
      "rewardsum:  120.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 3, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   3   0   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   2   0   0]]\n",
      "rewardsum:  131.0\n",
      "Time Slot: 43\n",
      "Rnd\n",
      "actionVec: [51, 90, 31, 94, 100]\n",
      "next_state: [100, 22, 1, 3, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   1   3   0]]\n",
      "rewardsum:  132.0\n",
      "Time Slot: 44\n",
      "Rnd\n",
      "actionVec: [67, 43, 0, 83, 100]\n",
      "next_state: [100, 19, 1, 5, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   1   5   0]]\n",
      "rewardsum:  135.0\n",
      "Time Slot: 45\n",
      "Rnd\n",
      "actionVec: [55, 4, 73, 21, 100]\n",
      "next_state: [93, 8, 10, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[93  8 10  1  0]]\n",
      "rewardsum:  140.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 9, 11, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   9  11   0   0]]\n",
      "rewardsum:  145.0\n",
      "Time Slot: 47\n",
      "Rnd\n",
      "actionVec: [20, 66, 77, 14, 100]\n",
      "next_state: [100, 16, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16  11   0   0]]\n",
      "rewardsum:  147.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 18, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 18 13  0  0]]\n",
      "rewardsum:  149.0\n",
      "Time Slot: 49\n",
      "Rnd\n",
      "actionVec: [81, 9, 80, 20, 100]\n",
      "next_state: [97, 10, 20, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 10 20  1  0]]\n",
      "rewardsum:  151.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 13, 20, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13  20   0   0]]\n",
      "rewardsum:  155.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 19, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  19   0   0]]\n",
      "rewardsum:  157.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 20, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  20   0   0]]\n",
      "rewardsum:  160.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 23, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  23   0   0]]\n",
      "rewardsum:  162.0\n",
      "Time Slot: 54\n",
      "Rnd\n",
      "actionVec: [71, 81, 55, 82, 100]\n",
      "next_state: [100, 27, 17, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  17   1   0]]\n",
      "rewardsum:  166.0\n",
      "Time Slot: 55\n",
      "Rnd\n",
      "actionVec: [73, 27, 20, 49, 100]\n",
      "next_state: [100, 25, 13, 5, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  13   5   0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 56\n",
      "Rnd\n",
      "actionVec: [30, 55, 3, 95, 100]\n",
      "next_state: [76, 20, 0, 17, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[76 20  0 17  0]]\n",
      "rewardsum:  169.0\n",
      "Time Slot: 57\n",
      "Rnd\n",
      "actionVec: [46, 85, 58, 95, 100]\n",
      "next_state: [100, 20, 2, 19, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   2  19   0]]\n",
      "rewardsum:  171.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [92, 16, 3, 10, 0]\n",
      "Reward: 9.0\n",
      "----------------- \n",
      "\n",
      "state:  [[92 16  3 10  0]]\n",
      "rewardsum:  180.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 15, 4, 0, 0]\n",
      "Reward: 11.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15   4   0   0]]\n",
      "rewardsum:  191.0\n",
      "Time Slot: 60\n",
      "Rnd\n",
      "actionVec: [58, 34, 16, 90, 100]\n",
      "next_state: [100, 13, 0, 5, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13   0   5   0]]\n",
      "rewardsum:  194.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 15, 0, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15   0   0   0]]\n",
      "rewardsum:  201.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 17, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   1   0   0]]\n",
      "rewardsum:  204.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   3   0   0]]\n",
      "rewardsum:  206.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 27, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 27  1  0  0]]\n",
      "rewardsum:  210.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   0   0   0]]\n",
      "rewardsum:  213.0\n",
      "Time Slot: 66\n",
      "Rnd\n",
      "actionVec: [22, 72, 2, 68, 100]\n",
      "next_state: [100, 37, 0, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   0   1   0]]\n",
      "rewardsum:  215.0\n",
      "Time Slot: 67\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   3   0   0]]\n",
      "rewardsum:  217.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 39, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 39  4  0  0]]\n",
      "rewardsum:  219.0\n",
      "Time Slot: 69\n",
      "Rnd\n",
      "actionVec: [20, 2, 53, 43, 100]\n",
      "next_state: [100, 25, 17, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  17   0   0]]\n",
      "rewardsum:  219.0\n",
      "Time Slot: 70\n",
      "Rnd\n",
      "actionVec: [68, 50, 41, 66, 100]\n",
      "next_state: [100, 24, 19, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  19   2   0]]\n",
      "rewardsum:  222.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 26, 17, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 26 17  0  0]]\n",
      "rewardsum:  227.0\n",
      "Time Slot: 72\n",
      "Rnd\n",
      "actionVec: [67, 7, 32, 15, 100]\n",
      "next_state: [100, 13, 28, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13  28   0   0]]\n",
      "rewardsum:  228.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 30, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18  30   0   0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 25, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  25   0   0]]\n",
      "rewardsum:  233.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 25, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  25   0   0]]\n",
      "rewardsum:  235.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 25, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  25   0   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [45, 35, 14, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[45 35 14  0  0]]\n",
      "rewardsum:  242.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  15   0   0]]\n",
      "rewardsum:  244.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  15   0   0]]\n",
      "rewardsum:  247.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  13   0   0]]\n",
      "rewardsum:  250.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  14   0   0]]\n",
      "rewardsum:  252.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  13   0   0]]\n",
      "rewardsum:  256.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  11   0   0]]\n",
      "rewardsum:  258.0\n",
      "Time Slot: 84\n",
      "Rnd\n",
      "actionVec: [49, 30, 35, 76, 100]\n",
      "next_state: [100, 35, 14, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  14   2   0]]\n",
      "rewardsum:  259.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 15, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  15   0   0]]\n",
      "rewardsum:  263.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  13   0   0]]\n",
      "rewardsum:  267.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  12   0   0]]\n",
      "rewardsum:  270.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  11   0   0]]\n",
      "rewardsum:  273.0\n",
      "Time Slot: 89\n",
      "Rnd\n",
      "actionVec: [65, 12, 63, 32, 100]\n",
      "next_state: [98, 25, 19, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 25 19  0  0]]\n",
      "rewardsum:  275.0\n",
      "Time Slot: 90\n",
      "Rnd\n",
      "actionVec: [67, 90, 49, 22, 100]\n",
      "next_state: [100, 27, 18, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  18   1   0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 17, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  17   0   0]]\n",
      "rewardsum:  283.0\n",
      "Time Slot: 92\n",
      "Rnd\n",
      "actionVec: [46, 11, 36, 93, 100]\n",
      "next_state: [95, 18, 24, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 18 24  1  0]]\n",
      "rewardsum:  284.0\n",
      "Time Slot: 93\n",
      "Rnd\n",
      "actionVec: [48, 58, 36, 81, 100]\n",
      "next_state: [100, 15, 24, 3, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15  24   3   0]]\n",
      "rewardsum:  287.0\n",
      "Time Slot: 94\n",
      "Rnd\n",
      "actionVec: [84, 89, 78, 86, 100]\n",
      "next_state: [99, 16, 22, 4, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 16 22  4  0]]\n",
      "rewardsum:  290.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 16, 21, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16  21   0   0]]\n",
      "rewardsum:  297.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 18, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20  18   0   0]]\n",
      "rewardsum:  301.0\n",
      "Time Slot: 97\n",
      "Rnd\n",
      "actionVec: [92, 51, 31, 63, 100]\n",
      "next_state: [100, 17, 17, 5, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17  17   5   0]]\n",
      "rewardsum:  302.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [94, 18, 14, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[94 18 14  0  0]]\n",
      "rewardsum:  310.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 15, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18  15   0   0]]\n",
      "rewardsum:  314.0\n",
      "Episode: 13\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  9471\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [86, 5, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[86  5  0  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 10, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 14, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 3\n",
      "Rnd\n",
      "actionVec: [47, 98, 52, 40, 100]\n",
      "next_state: [100, 19, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 33, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 33  0  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 7\n",
      "Rnd\n",
      "actionVec: [10, 71, 84, 48, 100]\n",
      "next_state: [100, 50, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  50   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 55, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  55   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 57, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  57   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 55, 1, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  55   1   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 11\n",
      "Rnd\n",
      "actionVec: [43, 24, 92, 8, 100]\n",
      "next_state: [99, 48, 8, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 48  8  1  0]]\n",
      "rewardsum:  1.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 42, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 42 10  0  0]]\n",
      "rewardsum:  4.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  12   0   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 35, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 35 11  0  0]]\n",
      "rewardsum:  9.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 29, 9, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 29  9  0  0]]\n",
      "rewardsum:  14.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   9   0   0]]\n",
      "rewardsum:  17.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 30, 6, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 30  6  0  0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 18\n",
      "Rnd\n",
      "actionVec: [19, 74, 84, 0, 100]\n",
      "next_state: [100, 34, 5, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   5   0   0]]\n",
      "rewardsum:  23.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  27.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   7   0   0]]\n",
      "rewardsum:  29.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  38   8   0   0]]\n",
      "rewardsum:  31.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   9   0   0]]\n",
      "rewardsum:  33.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   8   0   0]]\n",
      "rewardsum:  36.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   6   0   0]]\n",
      "rewardsum:  40.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [75, 35, 6, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[75 35  6  1  0]]\n",
      "rewardsum:  42.0\n",
      "Time Slot: 26\n",
      "Rnd\n",
      "actionVec: [64, 70, 98, 10, 100]\n",
      "next_state: [99, 31, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  4  0  0]]\n",
      "rewardsum:  47.0\n",
      "Time Slot: 27\n",
      "Rnd\n",
      "actionVec: [47, 39, 66, 51, 100]\n",
      "next_state: [100, 26, 7, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   7   2   0]]\n",
      "rewardsum:  49.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   9   0   0]]\n",
      "rewardsum:  53.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   9   0   0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 30\n",
      "Rnd\n",
      "actionVec: [10, 0, 43, 93, 100]\n",
      "next_state: [100, 34, 7, 3, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   7   3   0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 7, 2, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   7   2   0]]\n",
      "rewardsum:  60.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   6   0   0]]\n",
      "rewardsum:  64.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   9   0   0]]\n",
      "rewardsum:  67.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 5, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   5   0   0]]\n",
      "rewardsum:  72.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 31, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 31  6  0  0]]\n",
      "rewardsum:  74.0\n",
      "Time Slot: 36\n",
      "Rnd\n",
      "actionVec: [87, 44, 0, 95, 100]\n",
      "next_state: [99, 27, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 27 10  0  0]]\n",
      "rewardsum:  77.0\n",
      "Time Slot: 37\n",
      "Rnd\n",
      "actionVec: [74, 50, 78, 97, 100]\n",
      "next_state: [100, 25, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  13   0   0]]\n",
      "rewardsum:  79.0\n",
      "Time Slot: 38\n",
      "Rnd\n",
      "actionVec: [99, 90, 63, 1, 100]\n",
      "next_state: [99, 24, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 24 13  0  0]]\n",
      "rewardsum:  83.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 17, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  17   0   0]]\n",
      "rewardsum:  85.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 15, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  15   1   0]]\n",
      "rewardsum:  88.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 14, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  14   0   0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  14   0   0]]\n",
      "rewardsum:  95.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 12, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  12   0   0]]\n",
      "rewardsum:  100.0\n",
      "Time Slot: 44\n",
      "Rnd\n",
      "actionVec: [32, 62, 76, 33, 100]\n",
      "next_state: [100, 31, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  15   0   0]]\n",
      "rewardsum:  102.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 14, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  14   1   0]]\n",
      "rewardsum:  105.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 14, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  14   0   0]]\n",
      "rewardsum:  109.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  13   0   0]]\n",
      "rewardsum:  112.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 17, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  17   0   0]]\n",
      "rewardsum:  114.0\n",
      "Time Slot: 49\n",
      "Rnd\n",
      "actionVec: [86, 63, 27, 65, 100]\n",
      "next_state: [96, 31, 13, 5, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 31 13  5  0]]\n",
      "rewardsum:  116.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 13, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  13   0   0]]\n",
      "rewardsum:  123.0\n",
      "Time Slot: 51\n",
      "Rnd\n",
      "actionVec: [63, 88, 49, 45, 100]\n",
      "next_state: [79, 28, 10, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[79 28 10  2  0]]\n",
      "rewardsum:  126.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 28, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 28 10  0  0]]\n",
      "rewardsum:  130.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 27, 10, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 27 10  1  0]]\n",
      "rewardsum:  133.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  12   0   0]]\n",
      "rewardsum:  136.0\n",
      "Time Slot: 55\n",
      "Rnd\n",
      "actionVec: [93, 99, 70, 10, 100]\n",
      "next_state: [100, 28, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  11   0   0]]\n",
      "rewardsum:  140.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  14   0   0]]\n",
      "rewardsum:  142.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  13   0   0]]\n",
      "rewardsum:  146.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  15   0   0]]\n",
      "rewardsum:  148.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  16   0   0]]\n",
      "rewardsum:  151.0\n",
      "Time Slot: 60\n",
      "Rnd\n",
      "actionVec: [58, 51, 55, 60, 100]\n",
      "next_state: [100, 31, 15, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  15   1   0]]\n",
      "rewardsum:  154.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 14, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  14   0   0]]\n",
      "rewardsum:  159.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  15   0   0]]\n",
      "rewardsum:  162.0\n",
      "Time Slot: 63\n",
      "Rnd\n",
      "actionVec: [67, 7, 9, 97, 100]\n",
      "next_state: [96, 26, 17, 4, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 26 17  4  0]]\n",
      "rewardsum:  162.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 16, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  16   0   0]]\n",
      "rewardsum:  169.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  16   0   0]]\n",
      "rewardsum:  172.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 29, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 29 15  0  0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 28, 14, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 28 14  0  0]]\n",
      "rewardsum:  179.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 13, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  13   0   0]]\n",
      "rewardsum:  180.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 38, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 38 12  0  0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  12   0   0]]\n",
      "rewardsum:  185.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41  11   0   0]]\n",
      "rewardsum:  187.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 44, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  44  10   0   0]]\n",
      "rewardsum:  190.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   9   0   0]]\n",
      "rewardsum:  194.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   7   0   0]]\n",
      "rewardsum:  197.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   6   0   0]]\n",
      "rewardsum:  200.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   5   0   0]]\n",
      "rewardsum:  203.0\n",
      "Time Slot: 77\n",
      "Rnd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [62, 82, 57, 89, 100]\n",
      "next_state: [100, 31, 3, 3, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   3   3   0]]\n",
      "rewardsum:  206.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  4  0  0]]\n",
      "rewardsum:  211.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   2   0   0]]\n",
      "rewardsum:  215.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   3   0   0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 81\n",
      "Rnd\n",
      "actionVec: [83, 54, 84, 77, 100]\n",
      "next_state: [98, 25, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 25  6  0  0]]\n",
      "rewardsum:  220.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 24, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 24  4  0  0]]\n",
      "rewardsum:  225.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   4   0   0]]\n",
      "rewardsum:  229.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21   5   0   0]]\n",
      "rewardsum:  232.0\n",
      "Time Slot: 85\n",
      "Rnd\n",
      "actionVec: [77, 4, 54, 53, 100]\n",
      "next_state: [94, 12, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[94 12 12  0  0]]\n",
      "rewardsum:  234.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 16, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16  14   0   0]]\n",
      "rewardsum:  236.0\n",
      "Time Slot: 87\n",
      "Rnd\n",
      "actionVec: [11, 97, 76, 33, 100]\n",
      "next_state: [100, 24, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  14   0   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 29, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 29 13  0  0]]\n",
      "rewardsum:  241.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 17, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  17   0   0]]\n",
      "rewardsum:  243.0\n",
      "Time Slot: 90\n",
      "Rnd\n",
      "actionVec: [19, 93, 58, 67, 100]\n",
      "next_state: [100, 38, 16, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  16   0   0]]\n",
      "rewardsum:  245.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 14, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41  14   0   0]]\n",
      "rewardsum:  249.0\n",
      "Time Slot: 92\n",
      "Rnd\n",
      "actionVec: [26, 31, 23, 11, 100]\n",
      "next_state: [100, 38, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  14   0   0]]\n",
      "rewardsum:  252.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  14   0   0]]\n",
      "rewardsum:  254.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 36, 13, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 36 13  1  0]]\n",
      "rewardsum:  258.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  13   0   0]]\n",
      "rewardsum:  262.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  14   0   0]]\n",
      "rewardsum:  265.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 31, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 31 11  0  0]]\n",
      "rewardsum:  269.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 13, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  13   1   0]]\n",
      "rewardsum:  271.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  13   0   0]]\n",
      "rewardsum:  274.0\n",
      "Episode: 14\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  6410\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [80, 6, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[80  6  0  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 10, 1, 0, 1]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10   1   0   1]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 10, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10   4   0   0]]\n",
      "rewardsum:  4.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 14, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   5   0   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 17, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   7   0   0]]\n",
      "rewardsum:  9.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 22, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 22  6  0  0]]\n",
      "rewardsum:  12.0\n",
      "Time Slot: 6\n",
      "Rnd\n",
      "actionVec: [48, 17, 95, 5, 100]\n",
      "next_state: [100, 20, 13, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20  13   0   0]]\n",
      "rewardsum:  13.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   9   0   0]]\n",
      "rewardsum:  17.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 10, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  10   1   0]]\n",
      "rewardsum:  20.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 11, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  11   1   0]]\n",
      "rewardsum:  23.0\n",
      "Time Slot: 10\n",
      "Rnd\n",
      "actionVec: [80, 88, 97, 79, 100]\n",
      "next_state: [70, 29, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[70 29 13  0  0]]\n",
      "rewardsum:  26.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  13   0   0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 12\n",
      "Rnd\n",
      "actionVec: [81, 71, 99, 10, 100]\n",
      "next_state: [100, 26, 14, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  14   1   0]]\n",
      "rewardsum:  33.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 13, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  13   0   0]]\n",
      "rewardsum:  38.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  11   0   0]]\n",
      "rewardsum:  41.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   9   0   0]]\n",
      "rewardsum:  45.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  10   0   0]]\n",
      "rewardsum:  48.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   9   0   0]]\n",
      "rewardsum:  50.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  13   0   0]]\n",
      "rewardsum:  53.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  14   0   0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 20\n",
      "Rnd\n",
      "actionVec: [94, 58, 48, 59, 100]\n",
      "next_state: [98, 32, 13, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 32 13  2  0]]\n",
      "rewardsum:  58.0\n",
      "Time Slot: 21\n",
      "Rnd\n",
      "actionVec: [95, 48, 13, 31, 100]\n",
      "next_state: [100, 27, 6, 6, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   6   6   0]]\n",
      "rewardsum:  63.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 7, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   7   0   0]]\n",
      "rewardsum:  71.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   6   0   0]]\n",
      "rewardsum:  73.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   7   0   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   5   0   0]]\n",
      "rewardsum:  80.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   8   0   0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 27\n",
      "Rnd\n",
      "actionVec: [73, 86, 39, 84, 100]\n",
      "next_state: [100, 32, 5, 5, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   5   0]]\n",
      "rewardsum:  83.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 3, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  29   3   0   0]]\n",
      "rewardsum:  91.0\n",
      "Time Slot: 29\n",
      "Rnd\n",
      "actionVec: [63, 29, 49, 52, 100]\n",
      "next_state: [100, 24, 4, 4, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   4   4   0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 4, 1, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   4   1   0]]\n",
      "rewardsum:  99.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21   4   0   0]]\n",
      "rewardsum:  103.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   3   0   0]]\n",
      "rewardsum:  106.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   5   0   0]]\n",
      "rewardsum:  108.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  111.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   3   0   0]]\n",
      "rewardsum:  114.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [46, 36, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[46 36  2  0  0]]\n",
      "rewardsum:  117.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  121.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   0   0   0]]\n",
      "rewardsum:  124.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  126.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 43, 3, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43   3   0   0]]\n",
      "rewardsum:  129.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 43, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43   2   0   0]]\n",
      "rewardsum:  133.0\n",
      "Time Slot: 43\n",
      "Rnd\n",
      "actionVec: [30, 66, 7, 71, 100]\n",
      "next_state: [100, 41, 1, 3, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   1   3   0]]\n",
      "rewardsum:  134.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 2, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   2   0   0]]\n",
      "rewardsum:  139.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  143.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 33, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 33  3  0  0]]\n",
      "rewardsum:  145.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  149.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  152.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   0   0]]\n",
      "rewardsum:  155.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   1   0]]\n",
      "rewardsum:  157.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   3   0   0]]\n",
      "rewardsum:  160.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  164.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  166.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  169.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   0   0   0]]\n",
      "rewardsum:  174.0\n",
      "Time Slot: 56\n",
      "Rnd\n",
      "actionVec: [88, 26, 31, 69, 100]\n",
      "next_state: [100, 27, 1, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   1   2   0]]\n",
      "rewardsum:  176.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 2, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   2   1   0]]\n",
      "rewardsum:  180.0\n",
      "Time Slot: 58\n",
      "Rnd\n",
      "actionVec: [84, 83, 7, 82, 100]\n",
      "next_state: [100, 25, 0, 5, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   0   5   0]]\n",
      "rewardsum:  181.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 0, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   0   0   0]]\n",
      "rewardsum:  189.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   0   0   0]]\n",
      "rewardsum:  192.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   0   0   0]]\n",
      "rewardsum:  194.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  196.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   0   0   0]]\n",
      "rewardsum:  200.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 0, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   0   0   0]]\n",
      "rewardsum:  201.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 43, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43   0   0   0]]\n",
      "rewardsum:  204.0\n",
      "Time Slot: 66\n",
      "Rnd\n",
      "actionVec: [91, 11, 33, 57, 100]\n",
      "next_state: [91, 33, 4, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[91 33  4  2  0]]\n",
      "rewardsum:  206.0\n",
      "Time Slot: 67\n",
      "Rnd\n",
      "actionVec: [57, 79, 86, 22, 100]\n",
      "next_state: [100, 27, 6, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   6   0   0]]\n",
      "rewardsum:  211.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 28, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 28  4  0  0]]\n",
      "rewardsum:  216.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 5, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   5   1   0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 70\n",
      "Rnd\n",
      "actionVec: [78, 86, 58, 67, 100]\n",
      "next_state: [99, 19, 3, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 19  3  1  0]]\n",
      "rewardsum:  222.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   3   0   0]]\n",
      "rewardsum:  226.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 27, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 27  3  0  0]]\n",
      "rewardsum:  229.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   3   0   0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 74\n",
      "Rnd\n",
      "actionVec: [56, 82, 34, 91, 100]\n",
      "next_state: [99, 29, 1, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 29  1  1  0]]\n",
      "rewardsum:  235.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 1, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   1   0   0]]\n",
      "rewardsum:  240.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   2   0   0]]\n",
      "rewardsum:  243.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   1   0   0]]\n",
      "rewardsum:  247.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   2   0   0]]\n",
      "rewardsum:  249.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   0   0]]\n",
      "rewardsum:  251.0\n",
      "Time Slot: 80\n",
      "Rnd\n",
      "actionVec: [45, 49, 21, 82, 100]\n",
      "next_state: [100, 33, 0, 5, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   0   5   0]]\n",
      "rewardsum:  253.0\n",
      "Time Slot: 81\n",
      "Rnd\n",
      "actionVec: [91, 73, 34, 40, 100]\n",
      "next_state: [96, 30, 0, 3, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 30  0  3  0]]\n",
      "rewardsum:  258.0\n",
      "Time Slot: 82\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  263.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   3   0   0]]\n",
      "rewardsum:  265.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   2   0   0]]\n",
      "rewardsum:  268.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   0   0   0]]\n",
      "rewardsum:  272.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   0   0]]\n",
      "rewardsum:  275.0\n",
      "Time Slot: 87\n",
      "Rnd\n",
      "actionVec: [27, 38, 68, 40, 100]\n",
      "next_state: [100, 35, 3, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   1   0]]\n",
      "rewardsum:  276.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  3  0  0]]\n",
      "rewardsum:  280.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 30, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 30  1  0  0]]\n",
      "rewardsum:  284.0\n",
      "Time Slot: 90\n",
      "Rnd\n",
      "actionVec: [67, 17, 86, 64, 100]\n",
      "next_state: [98, 24, 10, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 24 10  0  0]]\n",
      "rewardsum:  285.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 8, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   8   0   0]]\n",
      "rewardsum:  290.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   9   0   0]]\n",
      "rewardsum:  293.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  11   0   0]]\n",
      "rewardsum:  295.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   9   0   0]]\n",
      "rewardsum:  298.0\n",
      "Time Slot: 95\n",
      "Rnd\n",
      "actionVec: [98, 34, 58, 1, 100]\n",
      "next_state: [100, 28, 9, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   9   0   0]]\n",
      "rewardsum:  303.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  10   0   0]]\n",
      "rewardsum:  306.0\n",
      "Time Slot: 97\n",
      "Rnd\n",
      "actionVec: [13, 2, 96, 18, 100]\n",
      "next_state: [45, 15, 24, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[45 15 24  0  0]]\n",
      "rewardsum:  307.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 17, 25, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17  25   0   0]]\n",
      "rewardsum:  310.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 25, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  25   0   0]]\n",
      "rewardsum:  313.0\n",
      "Episode: 15\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  7227\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Rnd\n",
      "actionVec: [15, 44, 2, 2, 100]\n",
      "next_state: [90, 7, 0, 0, 1]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[90  7  0  0  1]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 11, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11   1   0   0]]\n",
      "rewardsum:  3.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 13, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13   4   0   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 3\n",
      "Rnd\n",
      "actionVec: [95, 19, 3, 77, 100]\n",
      "next_state: [100, 10, 0, 9, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10   0   9   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 11, 2, 2, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11   2   2   0]]\n",
      "rewardsum:  14.0\n",
      "Time Slot: 5\n",
      "Rnd\n",
      "actionVec: [90, 75, 32, 4, 100]\n",
      "next_state: [77, 9, 1, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[77  9  1  1  0]]\n",
      "rewardsum:  19.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 15, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15   0   0   0]]\n",
      "rewardsum:  23.0\n",
      "Time Slot: 7\n",
      "Rnd\n",
      "actionVec: [97, 91, 53, 10, 100]\n",
      "next_state: [100, 16, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   1   0   0]]\n",
      "rewardsum:  26.0\n",
      "Time Slot: 8\n",
      "Rnd\n",
      "actionVec: [72, 14, 81, 35, 100]\n",
      "next_state: [100, 11, 5, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11   5   1   0]]\n",
      "rewardsum:  29.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 13, 3, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13   3   0   0]]\n",
      "rewardsum:  34.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   0   0   0]]\n",
      "rewardsum:  37.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   0   0   0]]\n",
      "rewardsum:  41.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   0   0   0]]\n",
      "rewardsum:  44.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   1   0   0]]\n",
      "rewardsum:  47.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  50.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   0   0   0]]\n",
      "rewardsum:  53.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  55.0\n",
      "Time Slot: 17\n",
      "Rnd\n",
      "actionVec: [8, 89, 49, 23, 100]\n",
      "next_state: [100, 40, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   0   0   0]]\n",
      "rewardsum:  58.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  61.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   3   0   0]]\n",
      "rewardsum:  63.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 5, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   5   0   0]]\n",
      "rewardsum:  64.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 38, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 38  6  0  0]]\n",
      "rewardsum:  67.0\n",
      "Time Slot: 22\n",
      "Rnd\n",
      "actionVec: [40, 86, 89, 51, 100]\n",
      "next_state: [99, 36, 6, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 36  6  1  0]]\n",
      "rewardsum:  69.0\n",
      "Time Slot: 23\n",
      "Rnd\n",
      "actionVec: [25, 63, 0, 80, 100]\n",
      "next_state: [100, 38, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   8   0   0]]\n",
      "rewardsum:  72.0\n",
      "Time Slot: 24\n",
      "Rnd\n",
      "actionVec: [16, 71, 71, 84, 100]\n",
      "next_state: [100, 37, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   6   0   0]]\n",
      "rewardsum:  75.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [77, 35, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[77 35  8  0  0]]\n",
      "rewardsum:  78.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   8   0   0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  86.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   9   0   0]]\n",
      "rewardsum:  88.0\n",
      "Time Slot: 29\n",
      "Rnd\n",
      "actionVec: [3, 35, 5, 40, 100]\n",
      "next_state: [100, 36, 8, 3, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   8   3   0]]\n",
      "rewardsum:  88.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 7, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   7   0   0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 31\n",
      "Rnd\n",
      "actionVec: [97, 74, 28, 98, 100]\n",
      "next_state: [99, 34, 4, 5, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34  4  5  0]]\n",
      "rewardsum:  95.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 33, 2, 1, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 33  2  1  0]]\n",
      "rewardsum:  102.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 2, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   0   0]]\n",
      "rewardsum:  107.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   2   0   0]]\n",
      "rewardsum:  110.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  28   4   0   0]]\n",
      "rewardsum:  112.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 29, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 29  4  0  0]]\n",
      "rewardsum:  115.0\n",
      "Time Slot: 37\n",
      "Rnd\n",
      "actionVec: [40, 77, 89, 24, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  118.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  121.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   5   0   0]]\n",
      "rewardsum:  123.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 8, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   8   1   0]]\n",
      "rewardsum:  126.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   7   0   0]]\n",
      "rewardsum:  130.0\n",
      "Time Slot: 42\n",
      "Rnd\n",
      "actionVec: [76, 37, 65, 67, 100]\n",
      "next_state: [96, 26, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 26 14  0  0]]\n",
      "rewardsum:  132.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 16, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  16   1   0]]\n",
      "rewardsum:  134.0\n",
      "Time Slot: 44\n",
      "Rnd\n",
      "actionVec: [21, 59, 58, 54, 100]\n",
      "next_state: [100, 29, 14, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  14   2   0]]\n",
      "rewardsum:  137.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 15, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  15   0   0]]\n",
      "rewardsum:  141.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 15, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  15   1   0]]\n",
      "rewardsum:  143.0\n",
      "Time Slot: 47\n",
      "Rnd\n",
      "actionVec: [13, 80, 80, 60, 100]\n",
      "next_state: [100, 40, 14, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  14   1   0]]\n",
      "rewardsum:  145.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 11, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  11   1   0]]\n",
      "rewardsum:  149.0\n",
      "Time Slot: 49\n",
      "Rnd\n",
      "actionVec: [24, 22, 33, 84, 100]\n",
      "next_state: [99, 33, 13, 3, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33 13  3  0]]\n",
      "rewardsum:  151.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 17, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  17   0   0]]\n",
      "rewardsum:  156.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 27, 13, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 27 13  0  0]]\n",
      "rewardsum:  161.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 11, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  11   0   0]]\n",
      "rewardsum:  166.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  11   0   0]]\n",
      "rewardsum:  169.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  12   0   0]]\n",
      "rewardsum:  171.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  11   0   0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 56\n",
      "Rnd\n",
      "actionVec: [13, 5, 75, 86, 100]\n",
      "next_state: [100, 21, 23, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  23   0   0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 21, 25, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 21 25  0  0]]\n",
      "rewardsum:  178.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 24, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  24   0   0]]\n",
      "rewardsum:  180.0\n",
      "Time Slot: 59\n",
      "Rnd\n",
      "actionVec: [29, 74, 88, 84, 100]\n",
      "next_state: [100, 34, 24, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  24   1   0]]\n",
      "rewardsum:  181.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 20, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32 20  1  0]]\n",
      "rewardsum:  186.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  15   0   0]]\n",
      "rewardsum:  189.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  12   0   0]]\n",
      "rewardsum:  193.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  12   0   0]]\n",
      "rewardsum:  196.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 29, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 29 11  0  0]]\n",
      "rewardsum:  200.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  11   0   0]]\n",
      "rewardsum:  203.0\n",
      "Time Slot: 66\n",
      "Rnd\n",
      "actionVec: [98, 87, 38, 54, 100]\n",
      "next_state: [98, 27, 7, 4, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 27  7  4  0]]\n",
      "rewardsum:  206.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 7, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   7   0   0]]\n",
      "rewardsum:  213.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 26, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 26  7  0  0]]\n",
      "rewardsum:  216.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 7, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   7   1   0]]\n",
      "rewardsum:  219.0\n",
      "Time Slot: 70\n",
      "Rnd\n",
      "actionVec: [19, 16, 83, 18, 100]\n",
      "next_state: [98, 20, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 20 13  0  0]]\n",
      "rewardsum:  222.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  15   0   0]]\n",
      "rewardsum:  224.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 24, 15, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 24 15  0  0]]\n",
      "rewardsum:  228.0\n",
      "Time Slot: 73\n",
      "Rnd\n",
      "actionVec: [37, 64, 70, 20, 100]\n",
      "next_state: [100, 27, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  14   0   0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 74\n",
      "Rnd\n",
      "actionVec: [83, 12, 50, 31, 100]\n",
      "next_state: [100, 20, 21, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20  21   1   0]]\n",
      "rewardsum:  232.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 19, 21, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19  21   0   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 19, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  19   0   0]]\n",
      "rewardsum:  241.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 19, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  19   0   0]]\n",
      "rewardsum:  245.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 17, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  17   0   0]]\n",
      "rewardsum:  249.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  12   0   0]]\n",
      "rewardsum:  251.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  11   0   0]]\n",
      "rewardsum:  254.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32 15  0  0]]\n",
      "rewardsum:  256.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 15, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  15   1   0]]\n",
      "rewardsum:  259.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  13   0   0]]\n",
      "rewardsum:  263.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  13   0   0]]\n",
      "rewardsum:  267.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 13, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  13   2   0]]\n",
      "rewardsum:  269.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  13   0   0]]\n",
      "rewardsum:  273.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  13   0   0]]\n",
      "rewardsum:  275.0\n",
      "Time Slot: 88\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  14   0   0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 89\n",
      "Rnd\n",
      "actionVec: [46, 49, 61, 25, 100]\n",
      "next_state: [100, 36, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  17   0   0]]\n",
      "rewardsum:  280.0\n",
      "Time Slot: 90\n",
      "Rnd\n",
      "actionVec: [0, 28, 0, 39, 100]\n",
      "next_state: [100, 34, 16, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  16   0   0]]\n",
      "rewardsum:  284.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [53, 34, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[53 34 15  0  0]]\n",
      "rewardsum:  287.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  16   0   0]]\n",
      "rewardsum:  290.0\n",
      "Time Slot: 93\n",
      "Rnd\n",
      "actionVec: [88, 2, 78, 33, 100]\n",
      "next_state: [90, 17, 30, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[90 17 30  0  0]]\n",
      "rewardsum:  290.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 16, 30, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16  30   0   0]]\n",
      "rewardsum:  294.0\n",
      "Time Slot: 95\n",
      "Rnd\n",
      "actionVec: [99, 48, 74, 11, 100]\n",
      "next_state: [97, 12, 32, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 12 32  0  0]]\n",
      "rewardsum:  297.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 31, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18  31   0   0]]\n",
      "rewardsum:  300.0\n",
      "Time Slot: 97\n",
      "Rnd\n",
      "actionVec: [18, 18, 63, 35, 100]\n",
      "next_state: [100, 20, 35, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20  35   0   0]]\n",
      "rewardsum:  301.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 23, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22  23   0   0]]\n",
      "rewardsum:  305.0\n",
      "Time Slot: 99\n",
      "Rnd\n",
      "actionVec: [67, 16, 43, 45, 100]\n",
      "next_state: [93, 18, 25, 3, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[93 18 25  3  0]]\n",
      "rewardsum:  306.0\n",
      "Episode: 16\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  8771\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [85, 3, 1, 0, 1]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[85  3  1  0  1]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 10, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10   1   0   0]]\n",
      "rewardsum:  3.0\n",
      "Time Slot: 2\n",
      "Rnd\n",
      "actionVec: [61, 47, 64, 23, 100]\n",
      "next_state: [100, 9, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   9   4   0   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 13, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13   1   0   0]]\n",
      "rewardsum:  10.0\n",
      "Time Slot: 4\n",
      "Rnd\n",
      "actionVec: [26, 22, 89, 34, 100]\n",
      "next_state: [100, 16, 4, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   4   0   0]]\n",
      "rewardsum:  11.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   4   0   0]]\n",
      "rewardsum:  15.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 24, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 24  5  0  0]]\n",
      "rewardsum:  17.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   5   0   0]]\n",
      "rewardsum:  20.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   6   0   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   4   0   0]]\n",
      "rewardsum:  26.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [81, 38, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[81 38  6  0  0]]\n",
      "rewardsum:  28.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   7   0   0]]\n",
      "rewardsum:  31.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   7   0   0]]\n",
      "rewardsum:  35.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   8   0   0]]\n",
      "rewardsum:  37.0\n",
      "Time Slot: 14\n",
      "Rnd\n",
      "actionVec: [25, 73, 73, 74, 100]\n",
      "next_state: [100, 35, 6, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   6   2   0]]\n",
      "rewardsum:  39.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [73, 31, 8, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[73 31  8  0  0]]\n",
      "rewardsum:  44.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   1   0]]\n",
      "rewardsum:  47.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  52.0\n",
      "Time Slot: 18\n",
      "Rnd\n",
      "actionVec: [15, 78, 0, 78, 100]\n",
      "next_state: [100, 38, 3, 2, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   3   2   0]]\n",
      "rewardsum:  52.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  57.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   4   0   0]]\n",
      "rewardsum:  60.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  2  0  0]]\n",
      "rewardsum:  64.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   0   0]]\n",
      "rewardsum:  67.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  1  0  0]]\n",
      "rewardsum:  70.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   1   0   0]]\n",
      "rewardsum:  74.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   0   0   0]]\n",
      "rewardsum:  78.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   1   0   0]]\n",
      "rewardsum:  80.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 28\n",
      "Rnd\n",
      "actionVec: [56, 64, 94, 54, 100]\n",
      "next_state: [100, 31, 7, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   7   1   0]]\n",
      "rewardsum:  84.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   8   0   0]]\n",
      "rewardsum:  88.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   9   0   0]]\n",
      "rewardsum:  90.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   8   0   0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   8   0   0]]\n",
      "rewardsum:  96.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   9   0   0]]\n",
      "rewardsum:  98.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   9   0   0]]\n",
      "rewardsum:  101.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 43, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43   9   0   0]]\n",
      "rewardsum:  103.0\n",
      "Time Slot: 36\n",
      "Rnd\n",
      "actionVec: [60, 97, 23, 2, 100]\n",
      "next_state: [100, 37, 3, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   3   0   0]]\n",
      "rewardsum:  109.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  3  0  0]]\n",
      "rewardsum:  112.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  115.0\n",
      "Time Slot: 39\n",
      "Rnd\n",
      "actionVec: [22, 22, 80, 70, 100]\n",
      "next_state: [100, 36, 4, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   4   1   0]]\n",
      "rewardsum:  116.0\n",
      "Time Slot: 40\n",
      "Rnd\n",
      "actionVec: [51, 64, 39, 37, 100]\n",
      "next_state: [100, 29, 2, 4, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   2   4   0]]\n",
      "rewardsum:  119.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 5, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   5   0   0]]\n",
      "rewardsum:  125.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   2   0   0]]\n",
      "rewardsum:  129.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   4   0   0]]\n",
      "rewardsum:  132.0\n",
      "Time Slot: 44\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   4   0   0]]\n",
      "rewardsum:  134.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  137.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 36, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 36  2  0  0]]\n",
      "rewardsum:  141.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 2, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   2   1   0]]\n",
      "rewardsum:  142.0\n",
      "Time Slot: 48\n",
      "Rnd\n",
      "actionVec: [3, 8, 95, 22, 100]\n",
      "next_state: [100, 46, 7, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  46   7   0   0]]\n",
      "rewardsum:  143.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 47, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  47   7   0   0]]\n",
      "rewardsum:  145.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 43, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43   7   0   0]]\n",
      "rewardsum:  149.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [84, 44, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[84 44  5  0  0]]\n",
      "rewardsum:  152.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   6   0   0]]\n",
      "rewardsum:  155.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 3, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34  3  0  0]]\n",
      "rewardsum:  160.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   6   0   0]]\n",
      "rewardsum:  162.0\n",
      "Time Slot: 55\n",
      "Rnd\n",
      "actionVec: [56, 59, 88, 0, 100]\n",
      "next_state: [99, 31, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  7  0  0]]\n",
      "rewardsum:  165.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   7   0   0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 57\n",
      "Rnd\n",
      "actionVec: [29, 12, 88, 58, 100]\n",
      "next_state: [100, 30, 10, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  10   2   0]]\n",
      "rewardsum:  169.0\n",
      "Time Slot: 58\n",
      "Rnd\n",
      "actionVec: [1, 95, 44, 23, 100]\n",
      "next_state: [100, 42, 11, 2, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42  11   2   0]]\n",
      "rewardsum:  169.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 8, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   8   0   0]]\n",
      "rewardsum:  174.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  10   0   0]]\n",
      "rewardsum:  177.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  11   0   0]]\n",
      "rewardsum:  180.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42  10   0   0]]\n",
      "rewardsum:  183.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 9, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   9   1   0]]\n",
      "rewardsum:  185.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   9   0   0]]\n",
      "rewardsum:  188.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   9   0   0]]\n",
      "rewardsum:  191.0\n",
      "Time Slot: 66\n",
      "Rnd\n",
      "actionVec: [20, 99, 60, 19, 100]\n",
      "next_state: [98, 43, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 43  7  0  0]]\n",
      "rewardsum:  194.0\n",
      "Time Slot: 67\n",
      "Rnd\n",
      "actionVec: [84, 32, 43, 62, 100]\n",
      "next_state: [100, 36, 8, 4, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   8   4   0]]\n",
      "rewardsum:  196.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 6, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  6  0  0]]\n",
      "rewardsum:  203.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   4   0   0]]\n",
      "rewardsum:  208.0\n",
      "Time Slot: 70\n",
      "Rnd\n",
      "actionVec: [0, 38, 55, 12, 100]\n",
      "next_state: [100, 25, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   3   0   0]]\n",
      "rewardsum:  212.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   1   0   0]]\n",
      "rewardsum:  215.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 28, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 28  0  0  0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   0   0   0]]\n",
      "rewardsum:  221.0\n",
      "Time Slot: 74\n",
      "Rnd\n",
      "actionVec: [94, 20, 73, 88, 100]\n",
      "next_state: [100, 27, 8, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   8   0   0]]\n",
      "rewardsum:  222.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   8   0   0]]\n",
      "rewardsum:  226.0\n",
      "Time Slot: 76\n",
      "Rnd\n",
      "actionVec: [41, 77, 16, 58, 100]\n",
      "next_state: [100, 28, 1, 5, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   1   5   0]]\n",
      "rewardsum:  229.0\n",
      "Time Slot: 77\n",
      "Rnd\n",
      "actionVec: [56, 81, 21, 87, 100]\n",
      "next_state: [99, 28, 0, 5, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 28  0  5  0]]\n",
      "rewardsum:  232.0\n",
      "Time Slot: 78\n",
      "Rnd\n",
      "actionVec: [70, 23, 75, 22, 100]\n",
      "next_state: [98, 22, 2, 2, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 22  2  2  0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   4   0   0]]\n",
      "rewardsum:  242.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   4   0   0]]\n",
      "rewardsum:  244.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 30, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 30  4  0  0]]\n",
      "rewardsum:  248.0\n",
      "Time Slot: 82\n",
      "Rnd\n",
      "actionVec: [14, 75, 11, 34, 100]\n",
      "next_state: [100, 34, 0, 4, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   4   0]]\n",
      "rewardsum:  248.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  254.0\n",
      "Time Slot: 84\n",
      "Rnd\n",
      "actionVec: [60, 79, 62, 13, 100]\n",
      "next_state: [100, 34, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   0   0]]\n",
      "rewardsum:  259.0\n",
      "Time Slot: 85\n",
      "Rnd\n",
      "actionVec: [92, 23, 75, 5, 100]\n",
      "next_state: [98, 23, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 23  8  0  0]]\n",
      "rewardsum:  261.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  10   0   0]]\n",
      "rewardsum:  264.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 13, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  13   0   0]]\n",
      "rewardsum:  265.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  11   0   0]]\n",
      "rewardsum:  268.0\n",
      "Time Slot: 89\n",
      "Rnd\n",
      "actionVec: [41, 73, 22, 37, 100]\n",
      "next_state: [92, 29, 6, 2, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[92 29  6  2  0]]\n",
      "rewardsum:  272.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 5, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   5   1   0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  281.0\n",
      "Time Slot: 92\n",
      "Rnd\n",
      "actionVec: [94, 67, 42, 55, 100]\n",
      "next_state: [98, 26, 1, 4, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 26  1  4  0]]\n",
      "rewardsum:  284.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 22, 3, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 22  3  0  0]]\n",
      "rewardsum:  290.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   5   0   0]]\n",
      "rewardsum:  293.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   0   0   0]]\n",
      "rewardsum:  298.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   1   0   0]]\n",
      "rewardsum:  301.0\n",
      "Time Slot: 97\n",
      "Rnd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [34, 5, 1, 36, 100]\n",
      "next_state: [79, 16, 5, 4, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[79 16  5  4  0]]\n",
      "rewardsum:  301.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 7, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   7   0   0]]\n",
      "rewardsum:  306.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   7   0   0]]\n",
      "rewardsum:  308.0\n",
      "Episode: 17\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  8621\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Rnd\n",
      "actionVec: [18, 95, 97, 57, 100]\n",
      "next_state: [82, 0, 1, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[82  0  1  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 5, 1, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   5   1   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 8, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   8   1   0   0]]\n",
      "rewardsum:  3.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 12, 1, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12   1   1   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 19, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   0   0   0]]\n",
      "rewardsum:  9.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [94, 23, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[94 23  2  0  0]]\n",
      "rewardsum:  11.0\n",
      "Time Slot: 6\n",
      "Rnd\n",
      "actionVec: [51, 39, 11, 14, 100]\n",
      "next_state: [97, 21, 0, 2, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 21  0  2  0]]\n",
      "rewardsum:  15.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   2   0   0]]\n",
      "rewardsum:  19.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   4   0   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 3, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   3   1   0]]\n",
      "rewardsum:  24.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [95, 31, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 31  2  0  0]]\n",
      "rewardsum:  27.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   3   0   0]]\n",
      "rewardsum:  29.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   2   0   0]]\n",
      "rewardsum:  33.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   1   0   0]]\n",
      "rewardsum:  36.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  39.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  43.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  45.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  47.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   4   0   0]]\n",
      "rewardsum:  49.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   3   0   0]]\n",
      "rewardsum:  52.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [94, 39, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[94 39  6  0  0]]\n",
      "rewardsum:  54.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   9   0   0]]\n",
      "rewardsum:  57.0\n",
      "Time Slot: 22\n",
      "Rnd\n",
      "actionVec: [97, 35, 18, 28, 100]\n",
      "next_state: [97, 30, 6, 5, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 30  6  5  0]]\n",
      "rewardsum:  59.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 5, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   5   0   0]]\n",
      "rewardsum:  66.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   5   0   0]]\n",
      "rewardsum:  70.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   6   0   0]]\n",
      "rewardsum:  72.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  10   0   0]]\n",
      "rewardsum:  75.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   8   0   0]]\n",
      "rewardsum:  79.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 27, 4, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 27  4  0  0]]\n",
      "rewardsum:  85.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   5   0   0]]\n",
      "rewardsum:  87.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [80, 29, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[80 29  5  0  0]]\n",
      "rewardsum:  90.0\n",
      "Time Slot: 31\n",
      "Rnd\n",
      "actionVec: [22, 75, 39, 72, 100]\n",
      "next_state: [100, 33, 3, 3, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   3   0]]\n",
      "rewardsum:  91.0\n",
      "Time Slot: 32\n",
      "Rnd\n",
      "actionVec: [79, 72, 96, 0, 100]\n",
      "next_state: [100, 31, 3, 2, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   3   2   0]]\n",
      "rewardsum:  96.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 0, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   0   0   0]]\n",
      "rewardsum:  102.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   0   0   0]]\n",
      "rewardsum:  105.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   2   0   0]]\n",
      "rewardsum:  107.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 25, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 25  5  0  0]]\n",
      "rewardsum:  110.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   3   0   0]]\n",
      "rewardsum:  114.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 7, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  7  0  0]]\n",
      "rewardsum:  115.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  120.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   2   0   0]]\n",
      "rewardsum:  124.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  126.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  129.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   1   0]]\n",
      "rewardsum:  132.0\n",
      "Time Slot: 44\n",
      "Rnd\n",
      "actionVec: [12, 88, 16, 60, 100]\n",
      "next_state: [100, 38, 0, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   0   2   0]]\n",
      "rewardsum:  134.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   2   0   0]]\n",
      "rewardsum:  137.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 43, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43   2   0   0]]\n",
      "rewardsum:  139.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 44, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  44   2   0   0]]\n",
      "rewardsum:  142.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 45, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  45   2   0   0]]\n",
      "rewardsum:  144.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 43, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43   5   0   0]]\n",
      "rewardsum:  146.0\n",
      "Time Slot: 50\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 38, 4, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 38  4  1  0]]\n",
      "rewardsum:  150.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  154.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 30, 1, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 30  1  0  0]]\n",
      "rewardsum:  159.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 28, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 28  2  0  0]]\n",
      "rewardsum:  161.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   2   0   0]]\n",
      "rewardsum:  164.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   2   0]]\n",
      "rewardsum:  166.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  171.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  173.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   3   0   0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 32, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 32  2  0  0]]\n",
      "rewardsum:  179.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 3, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   3   1   0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [91, 34, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[91 34  3  0  0]]\n",
      "rewardsum:  185.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   2   0   0]]\n",
      "rewardsum:  188.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   2   0   0]]\n",
      "rewardsum:  191.0\n",
      "Time Slot: 64\n",
      "Rnd\n",
      "actionVec: [87, 94, 61, 66, 100]\n",
      "next_state: [100, 28, 3, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   3   2   0]]\n",
      "rewardsum:  194.0\n",
      "Time Slot: 65\n",
      "Rnd\n",
      "actionVec: [47, 38, 59, 21, 100]\n",
      "next_state: [100, 26, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   4   0   0]]\n",
      "rewardsum:  199.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   3   0   0]]\n",
      "rewardsum:  203.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   0   0   0]]\n",
      "rewardsum:  207.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 27, 0, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 27  0  1  0]]\n",
      "rewardsum:  209.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   2   0   0]]\n",
      "rewardsum:  212.0\n",
      "Time Slot: 70\n",
      "Rnd\n",
      "actionVec: [36, 51, 25, 6, 100]\n",
      "next_state: [97, 31, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 31  1  0  0]]\n",
      "rewardsum:  216.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   0   0]]\n",
      "rewardsum:  219.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  221.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   0   0   0]]\n",
      "rewardsum:  224.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   4   0   0]]\n",
      "rewardsum:  226.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   4   0   0]]\n",
      "rewardsum:  229.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   5   0   0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   7   0   0]]\n",
      "rewardsum:  233.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   8   0   0]]\n",
      "rewardsum:  236.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   8   0   0]]\n",
      "rewardsum:  239.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   9   0   0]]\n",
      "rewardsum:  242.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   9   0   0]]\n",
      "rewardsum:  245.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 31, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 31 13  0  0]]\n",
      "rewardsum:  247.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  12   0   0]]\n",
      "rewardsum:  250.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  12   0   0]]\n",
      "rewardsum:  253.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  12   0   0]]\n",
      "rewardsum:  256.0\n",
      "Time Slot: 86\n",
      "Rnd\n",
      "actionVec: [97, 55, 39, 33, 100]\n",
      "next_state: [88, 32, 9, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[88 32  9  1  0]]\n",
      "rewardsum:  260.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   7   0   0]]\n",
      "rewardsum:  264.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   5   0   0]]\n",
      "rewardsum:  268.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   0   0]]\n",
      "rewardsum:  272.0\n",
      "Time Slot: 90\n",
      "Rnd\n",
      "actionVec: [23, 77, 58, 85, 100]\n",
      "next_state: [100, 35, 1, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   2   0]]\n",
      "rewardsum:  273.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   1   0   0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 40, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 40  2  0  0]]\n",
      "rewardsum:  279.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   3   0   0]]\n",
      "rewardsum:  282.0\n",
      "Time Slot: 94\n",
      "Rnd\n",
      "actionVec: [55, 68, 93, 66, 100]\n",
      "next_state: [100, 38, 4, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   4   1   0]]\n",
      "rewardsum:  284.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   4   0   0]]\n",
      "rewardsum:  287.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [69, 37, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[69 37  4  0  0]]\n",
      "rewardsum:  290.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   4   0   0]]\n",
      "rewardsum:  292.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   4   0   0]]\n",
      "rewardsum:  295.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   3   0   0]]\n",
      "rewardsum:  299.0\n",
      "Episode: 18\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  9595\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [82, 7, 2, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[82  7  2  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Rnd\n",
      "actionVec: [5, 71, 10, 18, 100]\n",
      "next_state: [100, 19, 0, 0, 1]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   0   0   1]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 2\n",
      "Rnd\n",
      "actionVec: [92, 24, 61, 49, 100]\n",
      "next_state: [100, 14, 6, 4, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  14   6   4   0]]\n",
      "rewardsum:  1.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 15, 5, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15   5   0   0]]\n",
      "rewardsum:  8.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   4   0   0]]\n",
      "rewardsum:  12.0\n",
      "Time Slot: 5\n",
      "Rnd\n",
      "actionVec: [54, 72, 3, 22, 100]\n",
      "next_state: [100, 23, 0, 2, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   0   2   0]]\n",
      "rewardsum:  16.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 24, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 24  0  0  0]]\n",
      "rewardsum:  20.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   0   0   0]]\n",
      "rewardsum:  24.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   1   0   0]]\n",
      "rewardsum:  26.0\n",
      "Time Slot: 9\n",
      "Rnd\n",
      "actionVec: [21, 80, 92, 94, 100]\n",
      "next_state: [100, 35, 1, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   1   0]]\n",
      "rewardsum:  28.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [93, 37, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[93 37  2  0  0]]\n",
      "rewardsum:  31.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   1   0]]\n",
      "rewardsum:  34.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 0, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   0   2   0]]\n",
      "rewardsum:  36.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   2   0   0]]\n",
      "rewardsum:  39.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  42.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   0   0   0]]\n",
      "rewardsum:  46.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  48.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   3   0   0]]\n",
      "rewardsum:  50.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   4   0   0]]\n",
      "rewardsum:  52.0\n",
      "Time Slot: 19\n",
      "Rnd\n",
      "actionVec: [53, 1, 90, 21, 100]\n",
      "next_state: [96, 26, 17, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 26 17  1  0]]\n",
      "rewardsum:  52.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 17, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  17   0   0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 21\n",
      "Rnd\n",
      "actionVec: [24, 19, 93, 44, 100]\n",
      "next_state: [98, 31, 20, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 31 20  0  0]]\n",
      "rewardsum:  58.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 24, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  24   0   0]]\n",
      "rewardsum:  60.0\n",
      "Time Slot: 23\n",
      "Rnd\n",
      "actionVec: [51, 10, 23, 36, 100]\n",
      "next_state: [93, 22, 21, 5, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[93 22 21  5  0]]\n",
      "rewardsum:  62.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 22, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  22   0   0]]\n",
      "rewardsum:  69.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 21, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  21   1   0]]\n",
      "rewardsum:  71.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 22, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  22   0   0]]\n",
      "rewardsum:  74.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 18, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  18   0   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 28\n",
      "Rnd\n",
      "actionVec: [56, 38, 5, 83, 100]\n",
      "next_state: [100, 25, 14, 6, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  14   6   0]]\n",
      "rewardsum:  78.0\n",
      "Time Slot: 29\n",
      "Rnd\n",
      "actionVec: [18, 83, 59, 59, 100]\n",
      "next_state: [100, 31, 13, 5, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  13   5   0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [69, 28, 12, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[69 28 12  0  0]]\n",
      "rewardsum:  89.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  12   0   0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 32\n",
      "Rnd\n",
      "actionVec: [21, 72, 65, 59, 100]\n",
      "next_state: [100, 28, 10, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  10   1   0]]\n",
      "rewardsum:  95.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 8, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   8   0   0]]\n",
      "rewardsum:  100.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   9   0   0]]\n",
      "rewardsum:  102.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   8   0   0]]\n",
      "rewardsum:  105.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 8, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   8   1   0]]\n",
      "rewardsum:  107.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   8   0   0]]\n",
      "rewardsum:  109.0\n",
      "Time Slot: 38\n",
      "Rnd\n",
      "actionVec: [85, 2, 50, 64, 100]\n",
      "next_state: [97, 26, 18, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 26 18  1  0]]\n",
      "rewardsum:  111.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 15, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  15   0   0]]\n",
      "rewardsum:  116.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  14   0   0]]\n",
      "rewardsum:  119.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  15   0   0]]\n",
      "rewardsum:  121.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  16   0   0]]\n",
      "rewardsum:  124.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  13   0   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 35, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 35 12  0  0]]\n",
      "rewardsum:  131.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  10   0   0]]\n",
      "rewardsum:  134.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 6, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   6   0   0]]\n",
      "rewardsum:  140.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 5, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   5   1   0]]\n",
      "rewardsum:  142.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   6   0   0]]\n",
      "rewardsum:  146.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   4   0   0]]\n",
      "rewardsum:  150.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   5   0   0]]\n",
      "rewardsum:  152.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   6   0   0]]\n",
      "rewardsum:  154.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   6   0   0]]\n",
      "rewardsum:  156.0\n",
      "Time Slot: 53\n",
      "Rnd\n",
      "actionVec: [31, 2, 42, 92, 100]\n",
      "next_state: [99, 34, 11, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34 11  2  0]]\n",
      "rewardsum:  157.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  10   0   0]]\n",
      "rewardsum:  161.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  36  13   0   0]]\n",
      "rewardsum:  164.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  14   0   0]]\n",
      "rewardsum:  166.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 13, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  13   1   0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 58\n",
      "Rnd\n",
      "actionVec: [85, 65, 20, 10, 100]\n",
      "next_state: [100, 32, 12, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  12   0   0]]\n",
      "rewardsum:  173.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 10, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  10   0   0]]\n",
      "rewardsum:  178.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   9   0   0]]\n",
      "rewardsum:  181.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 25, 4, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 25  4  0  0]]\n",
      "rewardsum:  187.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   3   0   0]]\n",
      "rewardsum:  191.0\n",
      "Time Slot: 63\n",
      "Rnd\n",
      "actionVec: [54, 41, 57, 38, 100]\n",
      "next_state: [100, 22, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   7   0   0]]\n",
      "rewardsum:  193.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   9   0   0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   9   0   0]]\n",
      "rewardsum:  198.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 31, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 31  8  0  0]]\n",
      "rewardsum:  202.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   8   0   0]]\n",
      "rewardsum:  205.0\n",
      "Time Slot: 68\n",
      "Rnd\n",
      "actionVec: [29, 51, 57, 96, 100]\n",
      "next_state: [100, 30, 11, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  11   2   0]]\n",
      "rewardsum:  207.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  13   0   0]]\n",
      "rewardsum:  211.0\n",
      "Time Slot: 70\n",
      "Rnd\n",
      "actionVec: [78, 22, 39, 73, 100]\n",
      "next_state: [100, 26, 7, 3, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   7   3   0]]\n",
      "rewardsum:  215.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 10, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  10   0   0]]\n",
      "rewardsum:  221.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 23, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 23  8  0  0]]\n",
      "rewardsum:  224.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 6, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   6   1   0]]\n",
      "rewardsum:  228.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   9   0   0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   7   0   0]]\n",
      "rewardsum:  235.0\n",
      "Time Slot: 76\n",
      "Rnd\n",
      "actionVec: [5, 98, 45, 65, 100]\n",
      "next_state: [100, 40, 6, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   6   0   0]]\n",
      "rewardsum:  236.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   6   0   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 44, 8, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  44   8   0   0]]\n",
      "rewardsum:  239.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   9   0   0]]\n",
      "rewardsum:  243.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [94, 43, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[94 43  9  0  0]]\n",
      "rewardsum:  246.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  10   0   0]]\n",
      "rewardsum:  249.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 30, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 30 11  0  0]]\n",
      "rewardsum:  252.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   8   0   0]]\n",
      "rewardsum:  256.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   9   0   0]]\n",
      "rewardsum:  258.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  10   0   0]]\n",
      "rewardsum:  262.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [60, 31, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[60 31 11  0  0]]\n",
      "rewardsum:  264.0\n",
      "Time Slot: 87\n",
      "Rnd\n",
      "actionVec: [37, 28, 65, 31, 100]\n",
      "next_state: [100, 30, 11, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  11   1   0]]\n",
      "rewardsum:  267.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 11, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31 11  1  0]]\n",
      "rewardsum:  270.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  10   0   0]]\n",
      "rewardsum:  273.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  10   0   0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  11   0   0]]\n",
      "rewardsum:  279.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 35, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 35 10  0  0]]\n",
      "rewardsum:  282.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  11   0   0]]\n",
      "rewardsum:  285.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 10, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  10   0   0]]\n",
      "rewardsum:  290.0\n",
      "Time Slot: 95\n",
      "Rnd\n",
      "actionVec: [68, 42, 33, 60, 100]\n",
      "next_state: [100, 28, 7, 2, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   7   2   0]]\n",
      "rewardsum:  294.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 25, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 25  7  0  0]]\n",
      "rewardsum:  298.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   9   0   0]]\n",
      "rewardsum:  301.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  12   0   0]]\n",
      "rewardsum:  303.0\n",
      "Time Slot: 99\n",
      "Rnd\n",
      "actionVec: [78, 45, 26, 10, 100]\n",
      "next_state: [100, 26, 9, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   9   0   0]]\n",
      "rewardsum:  308.0\n",
      "Episode: 19\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  8074\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [86, 5, 1, 0, 1]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[86  5  1  0  1]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 5, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   5   2   0   0]]\n",
      "rewardsum:  4.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 5, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   5   3   0   0]]\n",
      "rewardsum:  7.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 6, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   6   3   0   0]]\n",
      "rewardsum:  11.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 9, 5, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   9   5   1   0]]\n",
      "rewardsum:  13.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 11, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 11  6  0  0]]\n",
      "rewardsum:  17.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 13, 1, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13   1   1   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   1   0   0]]\n",
      "rewardsum:  25.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   0   0   0]]\n",
      "rewardsum:  28.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   0   0   0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   2   0   0]]\n",
      "rewardsum:  32.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   3   0   0]]\n",
      "rewardsum:  35.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   2   0   0]]\n",
      "rewardsum:  38.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   2   0   0]]\n",
      "rewardsum:  42.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   4   0   0]]\n",
      "rewardsum:  44.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [69, 32, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[69 32  5  0  0]]\n",
      "rewardsum:  47.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   6   0   0]]\n",
      "rewardsum:  50.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   0   0]]\n",
      "rewardsum:  53.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  3  0  0]]\n",
      "rewardsum:  60.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  62.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   5   0   0]]\n",
      "rewardsum:  65.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   6   0   0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   9   0   0]]\n",
      "rewardsum:  70.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  10   0   0]]\n",
      "rewardsum:  73.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  12   0   0]]\n",
      "rewardsum:  75.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   9   0   0]]\n",
      "rewardsum:  79.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   8   0   0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   8   0   0]]\n",
      "rewardsum:  85.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   7   0   0]]\n",
      "rewardsum:  88.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 35, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 35  7  0  0]]\n",
      "rewardsum:  91.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   7   0   0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   9   0   0]]\n",
      "rewardsum:  96.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   9   0   0]]\n",
      "rewardsum:  98.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   7   0   0]]\n",
      "rewardsum:  102.0\n",
      "Time Slot: 35\n",
      "Rnd\n",
      "actionVec: [26, 87, 10, 29, 100]\n",
      "next_state: [84, 36, 2, 3, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[84 36  2  3  0]]\n",
      "rewardsum:  105.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 3, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   3   0   0]]\n",
      "rewardsum:  111.0\n",
      "Time Slot: 37\n",
      "Rnd\n",
      "actionVec: [91, 80, 34, 34, 100]\n",
      "next_state: [96, 27, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 27  0  0  0]]\n",
      "rewardsum:  116.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   4   0   0]]\n",
      "rewardsum:  118.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   0   0   0]]\n",
      "rewardsum:  122.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   3   0   0]]\n",
      "rewardsum:  124.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   8   0   0]]\n",
      "rewardsum:  126.0\n",
      "Time Slot: 42\n",
      "Rnd\n",
      "actionVec: [15, 54, 16, 25, 100]\n",
      "next_state: [100, 32, 6, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   6   2   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 5, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   5   0   0]]\n",
      "rewardsum:  133.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   6   0   0]]\n",
      "rewardsum:  136.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   8   0   0]]\n",
      "rewardsum:  138.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   8   0   0]]\n",
      "rewardsum:  142.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   9   0   0]]\n",
      "rewardsum:  144.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   9   0   0]]\n",
      "rewardsum:  147.0\n",
      "Time Slot: 49\n",
      "Rnd\n",
      "actionVec: [17, 69, 77, 43, 100]\n",
      "next_state: [100, 38, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   9   0   0]]\n",
      "rewardsum:  149.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  10   0   0]]\n",
      "rewardsum:  152.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  11   0   0]]\n",
      "rewardsum:  154.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  14   0   0]]\n",
      "rewardsum:  156.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 38, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 38 14  0  0]]\n",
      "rewardsum:  159.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 11, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  11   1   0]]\n",
      "rewardsum:  163.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  12   0   0]]\n",
      "rewardsum:  165.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 37, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 37 13  0  0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 57\n",
      "Rnd\n",
      "actionVec: [37, 66, 0, 52, 100]\n",
      "next_state: [100, 34, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  12   0   0]]\n",
      "rewardsum:  172.0\n",
      "Time Slot: 58\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  13   0   0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  15   0   0]]\n",
      "rewardsum:  178.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  15   0   0]]\n",
      "rewardsum:  180.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  16   0   0]]\n",
      "rewardsum:  183.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 18, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  18   0   0]]\n",
      "rewardsum:  185.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 13, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  13   1   0]]\n",
      "rewardsum:  188.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  12   0   0]]\n",
      "rewardsum:  192.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  11   0   0]]\n",
      "rewardsum:  194.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 38, 10, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 38 10  1  0]]\n",
      "rewardsum:  197.0\n",
      "Time Slot: 67\n",
      "Rnd\n",
      "actionVec: [60, 62, 77, 12, 100]\n",
      "next_state: [100, 35, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  11   0   0]]\n",
      "rewardsum:  201.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  10   0   0]]\n",
      "rewardsum:  204.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  10   0   0]]\n",
      "rewardsum:  208.0\n",
      "Time Slot: 70\n",
      "Rnd\n",
      "actionVec: [73, 82, 49, 42, 100]\n",
      "next_state: [98, 25, 6, 2, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 25  6  2  0]]\n",
      "rewardsum:  213.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 6, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   6   0   0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   6   0   0]]\n",
      "rewardsum:  221.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   6   0   0]]\n",
      "rewardsum:  224.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   5   0   0]]\n",
      "rewardsum:  228.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   5   0   0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [94, 31, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[94 31  4  0  0]]\n",
      "rewardsum:  234.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 2, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   2   0   0]]\n",
      "rewardsum:  239.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   1   0   0]]\n",
      "rewardsum:  243.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   3   0   0]]\n",
      "rewardsum:  245.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   3   0   0]]\n",
      "rewardsum:  248.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   1   0   0]]\n",
      "rewardsum:  252.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  255.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  259.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  261.0\n",
      "Time Slot: 85\n",
      "Rnd\n",
      "actionVec: [54, 53, 41, 81, 100]\n",
      "next_state: [100, 29, 3, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   3   2   0]]\n",
      "rewardsum:  264.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 2, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   2   0   0]]\n",
      "rewardsum:  269.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   0   0   0]]\n",
      "rewardsum:  272.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 2, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  2  0  0]]\n",
      "rewardsum:  273.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 2, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   1   0]]\n",
      "rewardsum:  276.0\n",
      "Time Slot: 90\n",
      "Rnd\n",
      "actionVec: [86, 43, 97, 57, 100]\n",
      "next_state: [98, 30, 3, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 30  3  1  0]]\n",
      "rewardsum:  279.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 5, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   5   0   0]]\n",
      "rewardsum:  284.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 4, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   1   0]]\n",
      "rewardsum:  286.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   5   0   0]]\n",
      "rewardsum:  289.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   3   0   0]]\n",
      "rewardsum:  293.0\n",
      "Time Slot: 95\n",
      "Rnd\n",
      "actionVec: [46, 23, 93, 20, 100]\n",
      "next_state: [100, 25, 11, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  11   0   0]]\n",
      "rewardsum:  294.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  10   0   0]]\n",
      "rewardsum:  298.0\n",
      "Time Slot: 97\n",
      "Rnd\n",
      "actionVec: [85, 66, 51, 5, 100]\n",
      "next_state: [97, 27, 7, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 27  7  0  0]]\n",
      "rewardsum:  303.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 6, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21   6   0   0]]\n",
      "rewardsum:  308.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   6   0   0]]\n",
      "rewardsum:  311.0\n",
      "Episode: 20\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  6131\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [83, 5, 0, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[83  5  0  1  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 9, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   9   3   0   0]]\n",
      "rewardsum:  2.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 16, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   3   0   0]]\n",
      "rewardsum:  4.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 17, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   3   0   0]]\n",
      "rewardsum:  8.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 19, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   5   0   0]]\n",
      "rewardsum:  10.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 20, 3, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 20  3  0  0]]\n",
      "rewardsum:  15.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   3   0   0]]\n",
      "rewardsum:  18.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   2   0   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   1   0   0]]\n",
      "rewardsum:  26.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  31   3   0   0]]\n",
      "rewardsum:  28.0\n",
      "Time Slot: 10\n",
      "Rnd\n",
      "actionVec: [32, 70, 92, 28, 100]\n",
      "next_state: [95, 34, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 34  5  0  0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   5   0   0]]\n",
      "rewardsum:  33.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 5, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   5   1   0]]\n",
      "rewardsum:  35.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   5   0   0]]\n",
      "rewardsum:  38.0\n",
      "Time Slot: 14\n",
      "Rnd\n",
      "actionVec: [35, 5, 82, 93, 100]\n",
      "next_state: [98, 28, 14, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 28 14  1  0]]\n",
      "rewardsum:  39.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  13   0   0]]\n",
      "rewardsum:  43.0\n",
      "Time Slot: 16\n",
      "Rnd\n",
      "actionVec: [68, 14, 85, 20, 100]\n",
      "next_state: [97, 21, 20, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 21 20  0  0]]\n",
      "rewardsum:  46.0\n",
      "Time Slot: 17\n",
      "Rnd\n",
      "actionVec: [23, 32, 98, 15, 100]\n",
      "next_state: [100, 21, 23, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  23   2   0]]\n",
      "rewardsum:  47.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 24, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  24   0   0]]\n",
      "rewardsum:  51.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 24, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  24   0   0]]\n",
      "rewardsum:  54.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [71, 31, 24, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[71 31 24  0  0]]\n",
      "rewardsum:  55.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 20, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  20   0   0]]\n",
      "rewardsum:  58.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  17   0   0]]\n",
      "rewardsum:  61.0\n",
      "Time Slot: 23\n",
      "Rnd\n",
      "actionVec: [99, 0, 46, 35, 100]\n",
      "next_state: [100, 35, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  16   0   0]]\n",
      "rewardsum:  64.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 16, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  16   0   0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [95, 28, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 28 16  0  0]]\n",
      "rewardsum:  71.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  17   0   0]]\n",
      "rewardsum:  74.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 19, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  19   0   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 17, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  17   0   0]]\n",
      "rewardsum:  80.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  15   0   0]]\n",
      "rewardsum:  83.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  15   0   0]]\n",
      "rewardsum:  86.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 14, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  14   0   0]]\n",
      "rewardsum:  90.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  11   0   0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  12   0   0]]\n",
      "rewardsum:  96.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 8, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  8  0  0]]\n",
      "rewardsum:  101.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   9   0   0]]\n",
      "rewardsum:  104.0\n",
      "Time Slot: 36\n",
      "Rnd\n",
      "actionVec: [52, 75, 35, 52, 100]\n",
      "next_state: [98, 29, 5, 3, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 29  5  3  0]]\n",
      "rewardsum:  107.0\n",
      "Time Slot: 37\n",
      "Rnd\n",
      "actionVec: [53, 39, 21, 30, 100]\n",
      "next_state: [97, 26, 0, 5, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 26  0  5  0]]\n",
      "rewardsum:  112.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 1, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   1   0   0]]\n",
      "rewardsum:  119.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   3   0   0]]\n",
      "rewardsum:  121.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   3   0   0]]\n",
      "rewardsum:  124.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [79, 26, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[79 26  4  0  0]]\n",
      "rewardsum:  127.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   5   0   0]]\n",
      "rewardsum:  129.0\n",
      "Time Slot: 43\n",
      "Rnd\n",
      "actionVec: [47, 98, 63, 32, 100]\n",
      "next_state: [100, 31, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   6   0   0]]\n",
      "rewardsum:  133.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 28, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 28  6  0  0]]\n",
      "rewardsum:  137.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   2   0   0]]\n",
      "rewardsum:  141.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   3   0   0]]\n",
      "rewardsum:  144.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   3   0   0]]\n",
      "rewardsum:  147.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 30, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 30  3  0  0]]\n",
      "rewardsum:  150.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  152.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 35, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 35  3  0  0]]\n",
      "rewardsum:  156.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   4   0   0]]\n",
      "rewardsum:  158.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   4   0   0]]\n",
      "rewardsum:  160.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   5   0   0]]\n",
      "rewardsum:  163.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   4   0   0]]\n",
      "rewardsum:  165.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 5, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   5   1   0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 40, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 40  4  0  0]]\n",
      "rewardsum:  171.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 5, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   5   1   0]]\n",
      "rewardsum:  173.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 37, 2, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 37  2  0  0]]\n",
      "rewardsum:  178.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 34, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 34  0  0  0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  185.0\n",
      "Time Slot: 61\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   4   0   0]]\n",
      "rewardsum:  187.0\n",
      "Time Slot: 62\n",
      "Rnd\n",
      "actionVec: [91, 6, 12, 92, 100]\n",
      "next_state: [91, 24, 7, 4, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[91 24  7  4  0]]\n",
      "rewardsum:  188.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 8, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   8   0   0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   8   0   0]]\n",
      "rewardsum:  198.0\n",
      "Time Slot: 65\n",
      "Rnd\n",
      "actionVec: [9, 59, 11, 97, 100]\n",
      "next_state: [100, 24, 1, 8, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   1   8   0]]\n",
      "rewardsum:  198.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 1, 0, 0]\n",
      "Reward: 10.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   1   0   0]]\n",
      "rewardsum:  208.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   3   0   0]]\n",
      "rewardsum:  210.0\n",
      "Time Slot: 68\n",
      "Rnd\n",
      "actionVec: [17, 21, 13, 27, 100]\n",
      "next_state: [100, 27, 3, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   3   1   0]]\n",
      "rewardsum:  212.0\n",
      "Time Slot: 69\n",
      "Rnd\n",
      "actionVec: [22, 62, 86, 89, 100]\n",
      "next_state: [100, 32, 4, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   1   0]]\n",
      "rewardsum:  214.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   0   0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  223.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  225.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   0   0]]\n",
      "rewardsum:  229.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  1  0  0]]\n",
      "rewardsum:  232.0\n",
      "Time Slot: 75\n",
      "Rnd\n",
      "actionVec: [29, 10, 66, 88, 100]\n",
      "next_state: [100, 28, 8, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   8   0   0]]\n",
      "rewardsum:  233.0\n",
      "Time Slot: 76\n",
      "Rnd\n",
      "actionVec: [62, 48, 0, 53, 100]\n",
      "next_state: [100, 29, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   8   0   0]]\n",
      "rewardsum:  237.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 28, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 28  7  0  0]]\n",
      "rewardsum:  241.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   6   0   0]]\n",
      "rewardsum:  244.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   6   0   0]]\n",
      "rewardsum:  247.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   6   0   0]]\n",
      "rewardsum:  249.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   5   0   0]]\n",
      "rewardsum:  252.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   5   0   0]]\n",
      "rewardsum:  256.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   8   0   0]]\n",
      "rewardsum:  258.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 7, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   7   1   0]]\n",
      "rewardsum:  261.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   9   0   0]]\n",
      "rewardsum:  264.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   1   0]]\n",
      "rewardsum:  268.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   0   0]]\n",
      "rewardsum:  272.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  275.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 32, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 32  7  0  0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   6   0   0]]\n",
      "rewardsum:  280.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   6   0   0]]\n",
      "rewardsum:  283.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   6   0   0]]\n",
      "rewardsum:  285.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   7   0   0]]\n",
      "rewardsum:  287.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   6   0   0]]\n",
      "rewardsum:  291.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   7   0   0]]\n",
      "rewardsum:  293.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   6   0   0]]\n",
      "rewardsum:  296.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  301.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  304.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   1   0]]\n",
      "rewardsum:  307.0\n",
      "Episode: 21\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  6674\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [82, 6, 2, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[82  6  2  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Rnd\n",
      "actionVec: [62, 5, 97, 63, 100]\n",
      "next_state: [100, 0, 10, 2, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   0  10   2   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 5, 7, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   5   7   0   0]]\n",
      "rewardsum:  5.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 11, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11   7   0   0]]\n",
      "rewardsum:  8.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 19, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   7   0   0]]\n",
      "rewardsum:  10.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [89, 22, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[89 22  8  0  0]]\n",
      "rewardsum:  12.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   8   0   0]]\n",
      "rewardsum:  15.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   8   0   0]]\n",
      "rewardsum:  19.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  8  0  0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  10   0   0]]\n",
      "rewardsum:  25.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  10   0   0]]\n",
      "rewardsum:  28.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  10   0   0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 9, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   9   1   0]]\n",
      "rewardsum:  32.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   8   0   0]]\n",
      "rewardsum:  36.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  11   0   0]]\n",
      "rewardsum:  38.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 40, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 40 12  0  0]]\n",
      "rewardsum:  40.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  12   0   0]]\n",
      "rewardsum:  44.0\n",
      "Time Slot: 17\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34 11  0  0]]\n",
      "rewardsum:  47.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  13   0   0]]\n",
      "rewardsum:  50.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  14   0   0]]\n",
      "rewardsum:  53.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  15   0   0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  14   0   0]]\n",
      "rewardsum:  59.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  13   0   0]]\n",
      "rewardsum:  62.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 14, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  14   1   0]]\n",
      "rewardsum:  65.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 13, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  13   0   0]]\n",
      "rewardsum:  70.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  15   0   0]]\n",
      "rewardsum:  73.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  11   0   0]]\n",
      "rewardsum:  77.0\n",
      "Time Slot: 27\n",
      "Rnd\n",
      "actionVec: [20, 70, 69, 41, 100]\n",
      "next_state: [100, 32, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  12   0   0]]\n",
      "rewardsum:  79.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  13   0   0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  15   0   0]]\n",
      "rewardsum:  84.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [70, 36, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[70 36 15  0  0]]\n",
      "rewardsum:  86.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  13   0   0]]\n",
      "rewardsum:  90.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  15   0   0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  16   0   0]]\n",
      "rewardsum:  96.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  16   0   0]]\n",
      "rewardsum:  99.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 19, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  19   0   0]]\n",
      "rewardsum:  101.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 18, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  18   0   0]]\n",
      "rewardsum:  103.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  17   0   0]]\n",
      "rewardsum:  106.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  13   0   0]]\n",
      "rewardsum:  110.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  12   0   0]]\n",
      "rewardsum:  113.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  11   0   0]]\n",
      "rewardsum:  116.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 35, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 35 12  0  0]]\n",
      "rewardsum:  118.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  12   0   0]]\n",
      "rewardsum:  121.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  11   0   0]]\n",
      "rewardsum:  124.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  11   0   0]]\n",
      "rewardsum:  127.0\n",
      "Time Slot: 45\n",
      "Rnd\n",
      "actionVec: [62, 88, 32, 74, 100]\n",
      "next_state: [97, 31, 8, 6, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 31  8  6  0]]\n",
      "rewardsum:  129.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 26, 10, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 26 10  0  0]]\n",
      "rewardsum:  136.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   7   0   0]]\n",
      "rewardsum:  140.0\n",
      "Time Slot: 48\n",
      "Rnd\n",
      "actionVec: [35, 4, 33, 44, 100]\n",
      "next_state: [98, 11, 22, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 11 22  0  0]]\n",
      "rewardsum:  140.0\n",
      "Time Slot: 49\n",
      "Rnd\n",
      "actionVec: [36, 90, 52, 1, 100]\n",
      "next_state: [100, 15, 20, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15  20   0   0]]\n",
      "rewardsum:  144.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 19, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20  19   0   0]]\n",
      "rewardsum:  147.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 19, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  19   1   0]]\n",
      "rewardsum:  149.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 21, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  21   0   0]]\n",
      "rewardsum:  152.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  14   0   0]]\n",
      "rewardsum:  154.0\n",
      "Time Slot: 54\n",
      "Rnd\n",
      "actionVec: [46, 8, 72, 72, 100]\n",
      "next_state: [96, 20, 25, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 20 25  0  0]]\n",
      "rewardsum:  155.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 23, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  23   0   0]]\n",
      "rewardsum:  159.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 23, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  23   0   0]]\n",
      "rewardsum:  162.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 22, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  22   0   0]]\n",
      "rewardsum:  164.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 22, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  22   0   0]]\n",
      "rewardsum:  167.0\n",
      "Time Slot: 59\n",
      "Rnd\n",
      "actionVec: [65, 18, 13, 53, 100]\n",
      "next_state: [100, 27, 15, 4, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  15   4   0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 14, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  14   0   0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 28, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 28 12  0  0]]\n",
      "rewardsum:  179.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  11   0   0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  10   0   0]]\n",
      "rewardsum:  186.0\n",
      "Time Slot: 64\n",
      "Rnd\n",
      "actionVec: [98, 97, 72, 16, 100]\n",
      "next_state: [100, 28, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  10   0   0]]\n",
      "rewardsum:  189.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  11   0   0]]\n",
      "rewardsum:  192.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  13   0   0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 67\n",
      "Rnd\n",
      "actionVec: [52, 19, 14, 51, 100]\n",
      "next_state: [96, 28, 6, 8, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 28  6  8  0]]\n",
      "rewardsum:  196.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 27, 6, 0, 0]\n",
      "Reward: 10.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 27  6  0  0]]\n",
      "rewardsum:  206.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  27   5   0   0]]\n",
      "rewardsum:  208.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   4   0   0]]\n",
      "rewardsum:  212.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   1   0   0]]\n",
      "rewardsum:  216.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   1   0   0]]\n",
      "rewardsum:  219.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   0   0   0]]\n",
      "rewardsum:  224.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   0   0   0]]\n",
      "rewardsum:  226.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  1  0  0]]\n",
      "rewardsum:  229.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  230.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   4   0   0]]\n",
      "rewardsum:  232.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   6   0   0]]\n",
      "rewardsum:  234.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   5   0   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   4   0   0]]\n",
      "rewardsum:  241.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   2   0]]\n",
      "rewardsum:  244.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   0   0]]\n",
      "rewardsum:  248.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   0   0]]\n",
      "rewardsum:  251.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  254.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  256.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  260.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 30, 2, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 30  2  1  0]]\n",
      "rewardsum:  263.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  1  0  0]]\n",
      "rewardsum:  266.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   0   0   0]]\n",
      "rewardsum:  270.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   3   0   0]]\n",
      "rewardsum:  272.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   8   0   0]]\n",
      "rewardsum:  274.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  10   0   0]]\n",
      "rewardsum:  276.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   9   0   0]]\n",
      "rewardsum:  278.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   8   0   0]]\n",
      "rewardsum:  281.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 6, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   6   0   0]]\n",
      "rewardsum:  286.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   6   0   0]]\n",
      "rewardsum:  290.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   0   0]]\n",
      "rewardsum:  294.0\n",
      "Time Slot: 98\n",
      "Rnd\n",
      "actionVec: [19, 48, 72, 75, 100]\n",
      "next_state: [100, 34, 7, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   7   0   0]]\n",
      "rewardsum:  294.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   6   0   0]]\n",
      "rewardsum:  298.0\n",
      "Episode: 22\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  9365\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [85, 7, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[85  7  0  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 8, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   8   3   0   0]]\n",
      "rewardsum:  3.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 15, 2, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15   2   1   0]]\n",
      "rewardsum:  5.0\n",
      "Time Slot: 3\n",
      "Rnd\n",
      "actionVec: [69, 42, 20, 11, 100]\n",
      "next_state: [100, 13, 1, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13   1   0   0]]\n",
      "rewardsum:  10.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 17, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   1   0   0]]\n",
      "rewardsum:  14.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   0   0   0]]\n",
      "rewardsum:  17.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   2   0   0]]\n",
      "rewardsum:  19.0\n",
      "Time Slot: 7\n",
      "Rnd\n",
      "actionVec: [30, 24, 45, 17, 100]\n",
      "next_state: [97, 23, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 23  2  0  0]]\n",
      "rewardsum:  23.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   1   0   0]]\n",
      "rewardsum:  26.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   1   0   0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 29, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 29  1  0  0]]\n",
      "rewardsum:  33.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   2   0   0]]\n",
      "rewardsum:  35.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  38.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 0, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   0   1   0]]\n",
      "rewardsum:  42.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   0   0   0]]\n",
      "rewardsum:  45.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [73, 38, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[73 38  2  0  0]]\n",
      "rewardsum:  47.0\n",
      "Time Slot: 16\n",
      "Rnd\n",
      "actionVec: [87, 13, 82, 55, 100]\n",
      "next_state: [99, 29, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 29  7  0  0]]\n",
      "rewardsum:  50.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   9   0   0]]\n",
      "rewardsum:  52.0\n",
      "Time Slot: 18\n",
      "Rnd\n",
      "actionVec: [62, 60, 37, 90, 100]\n",
      "next_state: [99, 29, 8, 5, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 29  8  5  0]]\n",
      "rewardsum:  53.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 24, 6, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 24  6  0  0]]\n",
      "rewardsum:  61.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   8   0   0]]\n",
      "rewardsum:  64.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   8   0   0]]\n",
      "rewardsum:  67.0\n",
      "Time Slot: 22\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   8   0   0]]\n",
      "rewardsum:  70.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 9, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   9   1   0]]\n",
      "rewardsum:  72.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 8, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   8   0   0]]\n",
      "rewardsum:  77.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [92, 29, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[92 29  6  0  0]]\n",
      "rewardsum:  81.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 2, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   2   0   0]]\n",
      "rewardsum:  86.0\n",
      "Time Slot: 27\n",
      "Rnd\n",
      "actionVec: [54, 91, 90, 52, 100]\n",
      "next_state: [100, 28, 2, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   2   2   0]]\n",
      "rewardsum:  88.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   0   0   0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   3   0   0]]\n",
      "rewardsum:  96.0\n",
      "Time Slot: 30\n",
      "Rnd\n",
      "actionVec: [0, 51, 70, 42, 100]\n",
      "next_state: [100, 29, 5, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   5   1   0]]\n",
      "rewardsum:  98.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 4, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   4   1   0]]\n",
      "rewardsum:  102.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   4   0   0]]\n",
      "rewardsum:  106.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   6   0   0]]\n",
      "rewardsum:  108.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   6   0   0]]\n",
      "rewardsum:  111.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [92, 31, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[92 31  6  0  0]]\n",
      "rewardsum:  113.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [85, 30, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[85 30  7  0  0]]\n",
      "rewardsum:  117.0\n",
      "Time Slot: 37\n",
      "Rnd\n",
      "actionVec: [54, 8, 63, 52, 100]\n",
      "next_state: [100, 26, 11, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  11   2   0]]\n",
      "rewardsum:  119.0\n",
      "Time Slot: 38\n",
      "Rnd\n",
      "actionVec: [89, 37, 36, 14, 100]\n",
      "next_state: [99, 22, 14, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 22 14  0  0]]\n",
      "rewardsum:  124.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 20, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 20 13  0  0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 19, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19  13   0   0]]\n",
      "rewardsum:  132.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22  11   0   0]]\n",
      "rewardsum:  135.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22  11   0   0]]\n",
      "rewardsum:  139.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  12   0   0]]\n",
      "rewardsum:  141.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  14   0   0]]\n",
      "rewardsum:  143.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  14   0   0]]\n",
      "rewardsum:  146.0\n",
      "Time Slot: 46\n",
      "Rnd\n",
      "actionVec: [90, 58, 17, 18, 100]\n",
      "next_state: [54, 28, 9, 2, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[54 28  9  2  0]]\n",
      "rewardsum:  151.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 27, 5, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 27  5  0  0]]\n",
      "rewardsum:  158.0\n",
      "Time Slot: 48\n",
      "Rnd\n",
      "actionVec: [76, 70, 34, 61, 100]\n",
      "next_state: [96, 20, 2, 5, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 20  2  5  0]]\n",
      "rewardsum:  160.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 2, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   2   0   0]]\n",
      "rewardsum:  167.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 17, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 17  3  0  0]]\n",
      "rewardsum:  170.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   0   0   0]]\n",
      "rewardsum:  174.0\n",
      "Time Slot: 52\n",
      "Rnd\n",
      "actionVec: [48, 56, 68, 23, 100]\n",
      "next_state: [98, 22, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 22  1  0  0]]\n",
      "rewardsum:  178.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 1, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   1   1   0]]\n",
      "rewardsum:  181.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   2   0   0]]\n",
      "rewardsum:  184.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 2, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   1   0]]\n",
      "rewardsum:  186.0\n",
      "Time Slot: 56\n",
      "Rnd\n",
      "actionVec: [14, 44, 14, 75, 100]\n",
      "next_state: [100, 33, 0, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   0   1   0]]\n",
      "rewardsum:  189.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   0   0]]\n",
      "rewardsum:  193.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   0   0   0]]\n",
      "rewardsum:  196.0\n",
      "Time Slot: 59\n",
      "Rnd\n",
      "actionVec: [31, 24, 73, 86, 100]\n",
      "next_state: [100, 33, 6, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   6   1   0]]\n",
      "rewardsum:  197.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   7   0   0]]\n",
      "rewardsum:  201.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 6, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   6   1   0]]\n",
      "rewardsum:  203.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  207.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   0   0]]\n",
      "rewardsum:  210.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   1   0]]\n",
      "rewardsum:  213.0\n",
      "Time Slot: 65\n",
      "Rnd\n",
      "actionVec: [62, 30, 82, 6, 100]\n",
      "next_state: [98, 30, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 30 10  0  0]]\n",
      "rewardsum:  215.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  11   0   0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  13   0   0]]\n",
      "rewardsum:  221.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 9, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   9   0   0]]\n",
      "rewardsum:  226.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  13   0   0]]\n",
      "rewardsum:  228.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 16, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  16   0   0]]\n",
      "rewardsum:  230.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  15   0   0]]\n",
      "rewardsum:  233.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 18, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  18   0   0]]\n",
      "rewardsum:  235.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 18, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  18   0   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 22, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32 22  1  0]]\n",
      "rewardsum:  239.0\n",
      "Time Slot: 75\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 19, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  19   0   0]]\n",
      "rewardsum:  243.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 18, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  18   0   0]]\n",
      "rewardsum:  246.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 21, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  21   0   0]]\n",
      "rewardsum:  248.0\n",
      "Time Slot: 78\n",
      "Rnd\n",
      "actionVec: [89, 42, 21, 30, 100]\n",
      "next_state: [99, 30, 19, 2, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 30 19  2  0]]\n",
      "rewardsum:  252.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 26, 18, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 26 18  0  0]]\n",
      "rewardsum:  257.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  17   0   0]]\n",
      "rewardsum:  260.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 16, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  16   0   0]]\n",
      "rewardsum:  264.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  14   0   0]]\n",
      "rewardsum:  267.0\n",
      "Time Slot: 83\n",
      "Rnd\n",
      "actionVec: [41, 76, 40, 56, 100]\n",
      "next_state: [100, 28, 10, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  10   1   0]]\n",
      "rewardsum:  271.0\n",
      "Time Slot: 84\n",
      "Rnd\n",
      "actionVec: [30, 72, 97, 98, 100]\n",
      "next_state: [100, 29, 10, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  10   2   0]]\n",
      "rewardsum:  274.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 8, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   8   0   0]]\n",
      "rewardsum:  279.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32 11  0  0]]\n",
      "rewardsum:  281.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  10   0   0]]\n",
      "rewardsum:  285.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 12, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  12   0   0]]\n",
      "rewardsum:  286.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 10, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  10   0   0]]\n",
      "rewardsum:  291.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  10   0   0]]\n",
      "rewardsum:  293.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  11   0   0]]\n",
      "rewardsum:  296.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   9   0   0]]\n",
      "rewardsum:  299.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 8, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   8   1   0]]\n",
      "rewardsum:  302.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  10   0   0]]\n",
      "rewardsum:  305.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   9   0   0]]\n",
      "rewardsum:  308.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   9   0   0]]\n",
      "rewardsum:  311.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   8   0   0]]\n",
      "rewardsum:  314.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   9   0   0]]\n",
      "rewardsum:  317.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   8   0   0]]\n",
      "rewardsum:  320.0\n",
      "Episode: 23\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  8159\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [88, 4, 2, 0, 1]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[88  4  2  0  1]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 5, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   5   3   0   0]]\n",
      "rewardsum:  4.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 8, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   8   4   0   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 8, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   8   6   0   0]]\n",
      "rewardsum:  9.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 14, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   6   0   0]]\n",
      "rewardsum:  12.0\n",
      "Time Slot: 5\n",
      "Rnd\n",
      "actionVec: [9, 81, 52, 57, 100]\n",
      "next_state: [96, 28, 5, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 28  5  1  0]]\n",
      "rewardsum:  12.0\n",
      "Time Slot: 6\n",
      "Rnd\n",
      "actionVec: [15, 63, 49, 53, 100]\n",
      "next_state: [100, 33, 6, 3, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   6   3   0]]\n",
      "rewardsum:  13.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 5, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   5   0   0]]\n",
      "rewardsum:  18.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 1, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   1   1   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   1   0   0]]\n",
      "rewardsum:  26.0\n",
      "Time Slot: 10\n",
      "Rnd\n",
      "actionVec: [45, 50, 28, 96, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  28.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  2  0  0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  34.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   1   0]]\n",
      "rewardsum:  36.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  39.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [75, 30, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[75 30  4  0  0]]\n",
      "rewardsum:  43.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   5   0   0]]\n",
      "rewardsum:  46.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   3   0   0]]\n",
      "rewardsum:  50.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   2   0   0]]\n",
      "rewardsum:  53.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   3   0   0]]\n",
      "rewardsum:  57.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   4   0   0]]\n",
      "rewardsum:  60.0\n",
      "Time Slot: 21\n",
      "Rnd\n",
      "actionVec: [11, 57, 42, 13, 100]\n",
      "next_state: [100, 29, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   4   0   0]]\n",
      "rewardsum:  63.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   7   0   0]]\n",
      "rewardsum:  66.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 2, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   2   0   0]]\n",
      "rewardsum:  71.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   1   0   0]]\n",
      "rewardsum:  74.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   4   0   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  2  0  0]]\n",
      "rewardsum:  79.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[99 34  6  0  0]]\n",
      "rewardsum:  85.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   7   0   0]]\n",
      "rewardsum:  87.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   9   0   0]]\n",
      "rewardsum:  90.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 6, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   6   1   0]]\n",
      "rewardsum:  92.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   7   0   0]]\n",
      "rewardsum:  96.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   9   0   0]]\n",
      "rewardsum:  99.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   7   0   0]]\n",
      "rewardsum:  103.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  7  0  0]]\n",
      "rewardsum:  105.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   8   0   0]]\n",
      "rewardsum:  108.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  10   0   0]]\n",
      "rewardsum:  110.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  10   0   0]]\n",
      "rewardsum:  112.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  13   0   0]]\n",
      "rewardsum:  115.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [91, 34, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[91 34 14  0  0]]\n",
      "rewardsum:  118.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33 14  0  0]]\n",
      "rewardsum:  121.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33 13  0  0]]\n",
      "rewardsum:  124.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  13   0   0]]\n",
      "rewardsum:  126.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  15   0   0]]\n",
      "rewardsum:  129.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  12   0   0]]\n",
      "rewardsum:  133.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 36, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 36 11  0  0]]\n",
      "rewardsum:  136.0\n",
      "Time Slot: 47\n",
      "Rnd\n",
      "actionVec: [71, 66, 59, 94, 100]\n",
      "next_state: [100, 30, 13, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  13   2   0]]\n",
      "rewardsum:  139.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 11, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  11   0   0]]\n",
      "rewardsum:  145.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 15, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  15   0   0]]\n",
      "rewardsum:  146.0\n",
      "Time Slot: 50\n",
      "Rnd\n",
      "actionVec: [60, 99, 31, 66, 100]\n",
      "next_state: [92, 26, 10, 4, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[92 26 10  4  0]]\n",
      "rewardsum:  149.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 8, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   8   0   0]]\n",
      "rewardsum:  157.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   8   0   0]]\n",
      "rewardsum:  159.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   8   0   0]]\n",
      "rewardsum:  162.0\n",
      "Time Slot: 54\n",
      "Rnd\n",
      "actionVec: [11, 23, 34, 2, 100]\n",
      "next_state: [100, 29, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   8   0   0]]\n",
      "rewardsum:  166.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   8   0   0]]\n",
      "rewardsum:  169.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  10   0   0]]\n",
      "rewardsum:  172.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 25, 9, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 25  9  0  0]]\n",
      "rewardsum:  177.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 25, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 25  7  0  0]]\n",
      "rewardsum:  181.0\n",
      "Time Slot: 59\n",
      "Rnd\n",
      "actionVec: [60, 6, 25, 32, 100]\n",
      "next_state: [92, 17, 13, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[92 17 13  1  0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  12   0   0]]\n",
      "rewardsum:  186.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 10, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  10   1   0]]\n",
      "rewardsum:  190.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  10   0   0]]\n",
      "rewardsum:  194.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   9   0   0]]\n",
      "rewardsum:  198.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 10, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  10   0   0]]\n",
      "rewardsum:  199.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 10, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  10   0   0]]\n",
      "rewardsum:  204.0\n",
      "Time Slot: 66\n",
      "Rnd\n",
      "actionVec: [83, 65, 48, 9, 100]\n",
      "next_state: [100, 26, 8, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   8   1   0]]\n",
      "rewardsum:  208.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   9   0   0]]\n",
      "rewardsum:  212.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   9   0   0]]\n",
      "rewardsum:  216.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22  10   0   0]]\n",
      "rewardsum:  219.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  10   0   0]]\n",
      "rewardsum:  221.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  10   0   0]]\n",
      "rewardsum:  224.0\n",
      "Time Slot: 72\n",
      "Rnd\n",
      "actionVec: [92, 52, 59, 66, 100]\n",
      "next_state: [98, 29, 12, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 29 12  1  0]]\n",
      "rewardsum:  227.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  11   0   0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 16, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  16   0   0]]\n",
      "rewardsum:  232.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 18, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  18   0   0]]\n",
      "rewardsum:  234.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 17, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  17   1   0]]\n",
      "rewardsum:  236.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  15   0   0]]\n",
      "rewardsum:  239.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 43, 16, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43  16   1   0]]\n",
      "rewardsum:  241.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 45, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  45  12   0   0]]\n",
      "rewardsum:  244.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42  11   0   0]]\n",
      "rewardsum:  247.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41  11   0   0]]\n",
      "rewardsum:  250.0\n",
      "Time Slot: 82\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  10   0   0]]\n",
      "rewardsum:  254.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 10, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  10   1   0]]\n",
      "rewardsum:  256.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 11, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  11   1   0]]\n",
      "rewardsum:  259.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32 12  0  0]]\n",
      "rewardsum:  263.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  14   0   0]]\n",
      "rewardsum:  265.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [91, 35, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[91 35 12  0  0]]\n",
      "rewardsum:  268.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  12   0   0]]\n",
      "rewardsum:  271.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 12, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  12   1   0]]\n",
      "rewardsum:  274.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  12   0   0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34 14  0  0]]\n",
      "rewardsum:  280.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  14   0   0]]\n",
      "rewardsum:  282.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  14   0   0]]\n",
      "rewardsum:  285.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  11   0   0]]\n",
      "rewardsum:  289.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  12   0   0]]\n",
      "rewardsum:  291.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 12, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  12   1   0]]\n",
      "rewardsum:  293.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  14   0   0]]\n",
      "rewardsum:  296.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 38, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 38 12  0  0]]\n",
      "rewardsum:  299.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 11, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  11   1   0]]\n",
      "rewardsum:  302.0\n",
      "Episode: 24\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  8182\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [84, 7, 0, 0, 1]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[84  7  0  0  1]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 14, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   1   0   0]]\n",
      "rewardsum:  3.0\n",
      "Time Slot: 2\n",
      "Rnd\n",
      "actionVec: [29, 9, 44, 52, 100]\n",
      "next_state: [100, 15, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15   4   0   0]]\n",
      "rewardsum:  5.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   4   0   0]]\n",
      "rewardsum:  8.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 6, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   6   0   0]]\n",
      "rewardsum:  9.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [82, 26, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[82 26  5  0  0]]\n",
      "rewardsum:  13.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   5   0   0]]\n",
      "rewardsum:  16.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  18.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   0   0   0]]\n",
      "rewardsum:  27.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  28.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   6   0   0]]\n",
      "rewardsum:  31.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 3, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   3   1   0]]\n",
      "rewardsum:  35.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 2, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   2   1   0]]\n",
      "rewardsum:  39.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   2   0   0]]\n",
      "rewardsum:  43.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   2   0   0]]\n",
      "rewardsum:  46.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  2  0  0]]\n",
      "rewardsum:  48.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 33, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 33  2  0  0]]\n",
      "rewardsum:  51.0\n",
      "Time Slot: 18\n",
      "Rnd\n",
      "actionVec: [34, 20, 95, 83, 100]\n",
      "next_state: [100, 34, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   7   0   0]]\n",
      "rewardsum:  53.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   9   0   0]]\n",
      "rewardsum:  55.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [93, 36, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[93 36  7  0  0]]\n",
      "rewardsum:  58.0\n",
      "Time Slot: 21\n",
      "Rnd\n",
      "actionVec: [19, 48, 25, 75, 100]\n",
      "next_state: [100, 32, 1, 5, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   1   5   0]]\n",
      "rewardsum:  60.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 0, 0, 0]\n",
      "Reward: 9.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   0   0   0]]\n",
      "rewardsum:  69.0\n",
      "Time Slot: 23\n",
      "Rnd\n",
      "actionVec: [47, 65, 25, 85, 100]\n",
      "next_state: [100, 28, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   0   0   0]]\n",
      "rewardsum:  72.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   1   0   0]]\n",
      "rewardsum:  75.0\n",
      "Time Slot: 25\n",
      "Rnd\n",
      "actionVec: [30, 30, 55, 37, 100]\n",
      "next_state: [100, 26, 1, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   1   2   0]]\n",
      "rewardsum:  77.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 0, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   0   0   0]]\n",
      "rewardsum:  83.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   1   0   0]]\n",
      "rewardsum:  85.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   1   0   0]]\n",
      "rewardsum:  88.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  90.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 32, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 32  4  0  0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [90, 35, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[90 35  3  0  0]]\n",
      "rewardsum:  96.0\n",
      "Time Slot: 32\n",
      "Rnd\n",
      "actionVec: [13, 76, 21, 4, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  100.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   0   0   0]]\n",
      "rewardsum:  103.0\n",
      "Time Slot: 34\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 33, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 33  1  0  0]]\n",
      "rewardsum:  105.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   2   0   0]]\n",
      "rewardsum:  107.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  110.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  113.0\n",
      "Time Slot: 38\n",
      "Rnd\n",
      "actionVec: [29, 74, 80, 13, 100]\n",
      "next_state: [100, 38, 2, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   2   1   0]]\n",
      "rewardsum:  115.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  119.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [93, 37, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[93 37  0  0  0]]\n",
      "rewardsum:  122.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   1   0   0]]\n",
      "rewardsum:  125.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   1   0   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  130.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   3   0   0]]\n",
      "rewardsum:  132.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   4   0   0]]\n",
      "rewardsum:  135.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   3   0   0]]\n",
      "rewardsum:  138.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   4   0   0]]\n",
      "rewardsum:  141.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   1   0]]\n",
      "rewardsum:  144.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   5   0   0]]\n",
      "rewardsum:  147.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 7, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   7   1   0]]\n",
      "rewardsum:  149.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   8   0   0]]\n",
      "rewardsum:  152.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   7   0   0]]\n",
      "rewardsum:  156.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   9   0   0]]\n",
      "rewardsum:  158.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  10   0   0]]\n",
      "rewardsum:  160.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   9   0   0]]\n",
      "rewardsum:  162.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 38, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 38 11  0  0]]\n",
      "rewardsum:  165.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41  11   0   0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  11   0   0]]\n",
      "rewardsum:  171.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   9   0   0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   8   0   0]]\n",
      "rewardsum:  178.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  10   0   0]]\n",
      "rewardsum:  180.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  11   0   0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 13, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42  13   0   0]]\n",
      "rewardsum:  183.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 42, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 42 12  0  0]]\n",
      "rewardsum:  186.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 41, 11, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 41 11  1  0]]\n",
      "rewardsum:  190.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 39, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 39 11  0  0]]\n",
      "rewardsum:  193.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  12   0   0]]\n",
      "rewardsum:  197.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  11   0   0]]\n",
      "rewardsum:  199.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  13   0   0]]\n",
      "rewardsum:  202.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  13   0   0]]\n",
      "rewardsum:  204.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  15   0   0]]\n",
      "rewardsum:  207.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 18, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  18   0   0]]\n",
      "rewardsum:  210.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 20, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  20   0   0]]\n",
      "rewardsum:  212.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 19, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  19   0   0]]\n",
      "rewardsum:  215.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 17, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  17   0   0]]\n",
      "rewardsum:  219.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 33, 18, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 33 18  0  0]]\n",
      "rewardsum:  221.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35 17  0  0]]\n",
      "rewardsum:  224.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 17, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  17   0   0]]\n",
      "rewardsum:  226.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 17, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  17   0   0]]\n",
      "rewardsum:  228.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34 17  0  0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 19, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  19   0   0]]\n",
      "rewardsum:  234.0\n",
      "Time Slot: 82\n",
      "Rnd\n",
      "actionVec: [14, 63, 14, 28, 100]\n",
      "next_state: [100, 33, 12, 3, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  12   3   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 12, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  12   0   0]]\n",
      "rewardsum:  243.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  12   0   0]]\n",
      "rewardsum:  246.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  13   0   0]]\n",
      "rewardsum:  249.0\n",
      "Time Slot: 86\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  11   0   0]]\n",
      "rewardsum:  252.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  10   0   0]]\n",
      "rewardsum:  255.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  10   0   0]]\n",
      "rewardsum:  258.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  10   0   0]]\n",
      "rewardsum:  261.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  10   0   0]]\n",
      "rewardsum:  264.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [79, 36, 9, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[79 36  9  1  0]]\n",
      "rewardsum:  266.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  10   0   0]]\n",
      "rewardsum:  268.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  11   0   0]]\n",
      "rewardsum:  271.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  10   0   0]]\n",
      "rewardsum:  274.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 40, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 40  9  0  0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   9   0   0]]\n",
      "rewardsum:  280.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   8   0   0]]\n",
      "rewardsum:  284.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   7   0   0]]\n",
      "rewardsum:  288.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  291.0\n",
      "Episode: 25\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  9174\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [79, 7, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[79  7  0  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 12, 0, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12   0   1   0]]\n",
      "rewardsum:  1.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 16, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   1   0   0]]\n",
      "rewardsum:  5.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21   1   0   0]]\n",
      "rewardsum:  8.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   1   0   0]]\n",
      "rewardsum:  11.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   3   0   0]]\n",
      "rewardsum:  13.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 4, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   4   0   0]]\n",
      "rewardsum:  14.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   4   0   0]]\n",
      "rewardsum:  17.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   4   0   0]]\n",
      "rewardsum:  20.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   5   0   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [75, 36, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[75 36  6  0  0]]\n",
      "rewardsum:  26.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   9   0   0]]\n",
      "rewardsum:  29.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 30, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 30  8  0  0]]\n",
      "rewardsum:  32.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   9   0   0]]\n",
      "rewardsum:  36.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   9   0   0]]\n",
      "rewardsum:  39.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 8, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   8   0   0]]\n",
      "rewardsum:  44.0\n",
      "Time Slot: 16\n",
      "Rnd\n",
      "actionVec: [74, 15, 23, 20, 100]\n",
      "next_state: [93, 22, 6, 4, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[93 22  6  4  0]]\n",
      "rewardsum:  46.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 9, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21   9   0   0]]\n",
      "rewardsum:  52.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 7, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   7   1   0]]\n",
      "rewardsum:  55.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   7   0   0]]\n",
      "rewardsum:  59.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   7   0   0]]\n",
      "rewardsum:  62.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   5   0   0]]\n",
      "rewardsum:  65.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   7   0   0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   8   0   0]]\n",
      "rewardsum:  70.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   8   0   0]]\n",
      "rewardsum:  73.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [89, 36, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[89 36  8  0  0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  10   0   0]]\n",
      "rewardsum:  78.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 36, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 36  9  0  0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 28\n",
      "Rnd\n",
      "actionVec: [20, 61, 31, 64, 100]\n",
      "next_state: [100, 33, 6, 4, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   6   4   0]]\n",
      "rewardsum:  84.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 7, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   7   0   0]]\n",
      "rewardsum:  90.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   9   0   0]]\n",
      "rewardsum:  92.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   9   0   0]]\n",
      "rewardsum:  95.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  10   0   0]]\n",
      "rewardsum:  98.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   9   0   0]]\n",
      "rewardsum:  101.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 7, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   7   1   0]]\n",
      "rewardsum:  105.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   9   0   0]]\n",
      "rewardsum:  108.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 30, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 30  8  0  0]]\n",
      "rewardsum:  112.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   6   0   0]]\n",
      "rewardsum:  116.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   1   0]]\n",
      "rewardsum:  118.0\n",
      "Time Slot: 39\n",
      "Rnd\n",
      "actionVec: [2, 50, 17, 38, 100]\n",
      "next_state: [100, 41, 6, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   6   0   0]]\n",
      "rewardsum:  119.0\n",
      "Time Slot: 40\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 43, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43   7   0   0]]\n",
      "rewardsum:  121.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 43, 10, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43  10   1   0]]\n",
      "rewardsum:  123.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 44, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 44 11  0  0]]\n",
      "rewardsum:  126.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   9   0   0]]\n",
      "rewardsum:  130.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34 12  0  0]]\n",
      "rewardsum:  132.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  11   0   0]]\n",
      "rewardsum:  136.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  11   0   0]]\n",
      "rewardsum:  140.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  11   0   0]]\n",
      "rewardsum:  143.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 16, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  16   0   0]]\n",
      "rewardsum:  145.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  16   0   0]]\n",
      "rewardsum:  148.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  15   0   0]]\n",
      "rewardsum:  151.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  17   0   0]]\n",
      "rewardsum:  154.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 14, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  14   1   0]]\n",
      "rewardsum:  158.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 33, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 33 13  0  0]]\n",
      "rewardsum:  161.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  12   0   0]]\n",
      "rewardsum:  165.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 12, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  12   1   0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  14   0   0]]\n",
      "rewardsum:  171.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  13   0   0]]\n",
      "rewardsum:  174.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 30, 8, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 30  8  0  0]]\n",
      "rewardsum:  179.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  12   0   0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  11   0   0]]\n",
      "rewardsum:  185.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  10   0   0]]\n",
      "rewardsum:  188.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  11   0   0]]\n",
      "rewardsum:  190.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  11   0   0]]\n",
      "rewardsum:  192.0\n",
      "Time Slot: 64\n",
      "Rnd\n",
      "actionVec: [34, 7, 67, 8, 100]\n",
      "next_state: [100, 30, 19, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  19   0   0]]\n",
      "rewardsum:  193.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 19, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  19   0   0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 37, 21, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 37 21  0  0]]\n",
      "rewardsum:  198.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 35, 21, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 35 21  0  0]]\n",
      "rewardsum:  201.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 20, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  20   0   0]]\n",
      "rewardsum:  204.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [93, 34, 16, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[93 34 16  0  0]]\n",
      "rewardsum:  208.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  14   0   0]]\n",
      "rewardsum:  211.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 14, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  14   0   0]]\n",
      "rewardsum:  215.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  15   0   0]]\n",
      "rewardsum:  217.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  14   0   0]]\n",
      "rewardsum:  220.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  16   0   0]]\n",
      "rewardsum:  223.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 15, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34 15  1  0]]\n",
      "rewardsum:  225.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 15, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  15   0   0]]\n",
      "rewardsum:  229.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  14   0   0]]\n",
      "rewardsum:  232.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  13   0   0]]\n",
      "rewardsum:  235.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  13   0   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  12   0   0]]\n",
      "rewardsum:  241.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  12   0   0]]\n",
      "rewardsum:  244.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  14   0   0]]\n",
      "rewardsum:  247.0\n",
      "Time Slot: 83\n",
      "Rnd\n",
      "actionVec: [84, 9, 72, 36, 100]\n",
      "next_state: [98, 22, 27, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 22 27  1  0]]\n",
      "rewardsum:  247.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 25, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  25   0   0]]\n",
      "rewardsum:  252.0\n",
      "Time Slot: 85\n",
      "Rnd\n",
      "actionVec: [70, 42, 36, 19, 100]\n",
      "next_state: [100, 23, 23, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  23   2   0]]\n",
      "rewardsum:  255.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 22, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20  22   0   0]]\n",
      "rewardsum:  260.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 23, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  23   0   0]]\n",
      "rewardsum:  263.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  16   0   0]]\n",
      "rewardsum:  266.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 26, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 26 14  0  0]]\n",
      "rewardsum:  269.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 12, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  12   0   0]]\n",
      "rewardsum:  274.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  11   0   0]]\n",
      "rewardsum:  276.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  10   0   0]]\n",
      "rewardsum:  279.0\n",
      "Time Slot: 93\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   8   0   0]]\n",
      "rewardsum:  283.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 6, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   6   0   0]]\n",
      "rewardsum:  288.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 30, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 30  9  0  0]]\n",
      "rewardsum:  290.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   8   0   0]]\n",
      "rewardsum:  293.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  12   0   0]]\n",
      "rewardsum:  295.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  12   0   0]]\n",
      "rewardsum:  298.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  14   0   0]]\n",
      "rewardsum:  301.0\n",
      "Episode: 26\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  6960\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [85, 5, 2, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[85  5  2  1  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 6, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   6   2   0   0]]\n",
      "rewardsum:  4.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 11, 2, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11   2   1   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 14, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   3   0   0]]\n",
      "rewardsum:  9.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   4   0   0]]\n",
      "rewardsum:  12.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 20, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 20  3  0  0]]\n",
      "rewardsum:  16.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   2   0   0]]\n",
      "rewardsum:  19.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   3   0   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  25.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  27.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [94, 36, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[94 36  1  0  0]]\n",
      "rewardsum:  31.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  34.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   5   0   0]]\n",
      "rewardsum:  36.0\n",
      "Time Slot: 13\n",
      "Rnd\n",
      "actionVec: [72, 21, 46, 1, 100]\n",
      "next_state: [100, 32, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   9   0   0]]\n",
      "rewardsum:  39.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   7   0   0]]\n",
      "rewardsum:  43.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   9   0   0]]\n",
      "rewardsum:  46.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   8   0   0]]\n",
      "rewardsum:  48.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   9   0   0]]\n",
      "rewardsum:  51.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   8   0   0]]\n",
      "rewardsum:  54.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   7   0   0]]\n",
      "rewardsum:  58.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34  8  0  0]]\n",
      "rewardsum:  62.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   8   0   0]]\n",
      "rewardsum:  65.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   7   0   0]]\n",
      "rewardsum:  69.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   8   0   0]]\n",
      "rewardsum:  72.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   7   0   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   6   0   0]]\n",
      "rewardsum:  78.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 8, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  8  1  0]]\n",
      "rewardsum:  80.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   8   0   0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  11   0   0]]\n",
      "rewardsum:  84.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41  10   0   0]]\n",
      "rewardsum:  88.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42  11   0   0]]\n",
      "rewardsum:  90.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41  11   0   0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  11   0   0]]\n",
      "rewardsum:  95.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   9   0   0]]\n",
      "rewardsum:  99.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   8   0   0]]\n",
      "rewardsum:  102.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 36, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 36  8  0  0]]\n",
      "rewardsum:  105.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 36, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 36  6  0  0]]\n",
      "rewardsum:  108.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   8   0   0]]\n",
      "rewardsum:  111.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   6   0   0]]\n",
      "rewardsum:  114.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   6   0   0]]\n",
      "rewardsum:  118.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   5   0   0]]\n",
      "rewardsum:  121.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  125.0\n",
      "Time Slot: 42\n",
      "Rnd\n",
      "actionVec: [74, 73, 0, 58, 100]\n",
      "next_state: [100, 33, 3, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   1   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  132.0\n",
      "Time Slot: 44\n",
      "Rnd\n",
      "actionVec: [31, 89, 48, 83, 100]\n",
      "next_state: [100, 33, 1, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   2   0]]\n",
      "rewardsum:  134.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [77, 33, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[77 33  0  0  0]]\n",
      "rewardsum:  138.0\n",
      "Time Slot: 46\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [92, 36, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[92 36  1  0  0]]\n",
      "rewardsum:  140.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  143.0\n",
      "Time Slot: 48\n",
      "Rnd\n",
      "actionVec: [38, 88, 54, 78, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  146.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  149.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  151.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   6   0   0]]\n",
      "rewardsum:  153.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  5  0  0]]\n",
      "rewardsum:  156.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 6, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   6   0   0]]\n",
      "rewardsum:  157.0\n",
      "Time Slot: 54\n",
      "Rnd\n",
      "actionVec: [73, 71, 23, 70, 100]\n",
      "next_state: [99, 37, 0, 6, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 37  0  6  0]]\n",
      "rewardsum:  159.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 0, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   0   0   0]]\n",
      "rewardsum:  167.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   0   0]]\n",
      "rewardsum:  170.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  172.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 28, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 28  2  0  0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   0   0]]\n",
      "rewardsum:  177.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   1   0   0]]\n",
      "rewardsum:  180.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   4   0   0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   3   0   0]]\n",
      "rewardsum:  185.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   6   0   0]]\n",
      "rewardsum:  187.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   6   0   0]]\n",
      "rewardsum:  191.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   5   0   0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   2   0   0]]\n",
      "rewardsum:  198.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 29, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 29  1  0  0]]\n",
      "rewardsum:  202.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   2   0   0]]\n",
      "rewardsum:  205.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   0   0   0]]\n",
      "rewardsum:  209.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  1  0  0]]\n",
      "rewardsum:  212.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 33, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 33  2  0  0]]\n",
      "rewardsum:  214.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   0   0]]\n",
      "rewardsum:  216.0\n",
      "Time Slot: 73\n",
      "Rnd\n",
      "actionVec: [13, 62, 30, 23, 100]\n",
      "next_state: [100, 38, 4, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   4   1   0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   3   0   0]]\n",
      "rewardsum:  222.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  226.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [83, 36, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[83 36  2  0  0]]\n",
      "rewardsum:  229.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   4   0   0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 36, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 36  2  0  0]]\n",
      "rewardsum:  234.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   1   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  241.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   1   0   0]]\n",
      "rewardsum:  245.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   2   0   0]]\n",
      "rewardsum:  248.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   2   0   0]]\n",
      "rewardsum:  250.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   3   0   0]]\n",
      "rewardsum:  254.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   2   0   0]]\n",
      "rewardsum:  257.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   0   0]]\n",
      "rewardsum:  261.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  263.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   0   0]]\n",
      "rewardsum:  266.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   0   0   0]]\n",
      "rewardsum:  269.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 4, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   4   0   0]]\n",
      "rewardsum:  270.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 37, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 37  5  0  0]]\n",
      "rewardsum:  273.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  2  0  0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   1   0]]\n",
      "rewardsum:  280.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  284.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  286.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  289.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   4   0   0]]\n",
      "rewardsum:  292.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 35, 2, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 35  2  1  0]]\n",
      "rewardsum:  295.0\n",
      "Time Slot: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  299.0\n",
      "Episode: 27\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  8086\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [89, 3, 2, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[89  3  2  0  0]]\n",
      "rewardsum:  1.0\n",
      "Time Slot: 1\n",
      "Rnd\n",
      "actionVec: [60, 82, 68, 15, 100]\n",
      "next_state: [100, 3, 1, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   3   1   0   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 9, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   9   1   0   0]]\n",
      "rewardsum:  8.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 13, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13   2   0   0]]\n",
      "rewardsum:  10.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   3   0   0]]\n",
      "rewardsum:  13.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 22, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 22  4  0  0]]\n",
      "rewardsum:  15.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   2   0   0]]\n",
      "rewardsum:  19.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   3   0   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   0   0]]\n",
      "rewardsum:  26.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   1   0]]\n",
      "rewardsum:  29.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 34, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 34  1  0  0]]\n",
      "rewardsum:  32.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   0   0   0]]\n",
      "rewardsum:  35.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  37.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   2   0   0]]\n",
      "rewardsum:  39.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   3   0   0]]\n",
      "rewardsum:  41.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [87, 40, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[87 40  4  0  0]]\n",
      "rewardsum:  44.0\n",
      "Time Slot: 16\n",
      "Rnd\n",
      "actionVec: [84, 55, 11, 55, 100]\n",
      "next_state: [100, 33, 1, 3, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   3   0]]\n",
      "rewardsum:  48.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 1, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   1   0   0]]\n",
      "rewardsum:  54.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   1   0   0]]\n",
      "rewardsum:  57.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 0, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   0   1   0]]\n",
      "rewardsum:  60.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   0   0   0]]\n",
      "rewardsum:  63.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   1   0   0]]\n",
      "rewardsum:  65.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   0   0   0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   0   0   0]]\n",
      "rewardsum:  71.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   1   0   0]]\n",
      "rewardsum:  73.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   0   0   0]]\n",
      "rewardsum:  77.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   1   0   0]]\n",
      "rewardsum:  79.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 28\n",
      "Rnd\n",
      "actionVec: [17, 74, 32, 65, 100]\n",
      "next_state: [100, 38, 0, 3, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   0   3   0]]\n",
      "rewardsum:  83.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   0   0   0]]\n",
      "rewardsum:  87.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   0   0   0]]\n",
      "rewardsum:  90.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   1   0]]\n",
      "rewardsum:  92.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   1   0   0]]\n",
      "rewardsum:  95.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 38, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 38  2  0  0]]\n",
      "rewardsum:  97.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   1   0   0]]\n",
      "rewardsum:  100.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 0, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   0   1   0]]\n",
      "rewardsum:  103.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   0   0   0]]\n",
      "rewardsum:  106.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   0   0   0]]\n",
      "rewardsum:  109.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   0   0   0]]\n",
      "rewardsum:  111.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 3, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   3   0   0]]\n",
      "rewardsum:  112.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   4   0   0]]\n",
      "rewardsum:  115.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   5   0   0]]\n",
      "rewardsum:  117.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   6   0   0]]\n",
      "rewardsum:  121.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   6   0   0]]\n",
      "rewardsum:  124.0\n",
      "Time Slot: 44\n",
      "Rnd\n",
      "actionVec: [96, 80, 30, 5, 100]\n",
      "next_state: [100, 27, 6, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   6   0   0]]\n",
      "rewardsum:  129.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   4   0   0]]\n",
      "rewardsum:  134.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 23, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 23  4  0  0]]\n",
      "rewardsum:  137.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   7   0   0]]\n",
      "rewardsum:  139.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   9   0   0]]\n",
      "rewardsum:  142.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 27, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 27  6  0  0]]\n",
      "rewardsum:  146.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [75, 31, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[75 31  5  0  0]]\n",
      "rewardsum:  150.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  152.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   7   0   0]]\n",
      "rewardsum:  154.0\n",
      "Time Slot: 53\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   6   0   0]]\n",
      "rewardsum:  158.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   9   0   0]]\n",
      "rewardsum:  160.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   7   0   0]]\n",
      "rewardsum:  164.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   3   0   0]]\n",
      "rewardsum:  172.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   4   0   0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  177.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   1   0]]\n",
      "rewardsum:  179.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 37, 3, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 37  3  1  0]]\n",
      "rewardsum:  183.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  187.0\n",
      "Time Slot: 63\n",
      "Rnd\n",
      "actionVec: [14, 39, 92, 8, 100]\n",
      "next_state: [100, 39, 6, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   6   0   0]]\n",
      "rewardsum:  188.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   4   0   0]]\n",
      "rewardsum:  192.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  196.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  199.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   5   0   0]]\n",
      "rewardsum:  201.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   1   0]]\n",
      "rewardsum:  204.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  207.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   3   0   0]]\n",
      "rewardsum:  209.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [86, 39, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[86 39  4  0  0]]\n",
      "rewardsum:  212.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   0   0   0]]\n",
      "rewardsum:  216.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   0   0   0]]\n",
      "rewardsum:  219.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   1   0   0]]\n",
      "rewardsum:  221.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  2  0  0]]\n",
      "rewardsum:  224.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  227.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  230.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34  0  0  0]]\n",
      "rewardsum:  234.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  236.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   3   0   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [94, 34, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[94 34  6  0  0]]\n",
      "rewardsum:  241.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34  5  0  0]]\n",
      "rewardsum:  244.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  248.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  4  0  0]]\n",
      "rewardsum:  251.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 0, 2, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   0   2   0]]\n",
      "rewardsum:  255.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   1   0   0]]\n",
      "rewardsum:  259.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   2   0   0]]\n",
      "rewardsum:  262.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  264.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  2  0  0]]\n",
      "rewardsum:  268.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   0   0]]\n",
      "rewardsum:  271.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  274.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   6   0   0]]\n",
      "rewardsum:  276.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   6   0   0]]\n",
      "rewardsum:  279.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   6   0   0]]\n",
      "rewardsum:  282.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  6  0  0]]\n",
      "rewardsum:  285.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   9   0   0]]\n",
      "rewardsum:  287.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  10   0   0]]\n",
      "rewardsum:  290.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 10, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  10   1   0]]\n",
      "rewardsum:  292.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 8, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   8   0   0]]\n",
      "rewardsum:  297.0\n",
      "Episode: 28\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  5100\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [90, 5, 2, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[90  5  2  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Rnd\n",
      "actionVec: [60, 94, 50, 71, 100]\n",
      "next_state: [100, 8, 0, 3, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   8   0   3   0]]\n",
      "rewardsum:  3.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 9, 1, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   9   1   0   0]]\n",
      "rewardsum:  8.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 13, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13   2   0   0]]\n",
      "rewardsum:  11.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 17, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   0   0   0]]\n",
      "rewardsum:  14.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   2   0   0]]\n",
      "rewardsum:  17.0\n",
      "Time Slot: 6\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   1   0   0]]\n",
      "rewardsum:  20.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   1   0   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  25.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   3   0   0]]\n",
      "rewardsum:  27.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 37, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 37  1  0  0]]\n",
      "rewardsum:  31.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 36, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 36  2  0  0]]\n",
      "rewardsum:  33.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  36.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   1   0   0]]\n",
      "rewardsum:  40.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  42.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  45.0\n",
      "Time Slot: 16\n",
      "Rnd\n",
      "actionVec: [78, 15, 11, 76, 100]\n",
      "next_state: [81, 26, 2, 7, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[81 26  2  7  0]]\n",
      "rewardsum:  46.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 28, 0, 3, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 28  0  3  0]]\n",
      "rewardsum:  52.0\n",
      "Time Slot: 18\n",
      "Rnd\n",
      "actionVec: [30, 97, 40, 53, 100]\n",
      "next_state: [100, 29, 0, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   0   1   0]]\n",
      "rewardsum:  57.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   1   0   0]]\n",
      "rewardsum:  60.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [89, 29, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[89 29  3  0  0]]\n",
      "rewardsum:  62.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  65.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   0   0   0]]\n",
      "rewardsum:  69.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   0   0   0]]\n",
      "rewardsum:  71.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  74.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  77.0\n",
      "Time Slot: 26\n",
      "Rnd\n",
      "actionVec: [8, 94, 80, 62, 100]\n",
      "next_state: [100, 40, 3, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   3   1   0]]\n",
      "rewardsum:  77.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 1, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   1   0   0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   0   0   0]]\n",
      "rewardsum:  85.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   2   0   0]]\n",
      "rewardsum:  87.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 41, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 41  0  0  0]]\n",
      "rewardsum:  90.0\n",
      "Time Slot: 31\n",
      "Rnd\n",
      "actionVec: [85, 42, 26, 4, 100]\n",
      "next_state: [100, 29, 1, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   1   0   0]]\n",
      "rewardsum:  95.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   0   0   0]]\n",
      "rewardsum:  98.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   0   0]]\n",
      "rewardsum:  99.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 4, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   4   1   0]]\n",
      "rewardsum:  102.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   4   0   0]]\n",
      "rewardsum:  105.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 37, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 37  4  0  0]]\n",
      "rewardsum:  107.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   1   0   0]]\n",
      "rewardsum:  110.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   1   0   0]]\n",
      "rewardsum:  113.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 41, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 41  0  0  0]]\n",
      "rewardsum:  116.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   1   0   0]]\n",
      "rewardsum:  120.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 34, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 34  0  0  0]]\n",
      "rewardsum:  123.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   0   0   0]]\n",
      "rewardsum:  126.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   0   0]]\n",
      "rewardsum:  129.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 1, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   1   0   0]]\n",
      "rewardsum:  130.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   0   0   0]]\n",
      "rewardsum:  134.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   1   0   0]]\n",
      "rewardsum:  137.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   1   0   0]]\n",
      "rewardsum:  139.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   0   0   0]]\n",
      "rewardsum:  143.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   0   0   0]]\n",
      "rewardsum:  145.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  148.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   0   0   0]]\n",
      "rewardsum:  151.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 39, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 39  1  0  0]]\n",
      "rewardsum:  153.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   1   0   0]]\n",
      "rewardsum:  156.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 39, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 39  2  0  0]]\n",
      "rewardsum:  158.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [77, 40, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[77 40  2  0  0]]\n",
      "rewardsum:  161.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 37, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 37  4  0  0]]\n",
      "rewardsum:  164.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   3   0   0]]\n",
      "rewardsum:  167.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  170.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  173.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   4   0   0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 61\n",
      "Rnd\n",
      "actionVec: [8, 96, 34, 6, 100]\n",
      "next_state: [100, 45, 3, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  45   3   0   0]]\n",
      "rewardsum:  176.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 45, 1, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  45   1   1   0]]\n",
      "rewardsum:  179.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   3   0   0]]\n",
      "rewardsum:  183.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   1   0   0]]\n",
      "rewardsum:  187.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 1, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   1   1   0]]\n",
      "rewardsum:  189.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   0   0]]\n",
      "rewardsum:  192.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   0   0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34  1  0  0]]\n",
      "rewardsum:  199.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 34, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 34  3  0  0]]\n",
      "rewardsum:  202.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  205.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   1   0]]\n",
      "rewardsum:  207.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 37, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 37  2  0  0]]\n",
      "rewardsum:  210.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   5   0   0]]\n",
      "rewardsum:  212.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   7   0   0]]\n",
      "rewardsum:  214.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   7   0   0]]\n",
      "rewardsum:  217.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 36, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 36  8  0  0]]\n",
      "rewardsum:  220.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   7   0   0]]\n",
      "rewardsum:  224.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 10, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  10   0   0]]\n",
      "rewardsum:  225.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   9   0   0]]\n",
      "rewardsum:  229.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   7   0   0]]\n",
      "rewardsum:  232.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   8   0   0]]\n",
      "rewardsum:  235.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [94, 31, 5, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[94 31  5  0  0]]\n",
      "rewardsum:  240.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   5   0   0]]\n",
      "rewardsum:  243.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   6   0   0]]\n",
      "rewardsum:  246.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   5   0   0]]\n",
      "rewardsum:  249.0\n",
      "Time Slot: 86\n",
      "Rnd\n",
      "actionVec: [69, 25, 23, 34, 100]\n",
      "next_state: [95, 27, 0, 3, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 27  0  3  0]]\n",
      "rewardsum:  253.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 1, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   1   0   0]]\n",
      "rewardsum:  258.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 30, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 30  1  0  0]]\n",
      "rewardsum:  261.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 30, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 30  0  0  0]]\n",
      "rewardsum:  264.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   0   0   0]]\n",
      "rewardsum:  267.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  268.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   5   0   0]]\n",
      "rewardsum:  271.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   6   0   0]]\n",
      "rewardsum:  273.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   4   0   0]]\n",
      "rewardsum:  276.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 39, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 39  3  0  0]]\n",
      "rewardsum:  279.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   3   0   0]]\n",
      "rewardsum:  282.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 37, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 37  4  0  0]]\n",
      "rewardsum:  285.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  289.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  292.0\n",
      "Episode: 29\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  8606\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [82, 5, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[82  5  0  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 8, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   8   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 16, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 37, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 37  0  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 44, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  44   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 54, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  54   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 58, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  58   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 57, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  57   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 57, 3, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 57  3  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 55, 5, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  55   5   1   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 47, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  47   7   0   0]]\n",
      "rewardsum:  4.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   7   0   0]]\n",
      "rewardsum:  7.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 39, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 39  5  0  0]]\n",
      "rewardsum:  11.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  36   7   0   0]]\n",
      "rewardsum:  13.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   5   0   0]]\n",
      "rewardsum:  16.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  20.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  2  0  0]]\n",
      "rewardsum:  23.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   3   0   0]]\n",
      "rewardsum:  25.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [93, 33, 2, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[93 33  2  0  0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  32.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 39, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 39  1  0  0]]\n",
      "rewardsum:  35.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   0   0   0]]\n",
      "rewardsum:  38.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  41.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   2   0   0]]\n",
      "rewardsum:  44.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 2, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   2   1   0]]\n",
      "rewardsum:  46.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   0   0   0]]\n",
      "rewardsum:  51.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   0   0   0]]\n",
      "rewardsum:  54.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34  2  0  0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [93, 38, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[93 38  1  0  0]]\n",
      "rewardsum:  58.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   0   0   0]]\n",
      "rewardsum:  62.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   1   0   0]]\n",
      "rewardsum:  64.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   1   0   0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   2   0   0]]\n",
      "rewardsum:  70.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  73.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   4   0   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 37\n",
      "Rnd\n",
      "actionVec: [11, 61, 89, 27, 100]\n",
      "next_state: [100, 40, 5, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   5   0   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   6   0   0]]\n",
      "rewardsum:  79.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   3   0   0]]\n",
      "rewardsum:  83.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [94, 36, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[94 36  7  0  0]]\n",
      "rewardsum:  86.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [95, 39, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 39  6  0  0]]\n",
      "rewardsum:  88.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   6   0   0]]\n",
      "rewardsum:  92.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   0   0]]\n",
      "rewardsum:  95.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  7  0  0]]\n",
      "rewardsum:  97.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 36, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 36  5  0  0]]\n",
      "rewardsum:  101.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   4   0   0]]\n",
      "rewardsum:  103.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 37, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 37  5  0  0]]\n",
      "rewardsum:  106.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   7   0   0]]\n",
      "rewardsum:  109.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   6   0   0]]\n",
      "rewardsum:  112.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   7   0   0]]\n",
      "rewardsum:  115.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   7   0   0]]\n",
      "rewardsum:  117.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   7   0   0]]\n",
      "rewardsum:  120.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   7   0   0]]\n",
      "rewardsum:  123.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   6   0   0]]\n",
      "rewardsum:  126.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 37, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 37  6  0  0]]\n",
      "rewardsum:  129.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34  7  0  0]]\n",
      "rewardsum:  132.0\n",
      "Time Slot: 57\n",
      "Rnd\n",
      "actionVec: [47, 44, 58, 76, 100]\n",
      "next_state: [100, 32, 5, 3, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   3   0]]\n",
      "rewardsum:  134.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 8, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   8   0   0]]\n",
      "rewardsum:  139.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   9   0   0]]\n",
      "rewardsum:  142.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  10   0   0]]\n",
      "rewardsum:  144.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  10   0   0]]\n",
      "rewardsum:  147.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  11   0   0]]\n",
      "rewardsum:  151.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  14   0   0]]\n",
      "rewardsum:  153.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 34, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 34 13  0  0]]\n",
      "rewardsum:  156.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  15   0   0]]\n",
      "rewardsum:  158.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  15   0   0]]\n",
      "rewardsum:  161.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 36, 11, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 36 11  1  0]]\n",
      "rewardsum:  164.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 12, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  12   0   0]]\n",
      "rewardsum:  169.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  14   0   0]]\n",
      "rewardsum:  171.0\n",
      "Time Slot: 70\n",
      "Rnd\n",
      "actionVec: [21, 97, 54, 73, 100]\n",
      "next_state: [100, 35, 11, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  35  11   2   0]]\n",
      "rewardsum:  173.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 11, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  11   0   0]]\n",
      "rewardsum:  178.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  12   0   0]]\n",
      "rewardsum:  180.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 40, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 40 11  0  0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  11   0   0]]\n",
      "rewardsum:  185.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   9   0   0]]\n",
      "rewardsum:  188.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [75, 39, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[75 39  9  0  0]]\n",
      "rewardsum:  192.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   8   0   0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 8, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   8   1   0]]\n",
      "rewardsum:  198.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 34, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 34 10  0  0]]\n",
      "rewardsum:  201.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  12   0   0]]\n",
      "rewardsum:  203.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  10   0   0]]\n",
      "rewardsum:  207.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  11   0   0]]\n",
      "rewardsum:  209.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   9   0   0]]\n",
      "rewardsum:  213.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   7   0   0]]\n",
      "rewardsum:  216.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   6   0   0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 7, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   7   1   0]]\n",
      "rewardsum:  220.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   7   0   0]]\n",
      "rewardsum:  224.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 38, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 38  8  0  0]]\n",
      "rewardsum:  226.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 7, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   7   1   0]]\n",
      "rewardsum:  230.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   8   0   0]]\n",
      "rewardsum:  233.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   9   0   0]]\n",
      "rewardsum:  236.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 33, 11, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 33 11  1  0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 93\n",
      "Rnd\n",
      "actionVec: [10, 13, 34, 82, 100]\n",
      "next_state: [100, 39, 13, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  13   0   0]]\n",
      "rewardsum:  239.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42  15   0   0]]\n",
      "rewardsum:  241.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 42, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 42 16  0  0]]\n",
      "rewardsum:  244.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  15   0   0]]\n",
      "rewardsum:  247.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  14   0   0]]\n",
      "rewardsum:  250.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 14, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  14   0   0]]\n",
      "rewardsum:  251.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41  12   0   0]]\n",
      "rewardsum:  253.0\n",
      "Episode: 30\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  9582\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Rnd\n",
      "actionVec: [45, 72, 78, 54, 100]\n",
      "next_state: [84, 4, 1, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[84  4  1  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 10, 4, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10   4   0   0]]\n",
      "rewardsum:  1.0\n",
      "Time Slot: 2\n",
      "Rnd\n",
      "actionVec: [76, 16, 51, 95, 100]\n",
      "next_state: [100, 5, 8, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   5   8   1   0]]\n",
      "rewardsum:  4.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 10, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10   8   0   0]]\n",
      "rewardsum:  7.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 14, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   8   0   0]]\n",
      "rewardsum:  10.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 19, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 19  9  0  0]]\n",
      "rewardsum:  13.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   9   0   0]]\n",
      "rewardsum:  16.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  10   0   0]]\n",
      "rewardsum:  19.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   9   0   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  14   0   0]]\n",
      "rewardsum:  24.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 14, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  14   0   0]]\n",
      "rewardsum:  28.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  14   0   0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 14, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  14   0   0]]\n",
      "rewardsum:  34.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  13   0   0]]\n",
      "rewardsum:  37.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  13   0   0]]\n",
      "rewardsum:  40.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [74, 38, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[74 38 12  0  0]]\n",
      "rewardsum:  42.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 16, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  16   0   0]]\n",
      "rewardsum:  44.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  15   0   0]]\n",
      "rewardsum:  47.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 14, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  14   0   0]]\n",
      "rewardsum:  51.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  15   0   0]]\n",
      "rewardsum:  53.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  17   0   0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 16, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  16   0   0]]\n",
      "rewardsum:  58.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 16, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  33  16   1   0]]\n",
      "rewardsum:  61.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  17   0   0]]\n",
      "rewardsum:  64.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 17, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  17   0   0]]\n",
      "rewardsum:  66.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  12   0   0]]\n",
      "rewardsum:  70.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 10, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  10   1   0]]\n",
      "rewardsum:  73.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   8   0   0]]\n",
      "rewardsum:  77.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 36, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 36 10  0  0]]\n",
      "rewardsum:  80.0\n",
      "Time Slot: 29\n",
      "Rnd\n",
      "actionVec: [74, 0, 1, 80, 100]\n",
      "next_state: [98, 28, 0, 12, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 28  0 12  0]]\n",
      "rewardsum:  81.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 0, 0, 0]\n",
      "Reward: 12.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   0   0   0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 1, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   1   0   0]]\n",
      "rewardsum:  94.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   0   0   0]]\n",
      "rewardsum:  98.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   1   0   0]]\n",
      "rewardsum:  101.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   2   0   0]]\n",
      "rewardsum:  104.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  106.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  3  0  0]]\n",
      "rewardsum:  109.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  112.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  116.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   1   0]]\n",
      "rewardsum:  118.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 34, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 34  4  0  0]]\n",
      "rewardsum:  121.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  125.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 29, 2, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 29  2  0  0]]\n",
      "rewardsum:  130.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   4   0   0]]\n",
      "rewardsum:  133.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   3   0   0]]\n",
      "rewardsum:  136.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [95, 26, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 26  0  0  0]]\n",
      "rewardsum:  141.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   3   0   0]]\n",
      "rewardsum:  143.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   3   0   0]]\n",
      "rewardsum:  146.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   2   0   0]]\n",
      "rewardsum:  150.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   5   0   0]]\n",
      "rewardsum:  152.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  155.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   5   0   0]]\n",
      "rewardsum:  157.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   6   0   0]]\n",
      "rewardsum:  159.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 40, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 40  4  0  0]]\n",
      "rewardsum:  162.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   6   0   0]]\n",
      "rewardsum:  165.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   6   0   0]]\n",
      "rewardsum:  167.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   8   0   0]]\n",
      "rewardsum:  169.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   8   0   0]]\n",
      "rewardsum:  171.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   7   0   0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 8, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   8   1   0]]\n",
      "rewardsum:  177.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 7, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   7   0   0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   8   0   0]]\n",
      "rewardsum:  185.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   8   0   0]]\n",
      "rewardsum:  188.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   7   0   0]]\n",
      "rewardsum:  192.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   6   0   0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   5   0   0]]\n",
      "rewardsum:  199.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  201.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 1, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  1  0  0]]\n",
      "rewardsum:  206.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  208.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  210.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   7   0   0]]\n",
      "rewardsum:  212.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 35, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 35  5  0  0]]\n",
      "rewardsum:  216.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  219.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   3   0   0]]\n",
      "rewardsum:  223.0\n",
      "Time Slot: 74\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  1  0  0]]\n",
      "rewardsum:  227.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   0   0   0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   1   0   0]]\n",
      "rewardsum:  233.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   1   0   0]]\n",
      "rewardsum:  236.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   0   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  241.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   0   0   0]]\n",
      "rewardsum:  244.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   2   0   0]]\n",
      "rewardsum:  246.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 43, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43   2   0   0]]\n",
      "rewardsum:  248.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   2   0   0]]\n",
      "rewardsum:  251.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   0   0   0]]\n",
      "rewardsum:  255.0\n",
      "Time Slot: 85\n",
      "Rnd\n",
      "actionVec: [49, 57, 66, 0, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  258.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 31, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 31  1  0  0]]\n",
      "rewardsum:  262.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   1   0   0]]\n",
      "rewardsum:  265.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   3   0   0]]\n",
      "rewardsum:  268.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   6   0   0]]\n",
      "rewardsum:  270.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   7   0   0]]\n",
      "rewardsum:  273.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   8   0   0]]\n",
      "rewardsum:  275.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 5, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   5   0   0]]\n",
      "rewardsum:  280.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  283.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   6   0   0]]\n",
      "rewardsum:  285.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  288.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   0   0]]\n",
      "rewardsum:  292.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   6   0   0]]\n",
      "rewardsum:  294.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  298.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   6   0   0]]\n",
      "rewardsum:  301.0\n",
      "Episode: 31\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  6789\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [85, 6, 0, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[85  6  0  1  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 12, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12   0   0   0]]\n",
      "rewardsum:  2.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 16, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   0   0   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 16, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   1   0   0]]\n",
      "rewardsum:  9.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   0   0   0]]\n",
      "rewardsum:  12.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 28, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 28  1  0  0]]\n",
      "rewardsum:  14.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 0, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   1   0]]\n",
      "rewardsum:  16.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   1   0   0]]\n",
      "rewardsum:  18.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   2   0   0]]\n",
      "rewardsum:  21.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   0   0   0]]\n",
      "rewardsum:  25.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [93, 37, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[93 37  2  0  0]]\n",
      "rewardsum:  28.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  31.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   3   0   0]]\n",
      "rewardsum:  34.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 28, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 28  3  0  0]]\n",
      "rewardsum:  38.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   4   0   0]]\n",
      "rewardsum:  40.0\n",
      "Time Slot: 15\n",
      "Rnd\n",
      "actionVec: [11, 31, 91, 40, 100]\n",
      "next_state: [100, 33, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   6   0   0]]\n",
      "rewardsum:  42.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   6   0   0]]\n",
      "rewardsum:  45.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   5   0   0]]\n",
      "rewardsum:  48.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   4   0   0]]\n",
      "rewardsum:  52.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   5   0   0]]\n",
      "rewardsum:  54.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [85, 38, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[85 38  2  0  0]]\n",
      "rewardsum:  57.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  61.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   0   0]]\n",
      "rewardsum:  65.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  71.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [80, 26, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[80 26  5  0  0]]\n",
      "rewardsum:  74.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   6   0   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   8   0   0]]\n",
      "rewardsum:  79.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  31   7   0   0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  10   0   0]]\n",
      "rewardsum:  84.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   8   0   0]]\n",
      "rewardsum:  88.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   6   0   0]]\n",
      "rewardsum:  92.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 9, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  9  0  0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 8, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   8   1   0]]\n",
      "rewardsum:  95.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   9   0   0]]\n",
      "rewardsum:  98.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   7   0   0]]\n",
      "rewardsum:  101.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   4   0   0]]\n",
      "rewardsum:  106.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  109.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  111.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  7  0  0]]\n",
      "rewardsum:  114.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   8   0   0]]\n",
      "rewardsum:  117.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   6   0   0]]\n",
      "rewardsum:  121.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   6   0   0]]\n",
      "rewardsum:  125.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   7   0   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 44\n",
      "Rnd\n",
      "actionVec: [1, 63, 49, 17, 100]\n",
      "next_state: [100, 39, 7, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   7   0   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   5   0   0]]\n",
      "rewardsum:  132.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [78, 42, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[78 42  6  0  0]]\n",
      "rewardsum:  134.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 45, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  45   6   0   0]]\n",
      "rewardsum:  136.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 45, 3, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 45  3  1  0]]\n",
      "rewardsum:  141.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 34, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 34  4  0  0]]\n",
      "rewardsum:  144.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  148.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   0   0]]\n",
      "rewardsum:  151.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   0   0]]\n",
      "rewardsum:  154.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  157.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 0, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  0  1  0]]\n",
      "rewardsum:  161.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   0   0   0]]\n",
      "rewardsum:  165.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 30, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 30  1  0  0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   0   0   0]]\n",
      "rewardsum:  172.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   3   0   0]]\n",
      "rewardsum:  174.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   1   0]]\n",
      "rewardsum:  176.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  179.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 1, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   1   1   0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  185.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   2   0   0]]\n",
      "rewardsum:  188.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  192.0\n",
      "Time Slot: 65\n",
      "Rnd\n",
      "actionVec: [92, 81, 31, 5, 100]\n",
      "next_state: [100, 30, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   0   0   0]]\n",
      "rewardsum:  197.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  197.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   0   0]]\n",
      "rewardsum:  200.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  203.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  206.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 35, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 35  4  0  0]]\n",
      "rewardsum:  209.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   3   0   0]]\n",
      "rewardsum:  213.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  216.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  219.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   0   0   0]]\n",
      "rewardsum:  223.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  225.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  2  0  0]]\n",
      "rewardsum:  228.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   0   0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 37, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 37  0  0  0]]\n",
      "rewardsum:  234.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 34, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 34  0  0  0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   0   0   0]]\n",
      "rewardsum:  240.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 36, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[98 36  0  0  0]]\n",
      "rewardsum:  243.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   0   0   0]]\n",
      "rewardsum:  246.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   0   0   0]]\n",
      "rewardsum:  249.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  252.0\n",
      "Time Slot: 85\n",
      "Rnd\n",
      "actionVec: [6, 79, 63, 59, 100]\n",
      "next_state: [100, 41, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   0   0   0]]\n",
      "rewardsum:  254.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   0   0   0]]\n",
      "rewardsum:  256.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   2   0   0]]\n",
      "rewardsum:  258.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   3   0   0]]\n",
      "rewardsum:  261.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 43, 3, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43   3   1   0]]\n",
      "rewardsum:  263.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   1   0   0]]\n",
      "rewardsum:  266.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   1   0   0]]\n",
      "rewardsum:  269.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   0   0   0]]\n",
      "rewardsum:  273.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 38, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 38  2  0  0]]\n",
      "rewardsum:  275.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   5   0   0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  280.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  283.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   4   0   0]]\n",
      "rewardsum:  285.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   5   0   0]]\n",
      "rewardsum:  288.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 6, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   6   0   0]]\n",
      "rewardsum:  289.0\n",
      "Episode: 32\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  9919\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [83, 5, 1, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[83  5  1  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 7, 0, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   7   0   1   0]]\n",
      "rewardsum:  3.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 11, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11   0   0   0]]\n",
      "rewardsum:  7.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 15, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15   2   0   0]]\n",
      "rewardsum:  9.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 19, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   1   0   0]]\n",
      "rewardsum:  12.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [70, 22, 1, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[70 22  1  1  0]]\n",
      "rewardsum:  15.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   0   0   0]]\n",
      "rewardsum:  19.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   0   0   0]]\n",
      "rewardsum:  21.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  24.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  26.0\n",
      "Time Slot: 10\n",
      "Rnd\n",
      "actionVec: [54, 76, 15, 66, 100]\n",
      "next_state: [100, 37, 0, 3, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   0   3   0]]\n",
      "rewardsum:  28.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   0   0   0]]\n",
      "rewardsum:  33.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  35.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   3   0   0]]\n",
      "rewardsum:  37.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   3   0   0]]\n",
      "rewardsum:  40.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 37, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 37  0  0  0]]\n",
      "rewardsum:  44.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   0   0   0]]\n",
      "rewardsum:  47.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   0   0]]\n",
      "rewardsum:  50.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  52.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   3   0   0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   1   0   0]]\n",
      "rewardsum:  60.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   1   0   0]]\n",
      "rewardsum:  63.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   1   0   0]]\n",
      "rewardsum:  66.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   4   0   0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   6   0   0]]\n",
      "rewardsum:  70.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   5   0   0]]\n",
      "rewardsum:  74.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   6   0   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   6   0   0]]\n",
      "rewardsum:  78.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   5   0   0]]\n",
      "rewardsum:  81.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   5   0   0]]\n",
      "rewardsum:  85.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 10, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34 10  0  0]]\n",
      "rewardsum:  86.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 31, 12, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 31 12  1  0]]\n",
      "rewardsum:  89.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  12   0   0]]\n",
      "rewardsum:  92.0\n",
      "Time Slot: 33\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 13, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  13   1   0]]\n",
      "rewardsum:  94.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  14   0   0]]\n",
      "rewardsum:  97.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  14   0   0]]\n",
      "rewardsum:  100.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  13   0   0]]\n",
      "rewardsum:  104.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  13   0   0]]\n",
      "rewardsum:  108.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  12   0   0]]\n",
      "rewardsum:  111.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  15   0   0]]\n",
      "rewardsum:  113.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 14, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  14   0   0]]\n",
      "rewardsum:  117.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 30, 17, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 30 17  0  0]]\n",
      "rewardsum:  119.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 16, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  16   0   0]]\n",
      "rewardsum:  121.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  16   0   0]]\n",
      "rewardsum:  124.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 14, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35 14  0  0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  14   0   0]]\n",
      "rewardsum:  131.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  15   0   0]]\n",
      "rewardsum:  134.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  13   0   0]]\n",
      "rewardsum:  137.0\n",
      "Time Slot: 48\n",
      "Rnd\n",
      "actionVec: [97, 7, 24, 40, 100]\n",
      "next_state: [94, 23, 19, 3, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[94 23 19  3  0]]\n",
      "rewardsum:  138.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 19, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25  19   0   0]]\n",
      "rewardsum:  144.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 19, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  19   0   0]]\n",
      "rewardsum:  147.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 18, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  18   0   0]]\n",
      "rewardsum:  150.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 25, 19, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 25 19  0  0]]\n",
      "rewardsum:  153.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 16, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  16   0   0]]\n",
      "rewardsum:  155.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 13, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  13   1   0]]\n",
      "rewardsum:  159.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 31, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 31 12  0  0]]\n",
      "rewardsum:  163.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  11   0   0]]\n",
      "rewardsum:  166.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  12   0   0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   9   0   0]]\n",
      "rewardsum:  172.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  12   0   0]]\n",
      "rewardsum:  174.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  12   0   0]]\n",
      "rewardsum:  176.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  12   0   0]]\n",
      "rewardsum:  179.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  14   0   0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  12   0   0]]\n",
      "rewardsum:  186.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  13   0   0]]\n",
      "rewardsum:  188.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  15   0   0]]\n",
      "rewardsum:  191.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 14, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32 14  1  0]]\n",
      "rewardsum:  194.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 13, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  13   1   0]]\n",
      "rewardsum:  198.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  12   0   0]]\n",
      "rewardsum:  202.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  10   0   0]]\n",
      "rewardsum:  205.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  10   0   0]]\n",
      "rewardsum:  208.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   9   0   0]]\n",
      "rewardsum:  210.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 36, 6, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 36  6  0  0]]\n",
      "rewardsum:  216.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   6   0   0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  5  0  0]]\n",
      "rewardsum:  221.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   8   0   0]]\n",
      "rewardsum:  223.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   9   0   0]]\n",
      "rewardsum:  226.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   6   0   0]]\n",
      "rewardsum:  230.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   7   0   0]]\n",
      "rewardsum:  234.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  237.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   7   0   0]]\n",
      "rewardsum:  240.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   8   0   0]]\n",
      "rewardsum:  242.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   9   0   0]]\n",
      "rewardsum:  245.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  10   0   0]]\n",
      "rewardsum:  247.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 34, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[97 34 12  0  0]]\n",
      "rewardsum:  250.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 12, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  12   0   0]]\n",
      "rewardsum:  251.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  12   0   0]]\n",
      "rewardsum:  254.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  12   0   0]]\n",
      "rewardsum:  258.0\n",
      "Time Slot: 88\n",
      "Rnd\n",
      "actionVec: [30, 39, 27, 41, 100]\n",
      "next_state: [100, 36, 8, 4, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   8   4   0]]\n",
      "rewardsum:  260.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 10, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  10   0   0]]\n",
      "rewardsum:  266.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  11   0   0]]\n",
      "rewardsum:  268.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [50, 29, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[50 29 14  0  0]]\n",
      "rewardsum:  270.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 28, 11, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 28 11  0  0]]\n",
      "rewardsum:  275.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  13   0   0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  15   0   0]]\n",
      "rewardsum:  279.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  15   0   0]]\n",
      "rewardsum:  282.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  14   0   0]]\n",
      "rewardsum:  285.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 17, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  17   0   0]]\n",
      "rewardsum:  286.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41  16   0   0]]\n",
      "rewardsum:  289.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 40, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 40 15  0  0]]\n",
      "rewardsum:  291.0\n",
      "Episode: 33\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  7335\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [84, 9, 2, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[84  9  2  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 13, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13   2   0   0]]\n",
      "rewardsum:  3.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 14, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   2   0   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 4, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   4   0   0]]\n",
      "rewardsum:  7.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   3   0   0]]\n",
      "rewardsum:  11.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 29, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 29  3  0  0]]\n",
      "rewardsum:  14.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   4   0   0]]\n",
      "rewardsum:  17.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  21.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   3   0   0]]\n",
      "rewardsum:  24.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   1   0   0]]\n",
      "rewardsum:  27.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [89, 32, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[89 32  2  0  0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  33.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  36.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   1   0]]\n",
      "rewardsum:  38.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   0   0]]\n",
      "rewardsum:  42.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   0   0]]\n",
      "rewardsum:  46.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   0   0   0]]\n",
      "rewardsum:  48.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   0   0   0]]\n",
      "rewardsum:  50.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 0, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   0   1   0]]\n",
      "rewardsum:  53.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   1   0   0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [82, 40, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[82 40  4  0  0]]\n",
      "rewardsum:  58.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 4, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   4   1   0]]\n",
      "rewardsum:  60.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 7, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   7   1   0]]\n",
      "rewardsum:  62.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   9   0   0]]\n",
      "rewardsum:  64.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  10   0   0]]\n",
      "rewardsum:  67.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [84, 35, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[84 35 11  0  0]]\n",
      "rewardsum:  71.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 8, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   8   1   0]]\n",
      "rewardsum:  74.0\n",
      "Time Slot: 27\n",
      "Rnd\n",
      "actionVec: [90, 77, 20, 21, 100]\n",
      "next_state: [93, 30, 3, 2, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[93 30  3  2  0]]\n",
      "rewardsum:  78.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   4   0   0]]\n",
      "rewardsum:  83.0\n",
      "Time Slot: 29\n",
      "Rnd\n",
      "actionVec: [62, 0, 68, 76, 100]\n",
      "next_state: [100, 25, 4, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   4   2   0]]\n",
      "rewardsum:  85.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 5, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   5   0   0]]\n",
      "rewardsum:  90.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   3   0   0]]\n",
      "rewardsum:  94.0\n",
      "Time Slot: 32\n",
      "Rnd\n",
      "actionVec: [15, 58, 55, 27, 100]\n",
      "next_state: [100, 30, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   2   0   0]]\n",
      "rewardsum:  97.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   3   0   0]]\n",
      "rewardsum:  100.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  102.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  105.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  109.0\n",
      "Time Slot: 37\n",
      "Rnd\n",
      "actionVec: [4, 32, 3, 91, 100]\n",
      "next_state: [100, 42, 2, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   2   0   0]]\n",
      "rewardsum:  109.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   0   0   0]]\n",
      "rewardsum:  113.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   2   0   0]]\n",
      "rewardsum:  116.0\n",
      "Time Slot: 40\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   5   0   0]]\n",
      "rewardsum:  118.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   3   0   0]]\n",
      "rewardsum:  122.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   0   0]]\n",
      "rewardsum:  125.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   0   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  130.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  134.0\n",
      "Time Slot: 46\n",
      "Rnd\n",
      "actionVec: [46, 13, 46, 76, 100]\n",
      "next_state: [89, 32, 5, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[89 32  5  1  0]]\n",
      "rewardsum:  136.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   5   0   0]]\n",
      "rewardsum:  140.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   5   0   0]]\n",
      "rewardsum:  143.0\n",
      "Time Slot: 49\n",
      "Rnd\n",
      "actionVec: [11, 57, 30, 45, 100]\n",
      "next_state: [100, 30, 0, 3, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   0   3   0]]\n",
      "rewardsum:  146.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   0   0   0]]\n",
      "rewardsum:  151.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   1   0   0]]\n",
      "rewardsum:  154.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [95, 30, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 30  2  0  0]]\n",
      "rewardsum:  156.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 0, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   0   1   0]]\n",
      "rewardsum:  161.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   0   0]]\n",
      "rewardsum:  163.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   0   0]]\n",
      "rewardsum:  166.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  172.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   5   0   0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 7, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   7   1   0]]\n",
      "rewardsum:  176.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  181.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  183.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   7   0   0]]\n",
      "rewardsum:  186.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   8   0   0]]\n",
      "rewardsum:  188.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  192.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   5   0   0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   5   0   0]]\n",
      "rewardsum:  198.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   5   0   0]]\n",
      "rewardsum:  201.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  4  0  0]]\n",
      "rewardsum:  204.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  208.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   6   0   0]]\n",
      "rewardsum:  210.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   5   0   0]]\n",
      "rewardsum:  213.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   8   0   0]]\n",
      "rewardsum:  215.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   7   0   0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   6   0   0]]\n",
      "rewardsum:  220.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   6   0   0]]\n",
      "rewardsum:  223.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   3   0   0]]\n",
      "rewardsum:  227.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   3   0   0]]\n",
      "rewardsum:  230.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 33, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 33  4  0  0]]\n",
      "rewardsum:  234.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 31, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 31  5  0  0]]\n",
      "rewardsum:  236.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   8   0   0]]\n",
      "rewardsum:  239.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [74, 30, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[74 30  7  0  0]]\n",
      "rewardsum:  243.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   6   0   0]]\n",
      "rewardsum:  246.0\n",
      "Time Slot: 83\n",
      "Rnd\n",
      "actionVec: [45, 73, 84, 64, 100]\n",
      "next_state: [100, 29, 6, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   6   2   0]]\n",
      "rewardsum:  249.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   6   0   0]]\n",
      "rewardsum:  253.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 8, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   8   0   0]]\n",
      "rewardsum:  254.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  12   0   0]]\n",
      "rewardsum:  257.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35 12  0  0]]\n",
      "rewardsum:  259.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  12   0   0]]\n",
      "rewardsum:  262.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  12   0   0]]\n",
      "rewardsum:  265.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   9   0   0]]\n",
      "rewardsum:  269.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   9   0   0]]\n",
      "rewardsum:  273.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   7   0   0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  280.0\n",
      "Time Slot: 94\n",
      "Rnd\n",
      "actionVec: [49, 9, 53, 64, 100]\n",
      "next_state: [96, 21, 12, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 21 12  1  0]]\n",
      "rewardsum:  282.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 20, 12, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 20 12  0  0]]\n",
      "rewardsum:  288.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [87, 23, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[87 23 12  0  0]]\n",
      "rewardsum:  291.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 27, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 27 11  0  0]]\n",
      "rewardsum:  293.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   9   0   0]]\n",
      "rewardsum:  297.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  10   0   0]]\n",
      "rewardsum:  299.0\n",
      "Episode: 34\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  5858\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [87, 2, 1, 0, 1]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[87  2  1  0  1]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 4, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   4   2   0   0]]\n",
      "rewardsum:  4.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 10, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10   2   0   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 17, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   2   0   0]]\n",
      "rewardsum:  9.0\n",
      "Time Slot: 4\n",
      "Rnd\n",
      "actionVec: [3, 14, 91, 73, 100]\n",
      "next_state: [100, 28, 0, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   0   1   0]]\n",
      "rewardsum:  10.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  13.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   0   0   0]]\n",
      "rewardsum:  16.0\n",
      "Time Slot: 7\n",
      "Rnd\n",
      "actionVec: [50, 68, 61, 1, 100]\n",
      "next_state: [99, 37, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 37  2  0  0]]\n",
      "rewardsum:  19.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 36, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 36  3  0  0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 33, 3, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 33  3  1  0]]\n",
      "rewardsum:  25.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34  5  0  0]]\n",
      "rewardsum:  27.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 4, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   4   1   0]]\n",
      "rewardsum:  33.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  37.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  41.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   0   0]]\n",
      "rewardsum:  44.0\n",
      "Time Slot: 16\n",
      "Rnd\n",
      "actionVec: [42, 67, 18, 74, 100]\n",
      "next_state: [100, 29, 0, 4, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   0   4   0]]\n",
      "rewardsum:  44.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 1, 1, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   1   1   0]]\n",
      "rewardsum:  50.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   3   0   0]]\n",
      "rewardsum:  52.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 2, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   2   1   0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [84, 32, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[84 32  3  0  0]]\n",
      "rewardsum:  59.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   3   0   0]]\n",
      "rewardsum:  61.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  65.0\n",
      "Time Slot: 23\n",
      "Rnd\n",
      "actionVec: [12, 66, 99, 96, 100]\n",
      "next_state: [100, 39, 5, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   5   1   0]]\n",
      "rewardsum:  65.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   4   0   0]]\n",
      "rewardsum:  69.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   7   0   0]]\n",
      "rewardsum:  71.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   6   0   0]]\n",
      "rewardsum:  74.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   9   0   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   8   0   0]]\n",
      "rewardsum:  79.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  10   0   0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  11   0   0]]\n",
      "rewardsum:  84.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 11, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33 11  1  0]]\n",
      "rewardsum:  87.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  11   0   0]]\n",
      "rewardsum:  90.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  10   0   0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  12   0   0]]\n",
      "rewardsum:  96.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 37, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 37 13  0  0]]\n",
      "rewardsum:  98.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  14   0   0]]\n",
      "rewardsum:  100.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  13   0   0]]\n",
      "rewardsum:  103.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 16, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  16   0   0]]\n",
      "rewardsum:  105.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  17   0   0]]\n",
      "rewardsum:  108.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 19, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  19   0   0]]\n",
      "rewardsum:  110.0\n",
      "Time Slot: 41\n",
      "Rnd\n",
      "actionVec: [76, 76, 72, 9, 100]\n",
      "next_state: [100, 29, 19, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  19   0   0]]\n",
      "rewardsum:  114.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 18, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  18   0   0]]\n",
      "rewardsum:  118.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 16, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  16   0   0]]\n",
      "rewardsum:  120.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 15, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  15   0   0]]\n",
      "rewardsum:  124.0\n",
      "Time Slot: 45\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  13   0   0]]\n",
      "rewardsum:  126.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  13   0   0]]\n",
      "rewardsum:  129.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   9   0   0]]\n",
      "rewardsum:  133.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   8   0   0]]\n",
      "rewardsum:  137.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   8   0   0]]\n",
      "rewardsum:  140.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   8   0   0]]\n",
      "rewardsum:  143.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 12, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  12   0   0]]\n",
      "rewardsum:  144.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  14   0   0]]\n",
      "rewardsum:  147.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 31, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 31 14  0  0]]\n",
      "rewardsum:  150.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  14   0   0]]\n",
      "rewardsum:  153.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  15   0   0]]\n",
      "rewardsum:  155.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 17, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  17   0   0]]\n",
      "rewardsum:  157.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  15   0   0]]\n",
      "rewardsum:  160.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  14   0   0]]\n",
      "rewardsum:  163.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  15   0   0]]\n",
      "rewardsum:  166.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [82, 37, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[82 37 15  0  0]]\n",
      "rewardsum:  169.0\n",
      "Time Slot: 61\n",
      "Rnd\n",
      "actionVec: [85, 84, 10, 30, 100]\n",
      "next_state: [68, 31, 9, 4, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[68 31  9  4  0]]\n",
      "rewardsum:  172.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 9, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   9   0   0]]\n",
      "rewardsum:  179.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  10   0   0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 64\n",
      "Rnd\n",
      "actionVec: [39, 40, 20, 1, 100]\n",
      "next_state: [98, 23, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 23  7  0  0]]\n",
      "rewardsum:  186.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   7   0   0]]\n",
      "rewardsum:  190.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   7   0   0]]\n",
      "rewardsum:  193.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 27, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 27  8  0  0]]\n",
      "rewardsum:  196.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 28, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 28  8  0  0]]\n",
      "rewardsum:  199.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   6   0   0]]\n",
      "rewardsum:  203.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   7   0   0]]\n",
      "rewardsum:  206.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  210.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  214.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   1   0   0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  220.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 2, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  2  1  0]]\n",
      "rewardsum:  223.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  226.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 32, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 32  2  0  0]]\n",
      "rewardsum:  230.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   3   0   0]]\n",
      "rewardsum:  233.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   0   0]]\n",
      "rewardsum:  236.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  242.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  245.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  248.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  251.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34  1  0  0]]\n",
      "rewardsum:  254.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  258.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  261.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   1   0   0]]\n",
      "rewardsum:  264.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   0   0]]\n",
      "rewardsum:  266.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  269.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34  1  0  0]]\n",
      "rewardsum:  273.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  276.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 7, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   7   0   0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  280.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   5   0   0]]\n",
      "rewardsum:  283.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  287.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  6  0  0]]\n",
      "rewardsum:  289.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   6   0   0]]\n",
      "rewardsum:  292.0\n",
      "Time Slot: 99\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   5   0   0]]\n",
      "rewardsum:  295.0\n",
      "Episode: 35\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  9955\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [89, 5, 3, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[89  5  3  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 9, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   9   4   0   0]]\n",
      "rewardsum:  3.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 14, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   4   0   0]]\n",
      "rewardsum:  5.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   4   0   0]]\n",
      "rewardsum:  8.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   5   0   0]]\n",
      "rewardsum:  11.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 25, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 25  7  0  0]]\n",
      "rewardsum:  13.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   8   0   0]]\n",
      "rewardsum:  16.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   7   0   0]]\n",
      "rewardsum:  18.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  10   0   0]]\n",
      "rewardsum:  21.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  11   0   0]]\n",
      "rewardsum:  23.0\n",
      "Time Slot: 10\n",
      "Rnd\n",
      "actionVec: [10, 84, 8, 97, 100]\n",
      "next_state: [67, 33, 0, 10, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[67 33  0 10  0]]\n",
      "rewardsum:  24.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 2, 5, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  2  5  0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 2, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   2   0   0]]\n",
      "rewardsum:  36.0\n",
      "Time Slot: 13\n",
      "Rnd\n",
      "actionVec: [63, 70, 64, 47, 100]\n",
      "next_state: [100, 29, 0, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   0   1   0]]\n",
      "rewardsum:  40.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   0   0   0]]\n",
      "rewardsum:  44.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   0   0   0]]\n",
      "rewardsum:  46.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   0   0]]\n",
      "rewardsum:  49.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  50.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  53.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 44, 4, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  44   4   0   0]]\n",
      "rewardsum:  54.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   5   0   0]]\n",
      "rewardsum:  57.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 38, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 38  5  0  0]]\n",
      "rewardsum:  60.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   5   0   0]]\n",
      "rewardsum:  64.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 28, 1, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 28  1  1  0]]\n",
      "rewardsum:  71.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   0   0   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   1   0   0]]\n",
      "rewardsum:  78.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  81.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  83.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   4   0   0]]\n",
      "rewardsum:  85.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [88, 40, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[88 40  4  0  0]]\n",
      "rewardsum:  88.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   5   0   0]]\n",
      "rewardsum:  90.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 4, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   4   1   0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   4   0   0]]\n",
      "rewardsum:  97.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   3   0   0]]\n",
      "rewardsum:  99.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   2   0   0]]\n",
      "rewardsum:  103.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   5   0   0]]\n",
      "rewardsum:  105.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   7   0   0]]\n",
      "rewardsum:  107.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   6   0   0]]\n",
      "rewardsum:  110.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   9   0   0]]\n",
      "rewardsum:  112.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   9   0   0]]\n",
      "rewardsum:  115.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   9   0   0]]\n",
      "rewardsum:  117.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41  10   0   0]]\n",
      "rewardsum:  119.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  10   0   0]]\n",
      "rewardsum:  122.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  11   0   0]]\n",
      "rewardsum:  125.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  12   0   0]]\n",
      "rewardsum:  127.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  12   0   0]]\n",
      "rewardsum:  130.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33 14  0  0]]\n",
      "rewardsum:  133.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  12   0   0]]\n",
      "rewardsum:  137.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  11   0   0]]\n",
      "rewardsum:  139.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 12, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  12   1   0]]\n",
      "rewardsum:  142.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  10   0   0]]\n",
      "rewardsum:  146.0\n",
      "Time Slot: 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  11   0   0]]\n",
      "rewardsum:  149.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  13   0   0]]\n",
      "rewardsum:  152.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 30, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 30 14  0  0]]\n",
      "rewardsum:  155.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  14   0   0]]\n",
      "rewardsum:  158.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [90, 33, 16, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[90 33 16  0  0]]\n",
      "rewardsum:  160.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 15, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  15   0   0]]\n",
      "rewardsum:  165.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  14   0   0]]\n",
      "rewardsum:  167.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  15   0   0]]\n",
      "rewardsum:  170.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  12   0   0]]\n",
      "rewardsum:  174.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  11   0   0]]\n",
      "rewardsum:  177.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [95, 36, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 36  8  0  0]]\n",
      "rewardsum:  181.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32 10  0  0]]\n",
      "rewardsum:  184.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   9   0   0]]\n",
      "rewardsum:  188.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 10, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  10   1   0]]\n",
      "rewardsum:  190.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  11   0   0]]\n",
      "rewardsum:  193.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  11   0   0]]\n",
      "rewardsum:  196.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  12   0   0]]\n",
      "rewardsum:  199.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  12   0   0]]\n",
      "rewardsum:  201.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  15   0   0]]\n",
      "rewardsum:  204.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 14, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  14   1   0]]\n",
      "rewardsum:  206.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 16, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  16   1   0]]\n",
      "rewardsum:  209.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 17, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  17   0   0]]\n",
      "rewardsum:  213.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  16   0   0]]\n",
      "rewardsum:  216.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  14   0   0]]\n",
      "rewardsum:  219.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 33, 16, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 33 16  0  0]]\n",
      "rewardsum:  221.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 16, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  16   0   0]]\n",
      "rewardsum:  223.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  14   0   0]]\n",
      "rewardsum:  225.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  13   0   0]]\n",
      "rewardsum:  229.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 37, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 37 14  0  0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  13   0   0]]\n",
      "rewardsum:  234.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  13   0   0]]\n",
      "rewardsum:  237.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  10   0   0]]\n",
      "rewardsum:  240.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  11   0   0]]\n",
      "rewardsum:  244.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   9   0   0]]\n",
      "rewardsum:  247.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  10   0   0]]\n",
      "rewardsum:  249.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  11   0   0]]\n",
      "rewardsum:  252.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  11   0   0]]\n",
      "rewardsum:  255.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  10   0   0]]\n",
      "rewardsum:  258.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 7, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  7  0  0]]\n",
      "rewardsum:  263.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   7   0   0]]\n",
      "rewardsum:  266.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   8   0   0]]\n",
      "rewardsum:  268.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   8   0   0]]\n",
      "rewardsum:  271.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 36, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 36  9  0  0]]\n",
      "rewardsum:  273.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   8   0   0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   9   0   0]]\n",
      "rewardsum:  279.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  9  0  0]]\n",
      "rewardsum:  283.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   8   0   0]]\n",
      "rewardsum:  285.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   8   0   0]]\n",
      "rewardsum:  287.0\n",
      "Episode: 36\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  8702\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [86, 6, 3, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[86  6  3  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 8, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   8   4   0   0]]\n",
      "rewardsum:  3.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 13, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13   4   0   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 13, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13   7   0   0]]\n",
      "rewardsum:  8.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 15, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15   7   0   0]]\n",
      "rewardsum:  12.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [91, 20, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[91 20  5  0  0]]\n",
      "rewardsum:  15.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21   6   0   0]]\n",
      "rewardsum:  19.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   5   0   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 7, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   7   0   0]]\n",
      "rewardsum:  23.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  12   0   0]]\n",
      "rewardsum:  25.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  11   0   0]]\n",
      "rewardsum:  28.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  13   0   0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 15, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  15   0   0]]\n",
      "rewardsum:  31.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 14, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  14   0   0]]\n",
      "rewardsum:  36.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 16, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  16   0   0]]\n",
      "rewardsum:  38.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  15   0   0]]\n",
      "rewardsum:  41.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  13   0   0]]\n",
      "rewardsum:  43.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 13, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31 13  0  0]]\n",
      "rewardsum:  48.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 16, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  16   0   0]]\n",
      "rewardsum:  50.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  17   0   0]]\n",
      "rewardsum:  53.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [80, 32, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[80 32 14  0  0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 14, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  14   0   0]]\n",
      "rewardsum:  60.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  13   0   0]]\n",
      "rewardsum:  63.0\n",
      "Time Slot: 23\n",
      "Rnd\n",
      "actionVec: [68, 7, 4, 21, 100]\n",
      "next_state: [95, 31, 5, 8, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 31  5  8  0]]\n",
      "rewardsum:  64.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 28, 6, 0, 0]\n",
      "Reward: 9.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 28  6  0  0]]\n",
      "rewardsum:  73.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 4, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   4   1   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   2   0   0]]\n",
      "rewardsum:  80.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   1   0   0]]\n",
      "rewardsum:  83.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   2   0   0]]\n",
      "rewardsum:  86.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   0   0]]\n",
      "rewardsum:  89.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   4   0   0]]\n",
      "rewardsum:  91.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 36, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 36  3  0  0]]\n",
      "rewardsum:  94.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  98.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   2   0   0]]\n",
      "rewardsum:  100.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   0   0   0]]\n",
      "rewardsum:  104.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   0   0   0]]\n",
      "rewardsum:  107.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  109.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   0   0   0]]\n",
      "rewardsum:  113.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  115.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  118.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [84, 35, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[84 35  2  0  0]]\n",
      "rewardsum:  121.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  124.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  131.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  132.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  135.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   3   0   0]]\n",
      "rewardsum:  139.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   0   0   0]]\n",
      "rewardsum:  144.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  146.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  149.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  151.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  154.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 39, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 39  1  0  0]]\n",
      "rewardsum:  157.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   1   0   0]]\n",
      "rewardsum:  160.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   2   0   0]]\n",
      "rewardsum:  162.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   0   0   0]]\n",
      "rewardsum:  165.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  171.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  173.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  31   4   0   0]]\n",
      "rewardsum:  177.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   4   0   0]]\n",
      "rewardsum:  180.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [84, 33, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[84 33  5  0  0]]\n",
      "rewardsum:  183.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   1   0]]\n",
      "rewardsum:  186.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   0   0]]\n",
      "rewardsum:  189.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   6   0   0]]\n",
      "rewardsum:  192.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   6   0   0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  198.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   5   0   0]]\n",
      "rewardsum:  200.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  204.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   0   0]]\n",
      "rewardsum:  209.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   0   0   0]]\n",
      "rewardsum:  213.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   0   0   0]]\n",
      "rewardsum:  215.0\n",
      "Time Slot: 72\n",
      "Rnd\n",
      "actionVec: [22, 47, 12, 99, 100]\n",
      "next_state: [99, 28, 0, 3, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 28  0  3  0]]\n",
      "rewardsum:  217.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 1, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   1   0   0]]\n",
      "rewardsum:  222.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   0   0]]\n",
      "rewardsum:  224.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  227.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  230.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   3   0   0]]\n",
      "rewardsum:  232.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 5, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   5   1   0]]\n",
      "rewardsum:  234.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 2, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34  2  0  0]]\n",
      "rewardsum:  239.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 31, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 31  0  0  0]]\n",
      "rewardsum:  243.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  245.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34  0  0  0]]\n",
      "rewardsum:  248.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  251.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  254.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   0   0]]\n",
      "rewardsum:  258.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  1  0  0]]\n",
      "rewardsum:  260.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  3  0  0]]\n",
      "rewardsum:  262.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   3   0   0]]\n",
      "rewardsum:  265.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   4   0   0]]\n",
      "rewardsum:  267.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   3   0   0]]\n",
      "rewardsum:  271.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   3   0   0]]\n",
      "rewardsum:  274.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   4   0   0]]\n",
      "rewardsum:  276.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 39, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 39  0  0  0]]\n",
      "rewardsum:  280.0\n",
      "Time Slot: 94\n",
      "Rnd\n",
      "actionVec: [29, 80, 30, 38, 100]\n",
      "next_state: [100, 41, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   0   0   0]]\n",
      "rewardsum:  282.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   2   0   0]]\n",
      "rewardsum:  284.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   2   0   0]]\n",
      "rewardsum:  288.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   4   0   0]]\n",
      "rewardsum:  290.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   1   0]]\n",
      "rewardsum:  294.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  297.0\n",
      "Episode: 37\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  6336\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [86, 7, 1, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[86  7  1  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 13, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13   3   0   0]]\n",
      "rewardsum:  2.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 16, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   2   0   0]]\n",
      "rewardsum:  5.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   2   0   0]]\n",
      "rewardsum:  9.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   0   0   0]]\n",
      "rewardsum:  12.0\n",
      "Time Slot: 5\n",
      "Rnd\n",
      "actionVec: [93, 3, 11, 50, 100]\n",
      "next_state: [45, 15, 9, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[45 15  9  2  0]]\n",
      "rewardsum:  13.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 16, 10, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16  10   0   0]]\n",
      "rewardsum:  18.0\n",
      "Time Slot: 7\n",
      "Rnd\n",
      "actionVec: [80, 22, 91, 69, 100]\n",
      "next_state: [99, 10, 16, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 10 16  1  0]]\n",
      "rewardsum:  20.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 14, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14  17   0   0]]\n",
      "rewardsum:  23.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 17, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18  17   0   0]]\n",
      "rewardsum:  25.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 21, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  21   0   0]]\n",
      "rewardsum:  25.0\n",
      "Time Slot: 11\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 21, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26  21   0   0]]\n",
      "rewardsum:  29.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 15, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  15   2   0]]\n",
      "rewardsum:  31.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  13   0   0]]\n",
      "rewardsum:  35.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  15   0   0]]\n",
      "rewardsum:  37.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 12, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  12   1   0]]\n",
      "rewardsum:  40.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 37, 12, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 37 12  1  0]]\n",
      "rewardsum:  43.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  13   0   0]]\n",
      "rewardsum:  45.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  13   0   0]]\n",
      "rewardsum:  48.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  13   0   0]]\n",
      "rewardsum:  51.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  14   0   0]]\n",
      "rewardsum:  53.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  13   0   0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  14   0   0]]\n",
      "rewardsum:  59.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 17, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  17   0   0]]\n",
      "rewardsum:  61.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  15   0   0]]\n",
      "rewardsum:  64.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  12   0   0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  11   0   0]]\n",
      "rewardsum:  72.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  14   0   0]]\n",
      "rewardsum:  74.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  12   0   0]]\n",
      "rewardsum:  77.0\n",
      "Time Slot: 29\n",
      "Rnd\n",
      "actionVec: [97, 51, 35, 43, 100]\n",
      "next_state: [96, 30, 8, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 30  8  1  0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29  10   0   0]]\n",
      "rewardsum:  86.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   8   0   0]]\n",
      "rewardsum:  90.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 27, 4, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 27  4  1  0]]\n",
      "rewardsum:  94.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 25, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 25  6  0  0]]\n",
      "rewardsum:  97.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   7   0   0]]\n",
      "rewardsum:  100.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 6, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   6   1   0]]\n",
      "rewardsum:  103.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 35, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 35  5  0  0]]\n",
      "rewardsum:  106.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   5   0   0]]\n",
      "rewardsum:  109.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  113.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   5   0   0]]\n",
      "rewardsum:  116.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   6   0   0]]\n",
      "rewardsum:  118.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   6   0   0]]\n",
      "rewardsum:  121.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   7   0   0]]\n",
      "rewardsum:  124.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   8   0   0]]\n",
      "rewardsum:  127.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   7   0   0]]\n",
      "rewardsum:  130.0\n",
      "Time Slot: 45\n",
      "Rnd\n",
      "actionVec: [51, 34, 77, 20, 100]\n",
      "next_state: [100, 34, 10, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  10   1   0]]\n",
      "rewardsum:  132.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 9, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   9   1   0]]\n",
      "rewardsum:  135.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   9   0   0]]\n",
      "rewardsum:  139.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   9   0   0]]\n",
      "rewardsum:  143.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 30, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 30  7  0  0]]\n",
      "rewardsum:  147.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   8   0   0]]\n",
      "rewardsum:  149.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  10   0   0]]\n",
      "rewardsum:  152.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  11   0   0]]\n",
      "rewardsum:  155.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 10, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  10   1   0]]\n",
      "rewardsum:  158.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  12   0   0]]\n",
      "rewardsum:  160.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33 10  0  0]]\n",
      "rewardsum:  164.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [86, 33, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[86 33 11  0  0]]\n",
      "rewardsum:  167.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  10   0   0]]\n",
      "rewardsum:  171.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  10   0   0]]\n",
      "rewardsum:  173.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   9   0   0]]\n",
      "rewardsum:  176.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   8   0   0]]\n",
      "rewardsum:  179.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  10   0   0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 35, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 35  8  0  0]]\n",
      "rewardsum:  186.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 30, 4, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 30  4  0  0]]\n",
      "rewardsum:  192.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  30   1   0   0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   3   0   0]]\n",
      "rewardsum:  197.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   0   0   0]]\n",
      "rewardsum:  202.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   0   0   0]]\n",
      "rewardsum:  205.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  206.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   3   0   0]]\n",
      "rewardsum:  209.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   0   0]]\n",
      "rewardsum:  213.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 37, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 37  0  0  0]]\n",
      "rewardsum:  216.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 36, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 36  0  0  0]]\n",
      "rewardsum:  219.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   0   0   0]]\n",
      "rewardsum:  222.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  1  0  0]]\n",
      "rewardsum:  225.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   0   0   0]]\n",
      "rewardsum:  229.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   0   0   0]]\n",
      "rewardsum:  234.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  236.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   6   0   0]]\n",
      "rewardsum:  239.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   7   0   0]]\n",
      "rewardsum:  242.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  10   0   0]]\n",
      "rewardsum:  244.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   8   0   0]]\n",
      "rewardsum:  247.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   9   0   0]]\n",
      "rewardsum:  250.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   8   0   0]]\n",
      "rewardsum:  253.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   8   0   0]]\n",
      "rewardsum:  256.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [69, 36, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[69 36  8  0  0]]\n",
      "rewardsum:  259.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   7   0   0]]\n",
      "rewardsum:  263.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 6, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   6   1   0]]\n",
      "rewardsum:  266.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 30, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 30  6  0  0]]\n",
      "rewardsum:  270.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 5, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   5   1   0]]\n",
      "rewardsum:  273.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  276.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   7   0   0]]\n",
      "rewardsum:  278.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34  5  0  0]]\n",
      "rewardsum:  282.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  285.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  6  0  0]]\n",
      "rewardsum:  288.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   7   0   0]]\n",
      "rewardsum:  291.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   6   0   0]]\n",
      "rewardsum:  294.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   7   0   0]]\n",
      "rewardsum:  297.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   7   0   0]]\n",
      "rewardsum:  300.0\n",
      "Episode: 38\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  7943\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [88, 4, 1, 0, 1]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[88  4  1  0  1]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 5, 2, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   5   2   0   0]]\n",
      "rewardsum:  5.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 6, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   6   2   0   0]]\n",
      "rewardsum:  9.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 8, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   8   2   0   0]]\n",
      "rewardsum:  12.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 12, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12   1   0   0]]\n",
      "rewardsum:  16.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 13, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 13  4  0  0]]\n",
      "rewardsum:  18.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 19, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   4   0   0]]\n",
      "rewardsum:  20.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   4   0   0]]\n",
      "rewardsum:  23.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   5   0   0]]\n",
      "rewardsum:  25.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   6   0   0]]\n",
      "rewardsum:  27.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   5   0   0]]\n",
      "rewardsum:  31.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 8, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   8   0   0]]\n",
      "rewardsum:  32.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   9   0   0]]\n",
      "rewardsum:  35.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   8   0   0]]\n",
      "rewardsum:  38.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 7, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   7   1   0]]\n",
      "rewardsum:  41.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 36, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 36  7  0  0]]\n",
      "rewardsum:  45.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   5   0   0]]\n",
      "rewardsum:  49.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   5   0   0]]\n",
      "rewardsum:  52.0\n",
      "Time Slot: 18\n",
      "Rnd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [14, 52, 20, 9, 100]\n",
      "next_state: [100, 32, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   0   0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 19\n",
      "Rnd\n",
      "actionVec: [57, 15, 81, 63, 100]\n",
      "next_state: [100, 28, 5, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   5   2   0]]\n",
      "rewardsum:  58.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 3, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   3   0   0]]\n",
      "rewardsum:  64.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 3, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   3   0   0]]\n",
      "rewardsum:  65.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   4   0   0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   3   0   0]]\n",
      "rewardsum:  72.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  74.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   3   0   0]]\n",
      "rewardsum:  77.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 39, 0, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 39  0  1  0]]\n",
      "rewardsum:  79.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   0   0   0]]\n",
      "rewardsum:  83.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   1   0   0]]\n",
      "rewardsum:  85.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   4   0   0]]\n",
      "rewardsum:  87.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [82, 41, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[82 41  5  0  0]]\n",
      "rewardsum:  89.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   7   0   0]]\n",
      "rewardsum:  91.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   5   0   0]]\n",
      "rewardsum:  95.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   5   0   0]]\n",
      "rewardsum:  98.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   6   0   0]]\n",
      "rewardsum:  100.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   5   0   0]]\n",
      "rewardsum:  103.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  108.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   2   0   0]]\n",
      "rewardsum:  110.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   3   0   0]]\n",
      "rewardsum:  113.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  116.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   0   0]]\n",
      "rewardsum:  120.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   1   0]]\n",
      "rewardsum:  123.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   0   0]]\n",
      "rewardsum:  126.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   3   0   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 0, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   0   1   0]]\n",
      "rewardsum:  131.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [81, 38, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[81 38  2  0  0]]\n",
      "rewardsum:  134.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   3   0   0]]\n",
      "rewardsum:  137.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 36, 3, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 36  3  1  0]]\n",
      "rewardsum:  140.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   0   0]]\n",
      "rewardsum:  144.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  146.0\n",
      "Time Slot: 50\n",
      "Rnd\n",
      "actionVec: [37, 88, 91, 84, 100]\n",
      "next_state: [100, 36, 2, 3, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   3   0]]\n",
      "rewardsum:  147.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  152.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  154.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   6   0   0]]\n",
      "rewardsum:  156.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   9   0   0]]\n",
      "rewardsum:  159.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   7   0   0]]\n",
      "rewardsum:  163.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   8   0   0]]\n",
      "rewardsum:  165.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   7   0   0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   0   0]]\n",
      "rewardsum:  173.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 2, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   2   0   0]]\n",
      "rewardsum:  178.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   0   0   0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   1   0   0]]\n",
      "rewardsum:  185.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   3   0   0]]\n",
      "rewardsum:  187.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   6   0   0]]\n",
      "rewardsum:  189.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 31, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 31  7  0  0]]\n",
      "rewardsum:  191.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 5, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   5   0   0]]\n",
      "rewardsum:  196.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   8   0   0]]\n",
      "rewardsum:  198.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 32, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 32  8  0  0]]\n",
      "rewardsum:  201.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  33   8   0   0]]\n",
      "rewardsum:  204.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   8   0   0]]\n",
      "rewardsum:  207.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   6   0   0]]\n",
      "rewardsum:  210.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 6, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   6   1   0]]\n",
      "rewardsum:  213.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   7   0   0]]\n",
      "rewardsum:  216.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   8   0   0]]\n",
      "rewardsum:  219.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   9   0   0]]\n",
      "rewardsum:  221.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  226.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 7, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   7   0   0]]\n",
      "rewardsum:  227.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  10   0   0]]\n",
      "rewardsum:  229.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  11   0   0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  10   0   0]]\n",
      "rewardsum:  234.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  10   0   0]]\n",
      "rewardsum:  237.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   9   0   0]]\n",
      "rewardsum:  240.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   8   0   0]]\n",
      "rewardsum:  242.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  12   0   0]]\n",
      "rewardsum:  245.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  11   0   0]]\n",
      "rewardsum:  248.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  10   0   0]]\n",
      "rewardsum:  252.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  10   0   0]]\n",
      "rewardsum:  254.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 31, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 31 11  0  0]]\n",
      "rewardsum:  257.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  11   0   0]]\n",
      "rewardsum:  260.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  10   0   0]]\n",
      "rewardsum:  264.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  10   0   0]]\n",
      "rewardsum:  267.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   8   0   0]]\n",
      "rewardsum:  271.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 7, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   7   1   0]]\n",
      "rewardsum:  274.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   0   0]]\n",
      "rewardsum:  279.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   1   0]]\n",
      "rewardsum:  281.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  285.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   0   0]]\n",
      "rewardsum:  289.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   3   0   0]]\n",
      "rewardsum:  292.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  295.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  298.0\n",
      "Episode: 39\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  9006\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [83, 6, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[83  6  0  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 11, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 52, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  52   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 54, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  54   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 55, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  55   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [95, 56, 1, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 56  1  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 57, 3, 0, 1]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  57   3   0   1]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 49, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 49  5  0  0]]\n",
      "rewardsum:  3.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 46, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 46  8  0  0]]\n",
      "rewardsum:  5.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 43, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 43  9  0  0]]\n",
      "rewardsum:  7.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  10   0   0]]\n",
      "rewardsum:  11.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 9, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   9   1   0]]\n",
      "rewardsum:  14.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  10   0   0]]\n",
      "rewardsum:  16.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   8   0   0]]\n",
      "rewardsum:  20.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   8   0   0]]\n",
      "rewardsum:  23.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [80, 37, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[80 37  8  0  0]]\n",
      "rewardsum:  25.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   9   0   0]]\n",
      "rewardsum:  27.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  10   0   0]]\n",
      "rewardsum:  29.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   9   0   0]]\n",
      "rewardsum:  33.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   8   0   0]]\n",
      "rewardsum:  37.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   6   0   0]]\n",
      "rewardsum:  40.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   7   0   0]]\n",
      "rewardsum:  43.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   7   0   0]]\n",
      "rewardsum:  46.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 8, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   8   0   0]]\n",
      "rewardsum:  47.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   6   0   0]]\n",
      "rewardsum:  51.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   6   0   0]]\n",
      "rewardsum:  53.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 38, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 38  6  0  0]]\n",
      "rewardsum:  57.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   5   0   0]]\n",
      "rewardsum:  60.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   4   0   0]]\n",
      "rewardsum:  64.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   3   0   0]]\n",
      "rewardsum:  67.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  70.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  4  0  0]]\n",
      "rewardsum:  73.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   6   0   0]]\n",
      "rewardsum:  78.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   6   0   0]]\n",
      "rewardsum:  80.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   6   0   0]]\n",
      "rewardsum:  84.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   3   0   0]]\n",
      "rewardsum:  88.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   5   0   0]]\n",
      "rewardsum:  90.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  94.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  97.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   5   0   0]]\n",
      "rewardsum:  99.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  103.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 6, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   6   0   0]]\n",
      "rewardsum:  104.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 36, 3, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 36  3  1  0]]\n",
      "rewardsum:  108.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   4   0   0]]\n",
      "rewardsum:  111.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   0   0]]\n",
      "rewardsum:  115.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 1, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   1   0   0]]\n",
      "rewardsum:  120.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   3   0   0]]\n",
      "rewardsum:  122.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   3   0   0]]\n",
      "rewardsum:  125.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   1   0   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 32, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 32  1  0  0]]\n",
      "rewardsum:  131.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [77, 32, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[77 32  4  0  0]]\n",
      "rewardsum:  133.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  137.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   6   0   0]]\n",
      "rewardsum:  139.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  9  0  0]]\n",
      "rewardsum:  141.0\n",
      "Time Slot: 60\n",
      "Rnd\n",
      "actionVec: [27, 34, 10, 37, 100]\n",
      "next_state: [100, 32, 3, 7, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   3   7   0]]\n",
      "rewardsum:  142.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 5, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   5   0   0]]\n",
      "rewardsum:  150.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   5   0   0]]\n",
      "rewardsum:  153.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 30, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 30  4  0  0]]\n",
      "rewardsum:  156.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   7   0   0]]\n",
      "rewardsum:  158.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   8   0   0]]\n",
      "rewardsum:  161.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  10   0   0]]\n",
      "rewardsum:  163.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 8, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   8   0   0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 26, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 26  9  0  0]]\n",
      "rewardsum:  171.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 27, 5, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 27  5  0  0]]\n",
      "rewardsum:  176.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 30, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 30  5  0  0]]\n",
      "rewardsum:  178.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   4   0   0]]\n",
      "rewardsum:  181.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 30, 3, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 30  3  1  0]]\n",
      "rewardsum:  185.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  188.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 6, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   6   0   0]]\n",
      "rewardsum:  189.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  36   4   0   0]]\n",
      "rewardsum:  193.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 38, 6, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 38  6  0  0]]\n",
      "rewardsum:  194.0\n",
      "Time Slot: 77\n",
      "Rnd\n",
      "actionVec: [84, 19, 10, 40, 100]\n",
      "next_state: [99, 35, 7, 4, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  7  4  0]]\n",
      "rewardsum:  196.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 7, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   7   0   0]]\n",
      "rewardsum:  202.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   7   0   0]]\n",
      "rewardsum:  205.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  6  0  0]]\n",
      "rewardsum:  208.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   9   0   0]]\n",
      "rewardsum:  211.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   9   0   0]]\n",
      "rewardsum:  214.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   8   0   0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   5   0   0]]\n",
      "rewardsum:  222.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   7   0   0]]\n",
      "rewardsum:  224.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   6   0   0]]\n",
      "rewardsum:  226.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   6   0   0]]\n",
      "rewardsum:  228.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   9   0   0]]\n",
      "rewardsum:  230.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  11   0   0]]\n",
      "rewardsum:  233.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   9   0   0]]\n",
      "rewardsum:  236.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   7   0   0]]\n",
      "rewardsum:  240.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   7   0   0]]\n",
      "rewardsum:  242.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   6   0   0]]\n",
      "rewardsum:  246.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 3, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  3  0  0]]\n",
      "rewardsum:  251.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  253.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [77, 34, 1, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[77 34  1  1  0]]\n",
      "rewardsum:  257.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   0   0]]\n",
      "rewardsum:  260.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   2   0   0]]\n",
      "rewardsum:  263.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  266.0\n",
      "Episode: 40\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  7681\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [88, 4, 2, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[88  4  2  1  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 8, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   8   2   0   0]]\n",
      "rewardsum:  3.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 16, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   0   0   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 19, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   2   0   0]]\n",
      "rewardsum:  9.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   5   0   0]]\n",
      "rewardsum:  11.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 28, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 28  6  0  0]]\n",
      "rewardsum:  13.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   6   0   0]]\n",
      "rewardsum:  15.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   5   0   0]]\n",
      "rewardsum:  19.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   5   0   0]]\n",
      "rewardsum:  21.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   3   0   0]]\n",
      "rewardsum:  25.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   4   0   0]]\n",
      "rewardsum:  27.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  31.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   4   0   0]]\n",
      "rewardsum:  33.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  37.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   2   0   0]]\n",
      "rewardsum:  40.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [68, 35, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[68 35  4  0  0]]\n",
      "rewardsum:  42.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34  2  0  0]]\n",
      "rewardsum:  46.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 33, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 33  2  0  0]]\n",
      "rewardsum:  49.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 1, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   1   0   0]]\n",
      "rewardsum:  54.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   0   0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   0   0   0]]\n",
      "rewardsum:  59.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   0   0   0]]\n",
      "rewardsum:  62.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   0   0   0]]\n",
      "rewardsum:  66.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   1   0]]\n",
      "rewardsum:  67.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   0   0]]\n",
      "rewardsum:  70.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   1   0   0]]\n",
      "rewardsum:  72.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   1   0   0]]\n",
      "rewardsum:  75.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 46, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  46   0   0   0]]\n",
      "rewardsum:  77.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   2   0   0]]\n",
      "rewardsum:  81.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 0, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  39   0   1   0]]\n",
      "rewardsum:  83.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   0   0]]\n",
      "rewardsum:  87.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   0   0   0]]\n",
      "rewardsum:  90.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   0   0   0]]\n",
      "rewardsum:  92.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   2   0   0]]\n",
      "rewardsum:  94.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  98.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   1   0   0]]\n",
      "rewardsum:  101.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  103.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  107.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   5   0   0]]\n",
      "rewardsum:  109.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  112.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [92, 33, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[92 33  5  0  0]]\n",
      "rewardsum:  115.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  118.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   5   0   0]]\n",
      "rewardsum:  121.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 35, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 35  7  0  0]]\n",
      "rewardsum:  124.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 31, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 31  5  0  0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   0   0]]\n",
      "rewardsum:  131.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   3   0   0]]\n",
      "rewardsum:  135.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   1   0   0]]\n",
      "rewardsum:  138.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   0   0]]\n",
      "rewardsum:  141.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  144.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   4   0   0]]\n",
      "rewardsum:  146.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 39, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 39  2  0  0]]\n",
      "rewardsum:  149.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  153.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  157.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  160.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  2  0  0]]\n",
      "rewardsum:  163.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   0   0   0]]\n",
      "rewardsum:  167.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   0   0]]\n",
      "rewardsum:  169.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  173.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  179.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  0  0  0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  185.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  188.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 1, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   1   1   0]]\n",
      "rewardsum:  191.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   0   0   0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   3   0   0]]\n",
      "rewardsum:  197.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  3  0  0]]\n",
      "rewardsum:  199.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  203.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  206.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 36, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 36  1  0  0]]\n",
      "rewardsum:  209.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  213.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   3   0   0]]\n",
      "rewardsum:  216.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   1   0]]\n",
      "rewardsum:  217.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   5   0   0]]\n",
      "rewardsum:  220.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   5   0   0]]\n",
      "rewardsum:  223.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  228.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   0   0   0]]\n",
      "rewardsum:  233.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  236.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   1   0   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   2   0   0]]\n",
      "rewardsum:  241.0\n",
      "Time Slot: 82\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 43, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43   3   0   0]]\n",
      "rewardsum:  243.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   5   0   0]]\n",
      "rewardsum:  245.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 41, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 41  5  0  0]]\n",
      "rewardsum:  247.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   6   0   0]]\n",
      "rewardsum:  251.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 6, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   6   1   0]]\n",
      "rewardsum:  253.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   8   0   0]]\n",
      "rewardsum:  255.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 6, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   6   0   0]]\n",
      "rewardsum:  260.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  263.0\n",
      "Time Slot: 90\n",
      "Rnd\n",
      "actionVec: [43, 42, 60, 82, 100]\n",
      "next_state: [100, 32, 9, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   9   2   0]]\n",
      "rewardsum:  264.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 9, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   9   0   0]]\n",
      "rewardsum:  269.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   9   0   0]]\n",
      "rewardsum:  272.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  11   0   0]]\n",
      "rewardsum:  274.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  11   0   0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 9, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   9   1   0]]\n",
      "rewardsum:  280.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  8  0  0]]\n",
      "rewardsum:  284.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   9   0   0]]\n",
      "rewardsum:  286.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   8   0   0]]\n",
      "rewardsum:  290.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   8   0   0]]\n",
      "rewardsum:  292.0\n",
      "Episode: 41\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  6274\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [83, 3, 3, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[83  3  3  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 8, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   8   4   0   0]]\n",
      "rewardsum:  2.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 14, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   5   0   0]]\n",
      "rewardsum:  4.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   6   0   0]]\n",
      "rewardsum:  7.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   8   0   0]]\n",
      "rewardsum:  10.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [90, 22, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[90 22  8  0  0]]\n",
      "rewardsum:  13.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   9   0   0]]\n",
      "rewardsum:  16.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  10   0   0]]\n",
      "rewardsum:  18.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 12, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  12   1   0]]\n",
      "rewardsum:  19.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 14, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  14   0   0]]\n",
      "rewardsum:  23.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  12   0   0]]\n",
      "rewardsum:  26.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  11   0   0]]\n",
      "rewardsum:  29.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  11   0   0]]\n",
      "rewardsum:  32.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  10   0   0]]\n",
      "rewardsum:  35.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   9   0   0]]\n",
      "rewardsum:  38.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   9   0   0]]\n",
      "rewardsum:  42.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  10   0   0]]\n",
      "rewardsum:  44.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   8   0   0]]\n",
      "rewardsum:  48.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 6, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   6   1   0]]\n",
      "rewardsum:  51.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   7   0   0]]\n",
      "rewardsum:  54.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   5   0   0]]\n",
      "rewardsum:  58.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  62.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  65.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  67.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 32, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 32  8  0  0]]\n",
      "rewardsum:  69.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [74, 34, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[74 34  8  0  0]]\n",
      "rewardsum:  72.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 35, 11, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 35 11  0  0]]\n",
      "rewardsum:  73.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  10   0   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  10   0   0]]\n",
      "rewardsum:  79.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  10   0   0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   9   0   0]]\n",
      "rewardsum:  85.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  10   0   0]]\n",
      "rewardsum:  88.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  10   0   0]]\n",
      "rewardsum:  91.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   9   0   0]]\n",
      "rewardsum:  95.0\n",
      "Time Slot: 34\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   8   0   0]]\n",
      "rewardsum:  98.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   5   0   0]]\n",
      "rewardsum:  102.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   7   0   0]]\n",
      "rewardsum:  104.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   8   0   0]]\n",
      "rewardsum:  107.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   7   0   0]]\n",
      "rewardsum:  111.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   8   0   0]]\n",
      "rewardsum:  113.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   8   0   0]]\n",
      "rewardsum:  115.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   7   0   0]]\n",
      "rewardsum:  119.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   7   0   0]]\n",
      "rewardsum:  122.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 37, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 37  7  0  0]]\n",
      "rewardsum:  124.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34  9  0  0]]\n",
      "rewardsum:  126.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   9   0   0]]\n",
      "rewardsum:  130.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  11   0   0]]\n",
      "rewardsum:  132.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  8  0  0]]\n",
      "rewardsum:  135.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   9   0   0]]\n",
      "rewardsum:  139.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  12   0   0]]\n",
      "rewardsum:  141.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 31, 10, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 31 10  1  0]]\n",
      "rewardsum:  145.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 31, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 31  9  0  0]]\n",
      "rewardsum:  148.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  10   0   0]]\n",
      "rewardsum:  150.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  11   0   0]]\n",
      "rewardsum:  152.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  10   0   0]]\n",
      "rewardsum:  156.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  11   0   0]]\n",
      "rewardsum:  158.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  10   0   0]]\n",
      "rewardsum:  162.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  11   0   0]]\n",
      "rewardsum:  165.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  10   0   0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  10   0   0]]\n",
      "rewardsum:  171.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   9   0   0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   7   0   0]]\n",
      "rewardsum:  178.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 30, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 30 11  0  0]]\n",
      "rewardsum:  181.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  11   0   0]]\n",
      "rewardsum:  184.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  11   0   0]]\n",
      "rewardsum:  186.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 11, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  11   1   0]]\n",
      "rewardsum:  189.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 34, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 34 12  0  0]]\n",
      "rewardsum:  192.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  11   0   0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  14   0   0]]\n",
      "rewardsum:  198.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  13   0   0]]\n",
      "rewardsum:  201.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  14   0   0]]\n",
      "rewardsum:  203.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  14   0   0]]\n",
      "rewardsum:  205.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 38, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 38 13  0  0]]\n",
      "rewardsum:  209.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  14   0   0]]\n",
      "rewardsum:  211.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 43, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43  13   0   0]]\n",
      "rewardsum:  213.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 45, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  45  11   0   0]]\n",
      "rewardsum:  215.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41  11   0   0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 44, 11, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  44  11   1   0]]\n",
      "rewardsum:  220.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 43, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43  10   0   0]]\n",
      "rewardsum:  224.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  12   0   0]]\n",
      "rewardsum:  226.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 39, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 39 10  0  0]]\n",
      "rewardsum:  229.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  14   0   0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 36, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 36 11  0  0]]\n",
      "rewardsum:  235.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  14   0   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 9, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   9   0   0]]\n",
      "rewardsum:  243.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   8   0   0]]\n",
      "rewardsum:  247.0\n",
      "Time Slot: 86\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   8   0   0]]\n",
      "rewardsum:  250.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   8   0   0]]\n",
      "rewardsum:  253.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 30, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 30  8  0  0]]\n",
      "rewardsum:  257.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 31, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 31  8  0  0]]\n",
      "rewardsum:  260.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  7  0  0]]\n",
      "rewardsum:  262.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   6   0   0]]\n",
      "rewardsum:  265.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   9   0   0]]\n",
      "rewardsum:  267.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   9   0   0]]\n",
      "rewardsum:  270.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   9   0   0]]\n",
      "rewardsum:  273.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   7   0   0]]\n",
      "rewardsum:  276.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 37, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 37  6  0  0]]\n",
      "rewardsum:  279.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   5   0   0]]\n",
      "rewardsum:  282.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 5, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   5   0   0]]\n",
      "rewardsum:  287.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   7   0   0]]\n",
      "rewardsum:  289.0\n",
      "Episode: 42\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  5646\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [81, 4, 1, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[81  4  1  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 9, 2, 0, 1]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   9   2   0   1]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 13, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13   3   0   0]]\n",
      "rewardsum:  4.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 16, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  16   1   0   0]]\n",
      "rewardsum:  8.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   0   0   0]]\n",
      "rewardsum:  12.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 24, 3, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 24  3  0  0]]\n",
      "rewardsum:  13.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   3   0   0]]\n",
      "rewardsum:  17.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   2   0   0]]\n",
      "rewardsum:  20.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  25.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [83, 30, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[83 30  1  0  0]]\n",
      "rewardsum:  29.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  31.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  0  0  0]]\n",
      "rewardsum:  35.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   3   0   0]]\n",
      "rewardsum:  38.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   1   0   0]]\n",
      "rewardsum:  42.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   0   0   0]]\n",
      "rewardsum:  46.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 28, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 28  0  0  0]]\n",
      "rewardsum:  49.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   2   0   0]]\n",
      "rewardsum:  51.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  54.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   0   0]]\n",
      "rewardsum:  58.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  60.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  63.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  65.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   1   0   0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 43, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43   1   0   0]]\n",
      "rewardsum:  70.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [82, 40, 1, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[82 40  1  1  0]]\n",
      "rewardsum:  73.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   1   0   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   0   0   0]]\n",
      "rewardsum:  80.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   3   0   0]]\n",
      "rewardsum:  84.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   5   0   0]]\n",
      "rewardsum:  87.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  91.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   0   0   0]]\n",
      "rewardsum:  94.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  97.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 1, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   1   1   0]]\n",
      "rewardsum:  100.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 0, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   1   0]]\n",
      "rewardsum:  103.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  2  0  0]]\n",
      "rewardsum:  106.0\n",
      "Time Slot: 37\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   1   0]]\n",
      "rewardsum:  109.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  112.0\n",
      "Time Slot: 39\n",
      "Rnd\n",
      "actionVec: [82, 93, 92, 52, 100]\n",
      "next_state: [100, 31, 3, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   3   1   0]]\n",
      "rewardsum:  115.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   5   0   0]]\n",
      "rewardsum:  118.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   6   0   0]]\n",
      "rewardsum:  121.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   7   0   0]]\n",
      "rewardsum:  124.0\n",
      "Time Slot: 43\n",
      "Rnd\n",
      "actionVec: [51, 43, 22, 16, 100]\n",
      "next_state: [100, 25, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   4   0   0]]\n",
      "rewardsum:  129.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   4   0   0]]\n",
      "rewardsum:  132.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   6   0   0]]\n",
      "rewardsum:  135.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   5   0   0]]\n",
      "rewardsum:  139.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 3, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   3   1   0]]\n",
      "rewardsum:  142.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   3   0   0]]\n",
      "rewardsum:  145.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  148.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   4   0   0]]\n",
      "rewardsum:  150.0\n",
      "Time Slot: 51\n",
      "Rnd\n",
      "actionVec: [90, 65, 40, 47, 100]\n",
      "next_state: [100, 36, 1, 2, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   2   0]]\n",
      "rewardsum:  153.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 31, 0, 0, 0]\n",
      "Reward: 7.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 31  0  0  0]]\n",
      "rewardsum:  160.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 5, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   5   0   0]]\n",
      "rewardsum:  161.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  163.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   8   0   0]]\n",
      "rewardsum:  166.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  6  0  0]]\n",
      "rewardsum:  169.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   8   0   0]]\n",
      "rewardsum:  172.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   6   0   0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   7   0   0]]\n",
      "rewardsum:  178.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   6   0   0]]\n",
      "rewardsum:  180.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   7   0   0]]\n",
      "rewardsum:  184.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   8   0   0]]\n",
      "rewardsum:  186.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   8   0   0]]\n",
      "rewardsum:  188.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   6   0   0]]\n",
      "rewardsum:  192.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   5   0   0]]\n",
      "rewardsum:  196.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   7   0   0]]\n",
      "rewardsum:  198.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   7   0   0]]\n",
      "rewardsum:  201.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   8   0   0]]\n",
      "rewardsum:  203.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  10   0   0]]\n",
      "rewardsum:  205.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  10   0   0]]\n",
      "rewardsum:  208.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   8   0   0]]\n",
      "rewardsum:  211.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34  9  0  0]]\n",
      "rewardsum:  215.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   9   0   0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   8   0   0]]\n",
      "rewardsum:  222.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   8   0   0]]\n",
      "rewardsum:  225.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   8   0   0]]\n",
      "rewardsum:  228.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   9   0   0]]\n",
      "rewardsum:  230.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  10   0   0]]\n",
      "rewardsum:  232.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   9   0   0]]\n",
      "rewardsum:  235.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   9   0   0]]\n",
      "rewardsum:  239.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [50, 34, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[50 34 10  0  0]]\n",
      "rewardsum:  241.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34 11  0  0]]\n",
      "rewardsum:  244.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 11, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  11   1   0]]\n",
      "rewardsum:  247.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  11   0   0]]\n",
      "rewardsum:  250.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  10   0   0]]\n",
      "rewardsum:  254.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  11   0   0]]\n",
      "rewardsum:  256.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  10   0   0]]\n",
      "rewardsum:  259.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  11   0   0]]\n",
      "rewardsum:  262.0\n",
      "Time Slot: 89\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  10   0   0]]\n",
      "rewardsum:  265.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  11   0   0]]\n",
      "rewardsum:  267.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  12   0   0]]\n",
      "rewardsum:  269.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  11   0   0]]\n",
      "rewardsum:  272.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 36, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 36 14  0  0]]\n",
      "rewardsum:  274.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  15   0   0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 37, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 37 15  0  0]]\n",
      "rewardsum:  279.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  14   0   0]]\n",
      "rewardsum:  282.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  13   0   0]]\n",
      "rewardsum:  286.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38  12   0   0]]\n",
      "rewardsum:  289.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 37, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 37 12  0  0]]\n",
      "rewardsum:  292.0\n",
      "Episode: 43\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  7641\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [80, 7, 1, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[80  7  1  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 14, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  14   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 17, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34  0  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 48, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  48   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 56, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  56   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 57, 0, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  57   0   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 57, 1, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  57   1   0   0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 55, 5, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  55   5   0   0]]\n",
      "rewardsum:  1.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 51, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  51   6   0   0]]\n",
      "rewardsum:  3.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 47, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  47   7   0   0]]\n",
      "rewardsum:  5.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 44, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  44   9   0   0]]\n",
      "rewardsum:  7.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [86, 42, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[86 42 10  0  0]]\n",
      "rewardsum:  9.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42  11   0   0]]\n",
      "rewardsum:  11.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  13   0   0]]\n",
      "rewardsum:  14.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  12   0   0]]\n",
      "rewardsum:  17.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 40, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 40 12  0  0]]\n",
      "rewardsum:  19.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 10, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34 10  0  0]]\n",
      "rewardsum:  24.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  11   0   0]]\n",
      "rewardsum:  27.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 32, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 32 11  0  0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 10, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  10   0   0]]\n",
      "rewardsum:  35.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 26, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 26 11  0  0]]\n",
      "rewardsum:  37.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  11   0   0]]\n",
      "rewardsum:  40.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  12   0   0]]\n",
      "rewardsum:  43.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  12   0   0]]\n",
      "rewardsum:  45.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 33, 12, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 33 12  0  0]]\n",
      "rewardsum:  49.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  10   0   0]]\n",
      "rewardsum:  52.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 32, 8, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 32  8  0  0]]\n",
      "rewardsum:  57.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   8   0   0]]\n",
      "rewardsum:  60.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   9   0   0]]\n",
      "rewardsum:  63.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 30, 5, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 30  5  0  0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   5   0   0]]\n",
      "rewardsum:  71.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   7   0   0]]\n",
      "rewardsum:  74.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   4   0   0]]\n",
      "rewardsum:  77.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   6   0   0]]\n",
      "rewardsum:  79.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  83.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   5   0   0]]\n",
      "rewardsum:  86.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 5, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   5   1   0]]\n",
      "rewardsum:  89.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 4, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  30   4   1   0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 29, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 29  3  0  0]]\n",
      "rewardsum:  97.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   6   0   0]]\n",
      "rewardsum:  99.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 9, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   9   1   0]]\n",
      "rewardsum:  101.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 7, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   7   1   0]]\n",
      "rewardsum:  105.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 32, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 32  6  0  0]]\n",
      "rewardsum:  108.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 8, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   8   1   0]]\n",
      "rewardsum:  111.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 10, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  10   1   0]]\n",
      "rewardsum:  114.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  11   0   0]]\n",
      "rewardsum:  117.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [95, 29, 7, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 29  7  0  0]]\n",
      "rewardsum:  122.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   8   0   0]]\n",
      "rewardsum:  125.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   6   0   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   6   0   0]]\n",
      "rewardsum:  132.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   6   0   0]]\n",
      "rewardsum:  135.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   0   0]]\n",
      "rewardsum:  139.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 34, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 34  5  0  0]]\n",
      "rewardsum:  141.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   6   0   0]]\n",
      "rewardsum:  145.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   5   0   0]]\n",
      "rewardsum:  147.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 35, 5, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 35  5  1  0]]\n",
      "rewardsum:  150.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  155.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   1   0   0]]\n",
      "rewardsum:  159.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   4   0   0]]\n",
      "rewardsum:  161.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 29, 1, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 29  1  0  0]]\n",
      "rewardsum:  166.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   1   0   0]]\n",
      "rewardsum:  168.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  170.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [91, 36, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[91 36  4  0  0]]\n",
      "rewardsum:  172.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 36, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 36  5  0  0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   4   0   0]]\n",
      "rewardsum:  178.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  184.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 5, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   5   1   0]]\n",
      "rewardsum:  186.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   4   0   0]]\n",
      "rewardsum:  191.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 5, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   5   0   0]]\n",
      "rewardsum:  192.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   5   0   0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  199.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  202.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   3   0   0]]\n",
      "rewardsum:  204.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  207.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 36, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 36  0  0  0]]\n",
      "rewardsum:  211.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  214.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   0   0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 36, 1, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 36  1  0  0]]\n",
      "rewardsum:  219.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   0   0   0]]\n",
      "rewardsum:  223.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   0   0   0]]\n",
      "rewardsum:  226.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  229.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   0   0]]\n",
      "rewardsum:  234.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  3  0  0]]\n",
      "rewardsum:  237.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  239.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 36, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 36  2  0  0]]\n",
      "rewardsum:  243.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  247.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  3  0  0]]\n",
      "rewardsum:  250.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   0   0]]\n",
      "rewardsum:  253.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   3   0   0]]\n",
      "rewardsum:  256.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 30, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[99 30  3  0  0]]\n",
      "rewardsum:  259.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  262.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  265.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 36, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 36  1  0  0]]\n",
      "rewardsum:  268.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  272.0\n",
      "Episode: 44\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  8139\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [85, 4, 3, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[85  4  3  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 7, 1, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   7   1   1   0]]\n",
      "rewardsum:  1.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 13, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13   0   0   0]]\n",
      "rewardsum:  5.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   1   0   0]]\n",
      "rewardsum:  8.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 19, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  19   4   0   0]]\n",
      "rewardsum:  10.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 24, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 24  4  0  0]]\n",
      "rewardsum:  13.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   4   0   0]]\n",
      "rewardsum:  16.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  18.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   4   0   0]]\n",
      "rewardsum:  21.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 2, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   2   1   0]]\n",
      "rewardsum:  23.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [94, 39, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[94 39  0  0  0]]\n",
      "rewardsum:  28.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   1   0   0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   0   0   0]]\n",
      "rewardsum:  33.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   3   0   0]]\n",
      "rewardsum:  35.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   2   0   0]]\n",
      "rewardsum:  38.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [93, 40, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[93 40  2  0  0]]\n",
      "rewardsum:  40.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  44.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  47.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   1   0]]\n",
      "rewardsum:  50.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  51.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [78, 37, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[78 37  5  0  0]]\n",
      "rewardsum:  53.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   4   0   0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 40, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 40  4  0  0]]\n",
      "rewardsum:  59.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   3   0   0]]\n",
      "rewardsum:  63.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  67.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  69.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   5   0   0]]\n",
      "rewardsum:  72.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   3   0   0]]\n",
      "rewardsum:  75.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  3  0  0]]\n",
      "rewardsum:  78.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  81.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  4  0  0]]\n",
      "rewardsum:  84.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   3   0   0]]\n",
      "rewardsum:  88.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   5   0   0]]\n",
      "rewardsum:  91.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   8   0   0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   9   0   0]]\n",
      "rewardsum:  97.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   9   0   0]]\n",
      "rewardsum:  99.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [77, 33, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[77 33  7  0  0]]\n",
      "rewardsum:  103.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   7   0   0]]\n",
      "rewardsum:  105.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 37, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 37  6  0  0]]\n",
      "rewardsum:  108.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   4   0   0]]\n",
      "rewardsum:  113.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  115.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  119.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  121.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 0, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   0   1   0]]\n",
      "rewardsum:  125.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   0   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 4, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   1   0]]\n",
      "rewardsum:  131.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  135.0\n",
      "Time Slot: 47\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  2  0  0]]\n",
      "rewardsum:  137.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  140.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   0   0]]\n",
      "rewardsum:  144.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 3, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   3   0   0]]\n",
      "rewardsum:  145.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  149.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  152.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 0, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   1   0]]\n",
      "rewardsum:  155.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   0   0]]\n",
      "rewardsum:  159.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   3   0   0]]\n",
      "rewardsum:  161.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   0   0]]\n",
      "rewardsum:  164.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  3  0  0]]\n",
      "rewardsum:  167.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   5   0   0]]\n",
      "rewardsum:  169.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   7   0   0]]\n",
      "rewardsum:  172.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   7   0   0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   8   0   0]]\n",
      "rewardsum:  177.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   5   0   0]]\n",
      "rewardsum:  181.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   5   0   0]]\n",
      "rewardsum:  183.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 3, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  3  0  0]]\n",
      "rewardsum:  188.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  191.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  194.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   5   0   0]]\n",
      "rewardsum:  196.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   9   0   0]]\n",
      "rewardsum:  198.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  12   0   0]]\n",
      "rewardsum:  201.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  13   0   0]]\n",
      "rewardsum:  203.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  13   0   0]]\n",
      "rewardsum:  205.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 14, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  14   0   0]]\n",
      "rewardsum:  207.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  12   0   0]]\n",
      "rewardsum:  210.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 36, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 36 14  0  0]]\n",
      "rewardsum:  213.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  13   0   0]]\n",
      "rewardsum:  216.0\n",
      "Time Slot: 76\n",
      "Rnd\n",
      "actionVec: [29, 10, 17, 75, 100]\n",
      "next_state: [65, 29, 15, 6, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[65 29 15  6  0]]\n",
      "rewardsum:  216.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 14, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  14   0   0]]\n",
      "rewardsum:  224.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 15, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  15   0   0]]\n",
      "rewardsum:  227.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27  16   0   0]]\n",
      "rewardsum:  230.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 24, 15, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 24 15  0  0]]\n",
      "rewardsum:  234.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 21, 18, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  21  18   0   0]]\n",
      "rewardsum:  237.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 15, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23  15   0   0]]\n",
      "rewardsum:  241.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24  17   0   0]]\n",
      "rewardsum:  244.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 17, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28  17   0   0]]\n",
      "rewardsum:  246.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  17   0   0]]\n",
      "rewardsum:  249.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  15   0   0]]\n",
      "rewardsum:  251.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39  13   0   0]]\n",
      "rewardsum:  254.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 15, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41  15   0   0]]\n",
      "rewardsum:  255.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 16, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  16   0   0]]\n",
      "rewardsum:  259.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 17, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  17   0   0]]\n",
      "rewardsum:  260.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 19, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  19   0   0]]\n",
      "rewardsum:  263.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 20, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  20   0   0]]\n",
      "rewardsum:  266.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  17   0   0]]\n",
      "rewardsum:  269.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 18, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  18   0   0]]\n",
      "rewardsum:  271.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 18, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  18   0   0]]\n",
      "rewardsum:  274.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 18, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  18   0   0]]\n",
      "rewardsum:  276.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [95, 33, 18, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 33 18  0  0]]\n",
      "rewardsum:  279.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 29, 20, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 29 20  0  0]]\n",
      "rewardsum:  283.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 21, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  21   0   0]]\n",
      "rewardsum:  285.0\n",
      "Episode: 45\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  6511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Rnd\n",
      "actionVec: [29, 58, 94, 13, 100]\n",
      "next_state: [84, 5, 1, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[84  5  1  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 11, 1, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11   1   0   0]]\n",
      "rewardsum:  1.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 13, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13   3   0   0]]\n",
      "rewardsum:  5.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 17, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  17   3   0   0]]\n",
      "rewardsum:  8.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   4   0   0]]\n",
      "rewardsum:  11.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 24, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 24  2  0  0]]\n",
      "rewardsum:  15.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   2   0   0]]\n",
      "rewardsum:  18.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   1   0   0]]\n",
      "rewardsum:  21.0\n",
      "Time Slot: 8\n",
      "Rnd\n",
      "actionVec: [68, 99, 77, 96, 100]\n",
      "next_state: [100, 33, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   0   0   0]]\n",
      "rewardsum:  24.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 2, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   1   0]]\n",
      "rewardsum:  26.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [88, 33, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[88 33  3  0  0]]\n",
      "rewardsum:  29.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  32.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  1  0  0]]\n",
      "rewardsum:  36.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  39.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  41.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 3, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   3   0   0]]\n",
      "rewardsum:  42.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   4   0   0]]\n",
      "rewardsum:  45.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 6, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   6   0   0]]\n",
      "rewardsum:  46.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   4   0   0]]\n",
      "rewardsum:  50.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 5, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   5   1   0]]\n",
      "rewardsum:  52.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [90, 37, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[90 37  5  0  0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   3   0   0]]\n",
      "rewardsum:  59.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  63.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   0   0   0]]\n",
      "rewardsum:  67.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   0   0   0]]\n",
      "rewardsum:  69.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   3   0   0]]\n",
      "rewardsum:  71.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  75.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  78.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 5, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   5   0   0]]\n",
      "rewardsum:  79.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   7   0   0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  86.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   6   0   0]]\n",
      "rewardsum:  88.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   7   0   0]]\n",
      "rewardsum:  91.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   9   0   0]]\n",
      "rewardsum:  94.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   8   0   0]]\n",
      "rewardsum:  96.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [87, 38, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[87 38  7  0  0]]\n",
      "rewardsum:  99.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 9, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   9   1   0]]\n",
      "rewardsum:  102.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  10   0   0]]\n",
      "rewardsum:  106.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  8  0  0]]\n",
      "rewardsum:  110.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   6   0   0]]\n",
      "rewardsum:  114.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   7   0   0]]\n",
      "rewardsum:  117.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   7   0   0]]\n",
      "rewardsum:  121.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   7   0   0]]\n",
      "rewardsum:  123.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   5   0   0]]\n",
      "rewardsum:  127.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 4, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   4   0   0]]\n",
      "rewardsum:  132.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   0   0   0]]\n",
      "rewardsum:  137.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   3   0   0]]\n",
      "rewardsum:  140.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   5   0   0]]\n",
      "rewardsum:  142.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   6   0   0]]\n",
      "rewardsum:  144.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 30, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 30  3  0  0]]\n",
      "rewardsum:  148.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  150.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   8   0   0]]\n",
      "rewardsum:  153.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  5  0  0]]\n",
      "rewardsum:  157.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  28   5   0   0]]\n",
      "rewardsum:  161.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   5   0   0]]\n",
      "rewardsum:  165.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   6   0   0]]\n",
      "rewardsum:  167.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [66, 31, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[66 31  7  0  0]]\n",
      "rewardsum:  169.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   9   0   0]]\n",
      "rewardsum:  172.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   9   0   0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   9   0   0]]\n",
      "rewardsum:  177.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   8   0   0]]\n",
      "rewardsum:  181.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   9   0   0]]\n",
      "rewardsum:  184.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 10, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  10   0   0]]\n",
      "rewardsum:  187.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  11   0   0]]\n",
      "rewardsum:  189.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 11, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  11   0   0]]\n",
      "rewardsum:  193.0\n",
      "Time Slot: 65\n",
      "Rnd\n",
      "actionVec: [51, 70, 85, 44, 100]\n",
      "next_state: [100, 30, 14, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  14   1   0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  13   0   0]]\n",
      "rewardsum:  198.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 33, 13, 2, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 33 13  2  0]]\n",
      "rewardsum:  200.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  14   0   0]]\n",
      "rewardsum:  203.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 17, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  17   0   0]]\n",
      "rewardsum:  205.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  16   0   0]]\n",
      "rewardsum:  208.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [91, 35, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[91 35 17  0  0]]\n",
      "rewardsum:  211.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 17, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  17   0   0]]\n",
      "rewardsum:  213.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 14, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  14   0   0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  14   0   0]]\n",
      "rewardsum:  221.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 33, 16, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 33 16  0  0]]\n",
      "rewardsum:  223.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 14, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  14   0   0]]\n",
      "rewardsum:  228.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 29, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 29 12  0  0]]\n",
      "rewardsum:  231.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32 12  0  0]]\n",
      "rewardsum:  234.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  13   0   0]]\n",
      "rewardsum:  236.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 17, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  17   0   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 17, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  17   0   0]]\n",
      "rewardsum:  241.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 18, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  18   0   0]]\n",
      "rewardsum:  244.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 16, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  16   0   0]]\n",
      "rewardsum:  247.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 15, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  15   0   0]]\n",
      "rewardsum:  251.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 14, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  14   0   0]]\n",
      "rewardsum:  255.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  14   0   0]]\n",
      "rewardsum:  258.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 15, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  15   0   0]]\n",
      "rewardsum:  260.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 18, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  18   0   0]]\n",
      "rewardsum:  263.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 16, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  16   0   0]]\n",
      "rewardsum:  267.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 16, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  16   0   0]]\n",
      "rewardsum:  269.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 16, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  16   0   0]]\n",
      "rewardsum:  273.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 14, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  14   0   0]]\n",
      "rewardsum:  276.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [96, 29, 13, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 29 13  0  0]]\n",
      "rewardsum:  280.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 31, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 31 12  0  0]]\n",
      "rewardsum:  283.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 10, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  10   0   0]]\n",
      "rewardsum:  288.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 13, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  13   0   0]]\n",
      "rewardsum:  290.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  11   0   0]]\n",
      "rewardsum:  293.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  12   0   0]]\n",
      "rewardsum:  295.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  13   0   0]]\n",
      "rewardsum:  298.0\n",
      "Episode: 46\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  6738\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [89, 7, 0, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[89  7  0  1  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 6, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   6   3   0   0]]\n",
      "rewardsum:  4.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 8, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100   8   0   0   0]]\n",
      "rewardsum:  9.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 9, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100   9   2   0   0]]\n",
      "rewardsum:  12.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 15, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  15   0   0   0]]\n",
      "rewardsum:  15.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   0   0   0]]\n",
      "rewardsum:  19.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 2, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   2   0   0]]\n",
      "rewardsum:  20.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   0   0   0]]\n",
      "rewardsum:  23.0\n",
      "Time Slot: 8\n",
      "Rnd\n",
      "actionVec: [43, 71, 10, 31, 100]\n",
      "next_state: [100, 34, 0, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   1   0]]\n",
      "rewardsum:  26.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   0   0   0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [94, 41, 0, 2, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[94 41  0  2  0]]\n",
      "rewardsum:  31.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   1   0   0]]\n",
      "rewardsum:  35.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   0   0   0]]\n",
      "rewardsum:  37.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   1   0   0]]\n",
      "rewardsum:  39.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   4   0   0]]\n",
      "rewardsum:  42.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [81, 35, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[81 35  0  0  0]]\n",
      "rewardsum:  46.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  48.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   4   0   0]]\n",
      "rewardsum:  51.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 3, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   3   1   0]]\n",
      "rewardsum:  54.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   2   0   0]]\n",
      "rewardsum:  58.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   0   0]]\n",
      "rewardsum:  61.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   3   0   0]]\n",
      "rewardsum:  65.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  67.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  70.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  73.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   0   0   0]]\n",
      "rewardsum:  77.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   0   0   0]]\n",
      "rewardsum:  80.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   0   0]]\n",
      "rewardsum:  85.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  3  0  0]]\n",
      "rewardsum:  89.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   5   0   0]]\n",
      "rewardsum:  91.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  96.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   3   0   0]]\n",
      "rewardsum:  98.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   5   0   0]]\n",
      "rewardsum:  102.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   3   0   0]]\n",
      "rewardsum:  105.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  109.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  3  0  0]]\n",
      "rewardsum:  111.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   0   0]]\n",
      "rewardsum:  114.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  118.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   0   0   0]]\n",
      "rewardsum:  122.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 3, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   3   0   0]]\n",
      "rewardsum:  123.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   0   0   0]]\n",
      "rewardsum:  126.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   1   0   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   2   0   0]]\n",
      "rewardsum:  131.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 43, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  43   0   0   0]]\n",
      "rewardsum:  134.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   5   0   0]]\n",
      "rewardsum:  136.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   5   0   0]]\n",
      "rewardsum:  138.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   6   0   0]]\n",
      "rewardsum:  141.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   1   0]]\n",
      "rewardsum:  145.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   6   0   0]]\n",
      "rewardsum:  148.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 33, 5, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 33  5  1  0]]\n",
      "rewardsum:  150.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  154.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   4   0   0]]\n",
      "rewardsum:  158.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   5   0   0]]\n",
      "rewardsum:  160.0\n",
      "Time Slot: 55\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [85, 36, 4, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[85 36  4  1  0]]\n",
      "rewardsum:  163.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   3   0   0]]\n",
      "rewardsum:  166.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   3   0   0]]\n",
      "rewardsum:  169.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   4   0   0]]\n",
      "rewardsum:  171.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 37, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 37  1  0  0]]\n",
      "rewardsum:  175.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  179.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   1   0]]\n",
      "rewardsum:  181.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 34, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 34  1  0  0]]\n",
      "rewardsum:  185.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  187.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   0   0]]\n",
      "rewardsum:  190.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   3   0   0]]\n",
      "rewardsum:  192.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   5   0   0]]\n",
      "rewardsum:  194.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   5   0   0]]\n",
      "rewardsum:  196.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 40, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 40  2  0  0]]\n",
      "rewardsum:  200.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   3   0   0]]\n",
      "rewardsum:  203.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   1   0   0]]\n",
      "rewardsum:  206.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   1   0   0]]\n",
      "rewardsum:  209.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  212.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  215.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  221.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  223.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  226.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  229.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   0   0]]\n",
      "rewardsum:  233.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  2  0  0]]\n",
      "rewardsum:  236.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  237.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   3   0   0]]\n",
      "rewardsum:  239.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   5   0   0]]\n",
      "rewardsum:  242.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   5   0   0]]\n",
      "rewardsum:  244.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   4   0   0]]\n",
      "rewardsum:  248.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [66, 40, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[66 40  3  0  0]]\n",
      "rewardsum:  251.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   4   0   0]]\n",
      "rewardsum:  254.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   3   0   0]]\n",
      "rewardsum:  256.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   3   0   0]]\n",
      "rewardsum:  260.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   4   0   0]]\n",
      "rewardsum:  262.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 37, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 37  3  0  0]]\n",
      "rewardsum:  265.0\n",
      "Time Slot: 92\n",
      "Rnd\n",
      "actionVec: [3, 21, 85, 56, 100]\n",
      "next_state: [100, 44, 5, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  44   5   0   0]]\n",
      "rewardsum:  265.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 5, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   5   1   0]]\n",
      "rewardsum:  268.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 44, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  44   4   0   0]]\n",
      "rewardsum:  271.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   4   0   0]]\n",
      "rewardsum:  275.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   5   0   0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  281.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  284.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   6   0   0]]\n",
      "rewardsum:  286.0\n",
      "Episode: 47\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  7768\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [82, 5, 1, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[82  5  1  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 10, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  10   3   0   0]]\n",
      "rewardsum:  2.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 11, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11   3   0   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   4   0   0]]\n",
      "rewardsum:  8.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   3   0   0]]\n",
      "rewardsum:  12.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [89, 24, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[89 24  3  0  0]]\n",
      "rewardsum:  14.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   3   0   0]]\n",
      "rewardsum:  18.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  24.0\n",
      "Time Slot: 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  27.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   0   0   0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  33.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   1   0   0]]\n",
      "rewardsum:  36.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   2   0   0]]\n",
      "rewardsum:  38.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   0   0   0]]\n",
      "rewardsum:  41.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   1   0   0]]\n",
      "rewardsum:  43.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   4   0   0]]\n",
      "rewardsum:  45.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 37, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 37  3  0  0]]\n",
      "rewardsum:  49.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   1   0]]\n",
      "rewardsum:  52.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [82, 32, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[82 32  0  0  0]]\n",
      "rewardsum:  59.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 0, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   0   1   0]]\n",
      "rewardsum:  62.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   1   0   0]]\n",
      "rewardsum:  64.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   0   0   0]]\n",
      "rewardsum:  67.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   1   0   0]]\n",
      "rewardsum:  69.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   0   0   0]]\n",
      "rewardsum:  74.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  78.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  84.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   5   0   0]]\n",
      "rewardsum:  87.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   6   0   0]]\n",
      "rewardsum:  89.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   1   0]]\n",
      "rewardsum:  92.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   5   0   0]]\n",
      "rewardsum:  95.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   7   0   0]]\n",
      "rewardsum:  97.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [93, 37, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[93 37  7  0  0]]\n",
      "rewardsum:  100.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   6   0   0]]\n",
      "rewardsum:  104.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  5  0  0]]\n",
      "rewardsum:  108.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   5   0   0]]\n",
      "rewardsum:  112.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   2   0   0]]\n",
      "rewardsum:  115.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   3   0   0]]\n",
      "rewardsum:  118.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  120.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   4   0   0]]\n",
      "rewardsum:  123.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   7   0   0]]\n",
      "rewardsum:  125.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   7   0   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   6   0   0]]\n",
      "rewardsum:  131.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   6   0   0]]\n",
      "rewardsum:  134.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   8   0   0]]\n",
      "rewardsum:  137.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   6   0   0]]\n",
      "rewardsum:  141.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   0   0]]\n",
      "rewardsum:  145.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 3, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  3  1  0]]\n",
      "rewardsum:  147.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   7   0   0]]\n",
      "rewardsum:  150.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  5  0  0]]\n",
      "rewardsum:  153.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 5, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  5  0  0]]\n",
      "rewardsum:  157.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  160.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  163.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   7   0   0]]\n",
      "rewardsum:  166.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 29, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 29  6  0  0]]\n",
      "rewardsum:  170.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   9   0   0]]\n",
      "rewardsum:  173.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   9   0   0]]\n",
      "rewardsum:  176.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 11, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30  11   0   0]]\n",
      "rewardsum:  178.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 30, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[99 30  9  0  0]]\n",
      "rewardsum:  181.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36  10   0   0]]\n",
      "rewardsum:  183.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  11   0   0]]\n",
      "rewardsum:  186.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   9   0   0]]\n",
      "rewardsum:  189.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 36, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 36  8  0  0]]\n",
      "rewardsum:  193.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [77, 37, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[77 37  9  0  0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   9   0   0]]\n",
      "rewardsum:  199.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 11, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  11   0   0]]\n",
      "rewardsum:  202.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 12, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32  12   0   0]]\n",
      "rewardsum:  204.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 10, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33  10   0   0]]\n",
      "rewardsum:  208.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31  12   0   0]]\n",
      "rewardsum:  211.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 9, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   9   0   0]]\n",
      "rewardsum:  215.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   9   0   0]]\n",
      "rewardsum:  218.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   8   0   0]]\n",
      "rewardsum:  221.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   7   0   0]]\n",
      "rewardsum:  225.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   8   0   0]]\n",
      "rewardsum:  228.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 11, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  11   0   0]]\n",
      "rewardsum:  229.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  12   0   0]]\n",
      "rewardsum:  232.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 12, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35  12   0   0]]\n",
      "rewardsum:  235.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 13, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  13   0   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 81\n",
      "Rnd\n",
      "actionVec: [93, 87, 27, 99, 100]\n",
      "next_state: [97, 32, 7, 6, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 32  7  6  0]]\n",
      "rewardsum:  240.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 8, 0, 0]\n",
      "Reward: 8.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   8   0   0]]\n",
      "rewardsum:  248.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 25, 8, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 25  8  0  0]]\n",
      "rewardsum:  252.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 26, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  26   7   0   0]]\n",
      "rewardsum:  254.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 27, 3, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  27   3   0   0]]\n",
      "rewardsum:  259.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   4   0   0]]\n",
      "rewardsum:  262.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   1   0]]\n",
      "rewardsum:  265.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  268.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   4   0   0]]\n",
      "rewardsum:  272.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   3   0   0]]\n",
      "rewardsum:  275.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  278.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 6, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   6   0   0]]\n",
      "rewardsum:  280.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   7   0   0]]\n",
      "rewardsum:  282.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   7   0   0]]\n",
      "rewardsum:  285.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 7, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   7   0   0]]\n",
      "rewardsum:  289.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   8   0   0]]\n",
      "rewardsum:  291.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 35, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 35  7  0  0]]\n",
      "rewardsum:  294.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   8   0   0]]\n",
      "rewardsum:  297.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 10, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34  10   0   0]]\n",
      "rewardsum:  299.0\n",
      "Episode: 48\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  8819\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [82, 7, 1, 0, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[82  7  1  0  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 13, 4, 0, 1]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  13   4   0   1]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 18, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  18   3   0   0]]\n",
      "rewardsum:  4.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 22, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  22   5   0   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   5   0   0]]\n",
      "rewardsum:  8.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [91, 33, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[91 33  4  0  0]]\n",
      "rewardsum:  11.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 0, 1, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   0   1   0]]\n",
      "rewardsum:  16.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  18.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   1   0]]\n",
      "rewardsum:  21.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  24.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  27.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 2, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   2   1   0]]\n",
      "rewardsum:  28.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  40   4   0   0]]\n",
      "rewardsum:  31.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   3   0   0]]\n",
      "rewardsum:  34.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   3   0   0]]\n",
      "rewardsum:  37.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [82, 41, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[82 41  2  0  0]]\n",
      "rewardsum:  39.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   0   0   0]]\n",
      "rewardsum:  42.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   0   0   0]]\n",
      "rewardsum:  45.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   1   0   0]]\n",
      "rewardsum:  48.0\n",
      "Time Slot: 19\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   1   0   0]]\n",
      "rewardsum:  50.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   1   0   0]]\n",
      "rewardsum:  53.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  56.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 34, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 34  2  0  0]]\n",
      "rewardsum:  60.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   3   0   0]]\n",
      "rewardsum:  62.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  65.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  72.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   3   0   0]]\n",
      "rewardsum:  75.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   2   0   0]]\n",
      "rewardsum:  79.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 1, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   1   1   0]]\n",
      "rewardsum:  82.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   1   0   0]]\n",
      "rewardsum:  85.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 0, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   0   1   0]]\n",
      "rewardsum:  88.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  90.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 1, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   1   0]]\n",
      "rewardsum:  94.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   1   0   0]]\n",
      "rewardsum:  98.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   1   0   0]]\n",
      "rewardsum:  101.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [95, 35, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 35  1  0  0]]\n",
      "rewardsum:  103.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  107.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 1, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   1   1   0]]\n",
      "rewardsum:  108.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   1   0   0]]\n",
      "rewardsum:  112.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   4   0   0]]\n",
      "rewardsum:  114.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  117.0\n",
      "Time Slot: 42\n",
      "Rnd\n",
      "actionVec: [76, 73, 30, 12, 100]\n",
      "next_state: [98, 32, 0, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 32  0  0  0]]\n",
      "rewardsum:  122.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   1   0   0]]\n",
      "rewardsum:  124.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   1   0   0]]\n",
      "rewardsum:  128.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [91, 33, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[91 33  2  0  0]]\n",
      "rewardsum:  130.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  132.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  136.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   3   0   0]]\n",
      "rewardsum:  138.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 3, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   3   1   0]]\n",
      "rewardsum:  140.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  144.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   4   0   0]]\n",
      "rewardsum:  148.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   5   0   0]]\n",
      "rewardsum:  150.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  153.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   5   0   0]]\n",
      "rewardsum:  156.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 3, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   3   0   0]]\n",
      "rewardsum:  161.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 33, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 33  4  0  0]]\n",
      "rewardsum:  164.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 30, 2, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 30  2  1  0]]\n",
      "rewardsum:  167.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   0   0]]\n",
      "rewardsum:  170.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  174.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  176.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  179.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   0   0]]\n",
      "rewardsum:  182.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  185.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  188.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  191.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   0   0]]\n",
      "rewardsum:  195.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  196.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  198.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   4   0   0]]\n",
      "rewardsum:  200.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   3   0   0]]\n",
      "rewardsum:  203.0\n",
      "Time Slot: 71\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 40, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 40  4  0  0]]\n",
      "rewardsum:  207.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 4, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   4   1   0]]\n",
      "rewardsum:  209.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 5, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   5   1   0]]\n",
      "rewardsum:  212.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  216.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   3   0   0]]\n",
      "rewardsum:  220.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 33, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 33  4  0  0]]\n",
      "rewardsum:  222.0\n",
      "Time Slot: 77\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 33, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 33  2  0  0]]\n",
      "rewardsum:  226.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  229.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  232.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  235.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  237.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   3   0   0]]\n",
      "rewardsum:  240.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 38, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 38  4  0  0]]\n",
      "rewardsum:  243.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 38, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 38  3  0  0]]\n",
      "rewardsum:  246.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   5   0   0]]\n",
      "rewardsum:  249.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  253.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  255.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  258.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 7, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   7   0   0]]\n",
      "rewardsum:  259.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   6   0   0]]\n",
      "rewardsum:  263.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   6   0   0]]\n",
      "rewardsum:  266.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   6   0   0]]\n",
      "rewardsum:  269.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   6   0   0]]\n",
      "rewardsum:  272.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   5   0   0]]\n",
      "rewardsum:  275.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 7, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   7   0   0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 37, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 37  7  0  0]]\n",
      "rewardsum:  280.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   7   0   0]]\n",
      "rewardsum:  283.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 36, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 36  9  0  0]]\n",
      "rewardsum:  285.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 10, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37  10   1   0]]\n",
      "rewardsum:  287.0\n",
      "Episode: 49\n",
      "linear-wireless-mesh|123\n",
      "Got new port for ns3gm interface:  8737\n",
      "state:  [[0 0 0 0 0]]\n",
      "Time Slot: 0\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [80, 8, 0, 1, 0]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[80  8  0  1  0]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 1\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 11, 1, 0, 1]\n",
      "Reward: 0.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  11   1   0   1]]\n",
      "rewardsum:  0.0\n",
      "Time Slot: 2\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 12, 0, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  12   0   0   0]]\n",
      "rewardsum:  6.0\n",
      "Time Slot: 3\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 20, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  20   0   0   0]]\n",
      "rewardsum:  8.0\n",
      "Time Slot: 4\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 25, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  25   0   0   0]]\n",
      "rewardsum:  11.0\n",
      "Time Slot: 5\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [97, 32, 1, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[97 32  1  0  0]]\n",
      "rewardsum:  12.0\n",
      "Time Slot: 6\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   0   0   0]]\n",
      "rewardsum:  16.0\n",
      "Time Slot: 7\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 42, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  42   0   0   0]]\n",
      "rewardsum:  18.0\n",
      "Time Slot: 8\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   0   0   0]]\n",
      "rewardsum:  22.0\n",
      "Time Slot: 9\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   3   0   0]]\n",
      "rewardsum:  24.0\n",
      "Time Slot: 10\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   1   0   0]]\n",
      "rewardsum:  27.0\n",
      "Time Slot: 11\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 35, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 35  2  0  0]]\n",
      "rewardsum:  30.0\n",
      "Time Slot: 12\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 0, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   0   1   0]]\n",
      "rewardsum:  33.0\n",
      "Time Slot: 13\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  36.0\n",
      "Time Slot: 14\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   4   0   0]]\n",
      "rewardsum:  39.0\n",
      "Time Slot: 15\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [71, 31, 4, 1, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[71 31  4  1  0]]\n",
      "rewardsum:  41.0\n",
      "Time Slot: 16\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   3   0   0]]\n",
      "rewardsum:  45.0\n",
      "Time Slot: 17\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   2   0   0]]\n",
      "rewardsum:  48.0\n",
      "Time Slot: 18\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   0   0]]\n",
      "rewardsum:  51.0\n",
      "Time Slot: 19\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  54.0\n",
      "Time Slot: 20\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  57.0\n",
      "Time Slot: 21\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   3   0   0]]\n",
      "rewardsum:  59.0\n",
      "Time Slot: 22\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   2   0   0]]\n",
      "rewardsum:  63.0\n",
      "Time Slot: 23\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  65.0\n",
      "Time Slot: 24\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   3   0   0]]\n",
      "rewardsum:  68.0\n",
      "Time Slot: 25\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   1   0]]\n",
      "rewardsum:  71.0\n",
      "Time Slot: 26\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   4   0   0]]\n",
      "rewardsum:  74.0\n",
      "Time Slot: 27\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 39, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  39   4   0   0]]\n",
      "rewardsum:  76.0\n",
      "Time Slot: 28\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   3   0   0]]\n",
      "rewardsum:  80.0\n",
      "Time Slot: 29\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   1   0]]\n",
      "rewardsum:  83.0\n",
      "Time Slot: 30\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [95, 35, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[95 35  1  0  0]]\n",
      "rewardsum:  87.0\n",
      "Time Slot: 31\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  1  0  0]]\n",
      "rewardsum:  91.0\n",
      "Time Slot: 32\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   3   0   0]]\n",
      "rewardsum:  93.0\n",
      "Time Slot: 33\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   2   0   0]]\n",
      "rewardsum:  97.0\n",
      "Time Slot: 34\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 1, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   1   0   0]]\n",
      "rewardsum:  99.0\n",
      "Time Slot: 35\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   5   0   0]]\n",
      "rewardsum:  102.0\n",
      "Time Slot: 36\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   3   0   0]]\n",
      "rewardsum:  106.0\n",
      "Time Slot: 37\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   0   0]]\n",
      "rewardsum:  109.0\n",
      "Time Slot: 38\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 31, 0, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  31   0   0   0]]\n",
      "rewardsum:  113.0\n",
      "Time Slot: 39\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 0, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   0   0   0]]\n",
      "rewardsum:  116.0\n",
      "Time Slot: 40\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 0, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   0   0   0]]\n",
      "rewardsum:  118.0\n",
      "Time Slot: 41\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   3   0   0]]\n",
      "rewardsum:  121.0\n",
      "Time Slot: 42\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  124.0\n",
      "Time Slot: 43\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   3   0   0]]\n",
      "rewardsum:  126.0\n",
      "Time Slot: 44\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 7, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40   7   0   0]]\n",
      "rewardsum:  127.0\n",
      "Time Slot: 45\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   9   0   0]]\n",
      "rewardsum:  129.0\n",
      "Time Slot: 46\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 12, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  12   1   0]]\n",
      "rewardsum:  130.0\n",
      "Time Slot: 47\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 40, 10, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  40  10   1   0]]\n",
      "rewardsum:  133.0\n",
      "Time Slot: 48\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 8, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   8   0   0]]\n",
      "rewardsum:  138.0\n",
      "Time Slot: 49\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   6   0   0]]\n",
      "rewardsum:  142.0\n",
      "Time Slot: 50\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   6   0   0]]\n",
      "rewardsum:  145.0\n",
      "Time Slot: 51\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  6  0  0]]\n",
      "rewardsum:  149.0\n",
      "Time Slot: 52\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   5   0   0]]\n",
      "rewardsum:  152.0\n",
      "Time Slot: 53\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 5, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   5   1   0]]\n",
      "rewardsum:  155.0\n",
      "Time Slot: 54\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 29, 2, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 29  2  0  0]]\n",
      "rewardsum:  160.0\n",
      "Time Slot: 55\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 3, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   3   0   0]]\n",
      "rewardsum:  163.0\n",
      "Time Slot: 56\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 32, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  32   2   0   0]]\n",
      "rewardsum:  166.0\n",
      "Time Slot: 57\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  1  0  0]]\n",
      "rewardsum:  169.0\n",
      "Time Slot: 58\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  172.0\n",
      "Time Slot: 59\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 1, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   1   0   0]]\n",
      "rewardsum:  176.0\n",
      "Time Slot: 60\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   2   0   0]]\n",
      "rewardsum:  179.0\n",
      "Time Slot: 61\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [98, 31, 4, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[98 31  4  0  0]]\n",
      "rewardsum:  181.0\n",
      "Time Slot: 62\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 3, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   3   0   0]]\n",
      "rewardsum:  186.0\n",
      "Time Slot: 63\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 31, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 31  2  0  0]]\n",
      "rewardsum:  188.0\n",
      "Time Slot: 64\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 3, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   3   0   0]]\n",
      "rewardsum:  190.0\n",
      "Time Slot: 65\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   0   0]]\n",
      "rewardsum:  193.0\n",
      "Time Slot: 66\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 2, 1, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   2   1   0]]\n",
      "rewardsum:  196.0\n",
      "Time Slot: 67\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 41, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  41   2   0   0]]\n",
      "rewardsum:  199.0\n",
      "Time Slot: 68\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   2   0   0]]\n",
      "rewardsum:  202.0\n",
      "Time Slot: 69\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   2   0   0]]\n",
      "rewardsum:  205.0\n",
      "Time Slot: 70\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   1   0   0]]\n",
      "rewardsum:  208.0\n",
      "Time Slot: 71\n",
      "Max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 38, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 38  2  0  0]]\n",
      "rewardsum:  210.0\n",
      "Time Slot: 72\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  213.0\n",
      "Time Slot: 73\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  215.0\n",
      "Time Slot: 74\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 2, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   2   0   0]]\n",
      "rewardsum:  219.0\n",
      "Time Slot: 75\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   1   0   0]]\n",
      "rewardsum:  222.0\n",
      "Time Slot: 76\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [51, 35, 1, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[51 35  1  0  0]]\n",
      "rewardsum:  225.0\n",
      "Time Slot: 77\n",
      "Rnd\n",
      "actionVec: [73, 4, 39, 89, 100]\n",
      "next_state: [96, 24, 9, 1, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[96 24  9  1  0]]\n",
      "rewardsum:  226.0\n",
      "Time Slot: 78\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 8, 0, 0]\n",
      "Reward: 6.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   8   0   0]]\n",
      "rewardsum:  232.0\n",
      "Time Slot: 79\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   9   0   0]]\n",
      "rewardsum:  235.0\n",
      "Time Slot: 80\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 23, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  23   9   0   0]]\n",
      "rewardsum:  238.0\n",
      "Time Slot: 81\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 24, 7, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  24   7   0   0]]\n",
      "rewardsum:  241.0\n",
      "Time Slot: 82\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   8   0   0]]\n",
      "rewardsum:  244.0\n",
      "Time Slot: 83\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 9, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   9   0   0]]\n",
      "rewardsum:  246.0\n",
      "Time Slot: 84\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 8, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   8   0   0]]\n",
      "rewardsum:  249.0\n",
      "Time Slot: 85\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   9   0   0]]\n",
      "rewardsum:  252.0\n",
      "Time Slot: 86\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 38, 9, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  38   9   0   0]]\n",
      "rewardsum:  255.0\n",
      "Time Slot: 87\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 36, 6, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  36   6   0   0]]\n",
      "rewardsum:  259.0\n",
      "Time Slot: 88\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 4, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   4   0   0]]\n",
      "rewardsum:  263.0\n",
      "Time Slot: 89\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 33, 5, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  33   5   0   0]]\n",
      "rewardsum:  265.0\n",
      "Time Slot: 90\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 35, 3, 0, 0]\n",
      "Reward: 4.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  35   3   0   0]]\n",
      "rewardsum:  269.0\n",
      "Time Slot: 91\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 32, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 32  4  0  0]]\n",
      "rewardsum:  272.0\n",
      "Time Slot: 92\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 29, 6, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  29   6   0   0]]\n",
      "rewardsum:  275.0\n",
      "Time Slot: 93\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 8, 0, 0]\n",
      "Reward: 2.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   8   0   0]]\n",
      "rewardsum:  277.0\n",
      "Time Slot: 94\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 28, 5, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  28   5   0   0]]\n",
      "rewardsum:  282.0\n",
      "Time Slot: 95\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 30, 4, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  30   4   0   0]]\n",
      "rewardsum:  285.0\n",
      "Time Slot: 96\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 34, 5, 0, 0]\n",
      "Reward: 1.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  34   5   0   0]]\n",
      "rewardsum:  286.0\n",
      "Time Slot: 97\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [99, 38, 5, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[99 38  5  0  0]]\n",
      "rewardsum:  289.0\n",
      "Time Slot: 98\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [93, 34, 2, 0, 0]\n",
      "Reward: 5.0\n",
      "----------------- \n",
      "\n",
      "state:  [[93 34  2  0  0]]\n",
      "rewardsum:  294.0\n",
      "Time Slot: 99\n",
      "Max\n",
      "actionVec: [33, 78, 78, 8, 100]\n",
      "next_state: [100, 37, 2, 0, 0]\n",
      "Reward: 3.0\n",
      "----------------- \n",
      "\n",
      "state:  [[100  37   2   0   0]]\n",
      "rewardsum:  297.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save curves to MATLAB file\n"
     ]
    }
   ],
   "source": [
    "class DqnAgent(object):\n",
    "    \"\"\"docstring for DqnAgent\"\"\"\n",
    "    def __init__(self, inNum, outNum):\n",
    "        super(DqnAgent, self).__init__()\n",
    "        self.model = keras.Sequential()\n",
    "        self.model.add(keras.layers.Dense(inNum, input_shape=(inNum,), activation='relu'))\n",
    "        self.model.add(keras.layers.Dense(outNum, activation='softmax'))\n",
    "        self.model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "    def get_action(self, state):\n",
    "        return np.argmax(self.model.predict(state)[0])\n",
    "\n",
    "    def predict(self, next_state):\n",
    "        return self.model.predict(next_state)[0]\n",
    "\n",
    "    def fit(self, state, target, action):\n",
    "        target_f = self.model.predict(state)\n",
    "        target_f[0][action] = target\n",
    "        self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "\n",
    "\n",
    "# Environment initialization\n",
    "port = 5555\n",
    "simTime = 10 # seconds\n",
    "startSim = True\n",
    "stepTime = 0.05 # seconds\n",
    "seed = 132\n",
    "simArgs = {\"--simTime\": simTime,\n",
    "           \"--testArg\": 123,\n",
    "           \"--nodeNum\": 5,\n",
    "           \"--distance\": 500}\n",
    "debug = False\n",
    "\n",
    "#env = ns3env.Ns3Env(port=port, stepTime=stepTime, startSim=startSim, simSeed=seed, simArgs=simArgs, debug=debug)\n",
    "env = gym.make('ns3-v0')\n",
    "\n",
    "ob_space = env.observation_space\n",
    "ac_space = env.action_space\n",
    "print(\"Observation space: \", ob_space,  ob_space.dtype)\n",
    "print(\"Action space: \", ac_space, ac_space.dtype)\n",
    "s_size = ob_space.shape[0]\n",
    "a_size = ac_space.shape[0]\n",
    "\n",
    "inputQueues = 2\n",
    "cwSize = 100\n",
    "\n",
    "agent0 = DqnAgent(inputQueues, cwSize)\n",
    "agent1 = DqnAgent(inputQueues, cwSize)\n",
    "agent2 = DqnAgent(inputQueues, cwSize)\n",
    "agent3 = DqnAgent(inputQueues, cwSize)\n",
    "\n",
    "\n",
    "#print(\"agent0-3: \")\n",
    "#print(agent0)\n",
    "#print(agent1)\n",
    "#print(agent2)\n",
    "#print(agent3)\n",
    "#print(\"-------\")\n",
    "\n",
    "total_episodes = 50\n",
    "max_env_steps = 100\n",
    "env._max_episode_steps = max_env_steps\n",
    "\n",
    "epsilon = 1.0               # exploration rate\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.999\n",
    "\n",
    "time_history = []\n",
    "rew_history = []\n",
    "\n",
    "for e in range(total_episodes):\n",
    "\n",
    "    print('Episode:', e)\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, s_size])\n",
    "    print(\"state: \", state)\n",
    "    \n",
    "    rewardsum = 0\n",
    "    for time in range(max_env_steps):\n",
    "\n",
    "        print(\"Time Slot:\", time)\n",
    "        \n",
    "        # Choose action\n",
    "        if np.random.rand(1) < epsilon:\n",
    "            action0 = np.random.randint(cwSize)\n",
    "            action1 = np.random.randint(cwSize)\n",
    "            action2 = np.random.randint(cwSize)\n",
    "            action3 = np.random.randint(cwSize)\n",
    "            print(\"Rnd\")\n",
    "            #print(\"Rnd action0: \", action0)\n",
    "            #print(\"Rnd action1: \", action1)\n",
    "            #print(\"Rnd action2: \", action2)\n",
    "            #print(\"Rnd action3: \", action3)\n",
    "        else:\n",
    "            action0 = agent0.get_action(state[:,0:2])\n",
    "            action1 = agent1.get_action(state[:,1:3])\n",
    "            action2 = agent2.get_action(state[:,2:4])\n",
    "            action3 = agent3.get_action(state[:,3:5])\n",
    "            print(\"Max\")\n",
    "            #print(\"Max action0: \", action0)\n",
    "            #print(\"Max action1: \", action1)\n",
    "            #print(\"Max action2: \", action2)\n",
    "            #print(\"Max action3: \", action3)\n",
    "\n",
    "        # Step\n",
    "        actionVec = [action0, action1, action2, action3, 100]\n",
    "        #print(\"actionVec:\", actionVec)\n",
    "        next_state, reward, done, _, _ = env.step(actionVec)\n",
    "        \n",
    "        print(\"actionVec:\", actionVec)\n",
    "        print(\"next_state:\", next_state)\n",
    "        print(\"Reward:\", reward)\n",
    "        print('-----------------', '\\n')\n",
    "        #print(\"valores depois do env.step: \", next_state, reward, done)\n",
    "\n",
    "        if done:\n",
    "            print(\"episode: {}/{}, time: {}, rew: {}, eps: {:.2}\"\n",
    "                  .format(e, total_episodes, time, rewardsum, epsilon))\n",
    "            break\n",
    "\n",
    "        next_state = np.reshape(next_state, [1, s_size])\n",
    "\n",
    "        # Train\n",
    "        target0 = reward\n",
    "        target1 = reward\n",
    "        target2 = reward\n",
    "        target3 = reward\n",
    "        #print(\"target0: \", target0)\n",
    "        \n",
    "\n",
    "        if not done:\n",
    "            target0 = reward + 0.95 * np.amax(agent0.predict(next_state[:,0:2]))\n",
    "            target1 = reward + 0.95 * np.amax(agent1.predict(next_state[:,1:3]))\n",
    "            target2 = reward + 0.95 * np.amax(agent2.predict(next_state[:,2:4]))\n",
    "            target3 = reward + 0.95 * np.amax(agent3.predict(next_state[:,3:5]))\n",
    "            #print(\"target0: \", target0)\n",
    "            #print(\"target1: \", target1)\n",
    "            #print(\"target2: \", target2)\n",
    "            #print(\"target3: \", target3)\n",
    "\n",
    "        agent0.fit(state[:,0:2], target0, action0)\n",
    "        agent1.fit(state[:,1:3], target1, action1)\n",
    "        agent2.fit(state[:,2:4], target2, action2)\n",
    "        agent3.fit(state[:,3:5], target3, action3)\n",
    "        #print(\"agent0: \", agent0)\n",
    "        #print(\"agent1: \", agent1)\n",
    "        #print(\"agent2: \", agent2)\n",
    "        #print(\"agent3: \", agent3)\n",
    "\n",
    "        state = next_state\n",
    "        rewardsum += reward\n",
    "        print(\"state: \", state)\n",
    "        print(\"rewardsum: \", rewardsum)\n",
    "        \n",
    "        if epsilon > epsilon_min: epsilon *= epsilon_decay\n",
    "        \n",
    "    time_history.append(time)\n",
    "    rew_history.append(rewardsum)\n",
    "\n",
    "#for n in range(2 ** s_size):\n",
    "#    state = [n >> i & 1 for i in range(0, 2)]\n",
    "#    state = np.reshape(state, [1, s_size])\n",
    "#    print(\"state \" + str(state) \n",
    "#        + \" -> prediction \" + str(model.predict(state)[0])\n",
    "#        )\n",
    "\n",
    "#print(model.get_config())\n",
    "#print(model.to_json())\n",
    "#print(model.get_weights())\n",
    "\n",
    "\n",
    "plt.plot(range(len(time_history)), time_history)\n",
    "plt.plot(range(len(rew_history)), rew_history)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Time')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "curve0 = np.zeros(shape=(101,101))\n",
    "curve1 = np.zeros(shape=(101,101))\n",
    "curve2 = np.zeros(shape=(101,101))\n",
    "curve3 = np.zeros(shape=(101,101))\n",
    "\n",
    "for i in range(101):\n",
    "    for j in range(101):\n",
    "        state = np.array([i,j])\n",
    "        state = np.reshape(state, [1, 2])\n",
    "\n",
    "        curve0[i,j] = agent0.get_action(state)\n",
    "        curve1[i,j] = agent1.get_action(state)\n",
    "        curve2[i,j] = agent2.get_action(state)\n",
    "        curve3[i,j] = agent3.get_action(state)\n",
    "        \n",
    "print(\"Save curves to MATLAB file\")\n",
    "io.savemat(\"curves_2d.mat\", {\n",
    "                '0':curve0,\n",
    "                '1':curve1,\n",
    "                '2':curve2,\n",
    "                '3':curve3,\n",
    "               }\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb390c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
